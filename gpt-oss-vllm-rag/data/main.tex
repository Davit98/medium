% \documentclass[reqno]{amsart}%
\documentclass[a4paper,12pt]{report}
\usepackage{blindtext}
% \usepackage{fontspec}
% \setmainfont{Times New Roman}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[russian, english]{babel}
\usepackage{graphicx}
\usepackage[toc,page]{appendix}
\usepackage{longtable}
\usepackage{multirow}
\usepackage{authblk}
\usepackage{zref-totpages}
\usepackage{bm}
\usepackage{array}
\usepackage{url}
\usepackage{color}
\usepackage{enumerate}% http://ctan.org/pkg/enumerate
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{mathtools}

\usepackage{hyperref}
\usepackage{pgfplots}
\usepackage{subcaption}

\pgfplotsset{compat=1.18}
\usepackage{standalone}
\usepackage{multirow}
\usepackage{setspace}
\usepackage{systeme}
\graphicspath{ {./figures} }

\captionsetup{font=normalsize}
\captionsetup[sub]{font=footnotesize}
% \usepackage[russian]{babel}

\newcommand{\A}{\mathcal{A}}
\newcommand{\B}{\mathcal{B}}
\newcommand{\F}{\mathcal{F}}
\newcommand{\J}{\mathcal{J}}
\newcommand{\h}{\mathcal{H}}
\newcommand{\R}{\mathcal{R}}
\newcommand{\ov}{\overline}
\newcommand{\wh}[1]{\widehat{#1}}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}{Proposition}[section]
\newtheorem{lemma}{Lemma}[section]
\newtheorem{conjecture}{Conjecture}[section]
\newtheorem{corollary}{Corollary}[section]
\newtheorem{remark}{Remark}[section]
\newtheorem{definition}{Definition}[section]
\newtheorem{example}{Example}


\numberwithin{equation}{section} \numberwithin{figure}{section}
\numberwithin{table}{section}

\usepackage[left=3cm, right=1cm, top=2cm, bottom=2.5cm]{geometry}

\renewcommand{\baselinestretch}{1.69}

\begin{document}

\begin{titlepage}
\center 

\textsc{\large YEREVAN STATE UNIVERSITY}\\[3.5cm] 
\textsc{DAVIT M. MARTIROSYAN}\\[1.5cm] 

\textbf{{ \Large INVESTIGATION OF BOUNDED CONVEX BODIES IN $\mathbb{R}^n$ BY PROBABILISTIC METHODS}\\[1cm]} 

{Dissertation}\\[1cm] 

{By Specialty} \\
{A.01.05 ``Probability Theory and Mathematical Statistics''}
% \\[1.5cm]


% {For PhD in Mathematics}\\[2.5cm]
{For the Degree of Candidate of Physical and Mathematical Sciences}\\[3.5cm]

\hfill Scientific supervisor \\
\hfill  Doctor of Physical and Mathematical Sciences,  \\
\hfill V.K. OHANYAN 

\vfill 

{\large YEREVAN 2024}

\end{titlepage}

\setcounter{page}{2}


\begin{spacing}{1.2}
\tableofcontents{}
\end{spacing}


\chapter*{INTRODUCTION}
\addcontentsline{toc}{chapter}{INTRODUCTION} 


In the 30s of the previous century, a group of mathematicians led by W. Blaschke at the University of Hamburg embarked on a series of papers, titled "Integral Geometry", primarily aiming to explore the application of probabilistic concepts in obtaining geometrically significant results for convex bodies and in differential geometry, in general. The papers were later compiled in \cite{Blaschke}. For these details and further insights into the evolution of integral geometry and geometric probability, refer to the preface of \cite{Santalo}.

The random geometric elements that one may consider with a convex body in Euclidean space can be various, such as points, lines, hyperplanes, congruent figures, motions, etc. One of the well-known such characteristics of a convex body $D$ in $\mathbb{R}^n$ is the $n$-dimensional Lebesgue measure $L_n(\cdot)$ of the region shared between $D$ and its translated copy by a random vector $x$. The function     
 $$C_{D}(x) = L_{n}(D \cap \{D+x\}), \hspace{5pt} x \in \mathbb{R}^n,$$
 where $D+x=\{\mathcal{P}+x\,:\, \mathcal{P}\in D\}$, is called the \textbf{covariogram} of $D$. It was introduced by G. Matheron \cite{Matheron}. His hypothesis \cite{Matheron86} that the covariogram determines a convex body, among all convex bodies, up to translations and reflections, was rejected in \cite{Bianchi rejection}, for $n\geq 4$. However, the hypothesis found its confirmation earlier for the planar convex polygons \cite{Nagel}, later for all planar convex bodies \cite{Bianchi and Averkov} and for three-dimensional convex polytopes \cite{Bianchi}. The general 3-dimensional case is still open (see \cite{Schneider and Weil}, p. 375). 
 
 Over the past two decades, a team of mathematicians, under the leadership of V. Ohanyan at Yerevan State University, has contributed significantly to the field. Their collective efforts have aimed at establishing the explicit form of the covariogram for specific bodies $D \subset \mathbb{R}^n$, as well as leveraging the covariogram to compute diverse geometric probabilities. In particular, the covariograms were computed for triangles \cite{GO_Triangle}, parallelograms \cite{GO_Parallelogram}, cylinders \cite{HO_Cylinder}, and square-based parallelepipeds \cite{OAd_parallelepiped}. For covariogram-related geometric probabilities, see \cite{GO_random segment} - \cite{AO_pattern recognition}.
 
 % , \cite{AH_triangle}, \cite{AO_geometric probabilities} , and \cite{AO_pattern recognition}.

 Another random element studied in a planar convex body for recognition purposes is its chord length generated by a random line. Let $\mathbb{G}$ be the space of all lines $g$ in $\mathbb{R}^2$. Each line $g$ is determined by the angle $\varphi\in [0, 2\pi)$ that the direction perpendicular to $g$ makes with a fixed direction, and by its distance $p\in [0,+\infty)$ from the origin. We equip $\mathbb{G}$ with a measure $\mu$ invariant under Euclidean motions in $\mathbb{R}^2$. Then, up to a constant factor,    
$$\mu(X)=\int_X dg,$$
for the measurable subsets $X\subset \mathbb{G}$, where $dg=dpd\varphi$ (see \cite{Santalo}, p. 28). Let us denote by $[D]$ the set of lines that intersect the planar convex body $D$. There is a classical result (see \cite{Santalo}, p. 30) stating that the measure of $[D]$ is equal to $L$, the length of the boundary of $D$. Further, let $\chi(g)$ be the chord $g \cap D$ generated by $g\in [D]\subset \mathbb{G}$. We denote the length of the chord $\chi(g)$ by $|\chi(g)|$. The function $F_D:\mathbb{R}\rightarrow [0,\,1]$, defined by        
$$F_D(t)=\frac{1}{L}\int_{\{g\in[D]:\, |\chi(g)|\leq t \}}dg,$$
is called the \textbf{chord length distribution} function of $D$. It is known (see \cite{One more Sulanke}, p. 55) that for non-degenerated convex domains $D$, the function $F_D$ is continuous. For various classes of convex bodies this function is shown to be absolutely continuous with respect to Lebesgue measure, and a Monte Carlo simulation scheme is proposed for approximating the corresponding probability density functions (see \cite{2023}). Generally, the chord length distribution function does not characterize $D$ up to translations and reflections, even for convex polygons. Mallows and Clark \cite{Mallows and Clark} constructed two non-congruent convex polygons with the same chord length distribution. However, for some classes of polygons, there are positive results. For example, in \cite{Gates_1}, it is demonstrated how a triangle can be recognised from the odd moments of the length of random chords and how a quadrilateral can be recognised from the derivative of its chord length density. Qualitative distinctions between polygons and sets with smooth boundaries were discussed in \cite{Gates_2}.  Explicit formulas for the chord length distribution function are obtained for regular triangles in \cite{One more Sulanke}, for regular pentagons  \cite{{AO_polygons}}, and later, for regular $n$-gons, in \cite{HO_regular polygons}. The relation between the chord length distribution of an infinitely long cylinder and that of its base is considered in \cite{Hayk}. 

To enhance the information derived from the chord length distribution, a strategy involves categorizing random chords based on their direction. For any given direction $\phi=(\cos\varphi, \sin\varphi)\in \mathbb{S}^1$, where $\mathbb{S}^1$ represents the unit circle in $\mathbb{R}^2$, the focus is on the probability of a random line from $[D]$ with the direction vector $\phi$, forming a chord of length $x$ or less. This probability is termed the \textbf{orientation-dependent chord length distribution (ODCLD)} function, denoted by $F_D(x,\varphi)$. Notably, this function provides more detailed information about $D$ compared to the chord length distribution function. The latter can be imagined as an average of ODCLD function across all possible directions, explaining its lower information content. Furthermore, Matheron \cite{Matheron} demonstrated that the covariogram of $D$ encapsulates the same information about $D$ as the ODCLD function (refer to \cite{Nagel}). In simpler terms, the task of determining a convex body from its covariogram is equivalent to the challenge of determining it from its ODCLD (see \cite{Bianchi and Averkov}).

Explicit forms for the ODCLD function for triangles, ellipses, regular polygons, and parallelograms were obtained in the papers \cite{GO_Triangle}, \cite{GO_Parallelogram}, and \cite{HO_Regular Polygons and Ellipse}. Furthermore, the latter publication encompasses additional insights, including the distribution functions for cross-sectional areas of both ellipsoids and cylinders. The ODCLD functions for rectangular and trapezoid-based prisms were studied in \cite{OAd_parallelepiped}, \cite{OM1}, and \cite{K}. 
\vskip 20pt
\textit{The first chapter} of this dissertation focuses on finding an explicit representation of the ODCLD function for any right prism based on an arbitrary convex quadrilateral. The quadrilateral is closed: it contains its interior points and the boundary. After the preliminaries, Section \ref{Rectangular Parallelepiped} and Section \ref{Right prism on a right trapezoid} showcase our early discoveries \cite{OM1} regarding the ODCLD functions of a rectangular parallelepiped and a right prism based on a right trapezoid. We opt not to present the copies of results for these cases here in the introduction (specifically, Theorem \ref{theroem3_1} and Theorem \ref{theorem_5_1}) and instead concentrate solely on the outcomes related to general convex quadrilaterals and prisms based on them.   

The necessary terminology and characteristics of the quadrilateral to build the ODCLD function are provided in Section \ref{Quadrilateral}. In a Cartesian plane, for any convex quadrilateral $\textbf{D}$ there are points $B(b,0),\,b>0$, $A\in \{(x,y):\,x\geq 0, y>0\} $, and $C\in \{(x,y):\,x>0, y>0\}$ such that $\textbf{D}$ is congruent to the quadrilateral $OACB$, where $O$ is the origin of coordinates. We will call such a quadrilateral \textbf{an image} of $\textbf{D}$. The side $OB$ will be called \textbf{the base}, the sides $OA$ and $BC$ will be called \textbf{legs}, $\alpha$ and $\beta$ will stand for the inclination angles (measured anticlockwise from the positive direction of $x$-axis)  of the legs $OA$ and $BC$, respectively. If $\alpha \leq \beta$ then the quadrilateral $OABC$ will be called \textbf{a standard image} of $\textbf{D}$ (see Figure~\ref{fig:standard_image}). If $\alpha_0$ and $\beta_0$ are the inclination angles of the diagonals $OC$ and $BA$, respectively, then we use the notation $\textbf{D}_s=[b, \alpha_0, \alpha, \beta, \beta_0]$ for that standard image of $\textbf{D}$.  The values $\alpha_0, \alpha, \beta, \beta_0$ determine another parameter $\gamma$, the inclination angle of $AC$. We classify the standard images into two categories based on the value of $\gamma$. Due to convexity of $\textbf{D}$, either $0\leq \gamma<\alpha_0$, or $\beta_0<\gamma<\pi$. If the first inequality occurs, we will call the standard image to be of \textbf{Type 1}, otherwise - of \textbf{Type 2}.  


Let $l_{\varphi}$ be the subspace of $\mathbb{R}^2$ spanned by the vector $\phi=(\cos\varphi, \sin\varphi )\in \mathbb{S}^1$. By $\phi^\perp$ we denote the orthogonal complement of $l_{\varphi}$ in $\mathbb{R}^2$. For any $y\in \phi^\perp$, let $l_{\varphi}+y$ be the line parallel to $\phi$ and passing through $y$. For a bounded convex set $E\subset \mathbb{R}^2$ with non-empty interior, we denote $\chi(l_{\varphi}+y)=L_1\big((l_{\varphi}+y) \cap E\big),$ 
and, if the line $l_{\varphi}+y$ has a common segment with $E$, then we will say that it makes a chord in $E$ of length $\chi(l_{\varphi}+y)$. Look at Figure~\ref{fig:preliminary_fig_1} for a visual example.        

Let $\Pi_E(\varphi)$ be the orthogonal projection of $E$ onto $\phi^\perp$. Assuming that $y$ is uniformly distributed over $\Pi_E(\varphi)$, the ODCLD function in direction $\phi$ for $E$ is defined by  
$$
F_{E}(x,\varphi) = {\frac {L_{1}(\Pi_{E}^x (\varphi))}{b_{E}(\varphi)}},
$$
where $\Pi_{E}^x (\varphi)=\{y\in \Pi_{E}(\varphi):\chi(l_{\varphi}+y) \leq x\}$ and $b_E(\varphi)=L_1(\Pi_E(\varphi))$.

Since $l_{\varphi-\pi}=l_{\varphi}$, we can assume $\varphi \in [0,\,\pi)$. To determine the ODCLD function $F_{\textbf{D}_s}(x,\varphi)$ we use the quantities  
\vskip -5mm
$$
x_{0}(\varphi) = \min\limits_{y \in \phi_v^\perp} \chi(l_{\varphi} + y) \,\,\,\text{and}\,\,\, x_{1}(\varphi) = \max\limits_{y \in \phi_v^\perp} \chi(l_{\varphi} + y), 
$$
where $\phi_v^\perp$ is the set of vectors $y \in \phi^\perp$ so that the line $l_{\varphi} + y$ passes through a vertex of $\textbf{D}_s$ and makes a chord of positive Lebesgue measure there. The quantity $x_{1}(\varphi)$ coincides with the length of the longest chord
$$x_{\max}(\varphi)=\max\limits_{y \in \Pi_{\textbf{D}_s}(\varphi)} \chi(l_{\varphi} + y),$$
and any chord of length $x_{\max}(\varphi)$ is known as a \textbf{$\varphi$-diameter} of $\textbf{D}_s$ (see \cite{Mount}, p. 248). We extend this concept: in the upcoming text, where convenient, we will call it a \textbf{first-order $\varphi$-diameter} of $\textbf{D}_s$, and any chord of length $x_0(\varphi)$ will be called a \textbf{second-order $\varphi$-diameter} of $\textbf{D}_s$. Visual examples are shown in Figure~\ref{fig:1st_2nd_order_diameters}.

In addition to $x_0(\varphi)$ and $x_1(\varphi)$, we introduce three more orientation-dependent characteristics  $\ell_0(\varphi)$, $\ell(\varphi)$, and $\ell_1(\varphi)$ of the standard image $\textbf{D}_s=[b, \alpha_0, \alpha, \beta, \beta_0]$. These characteristics will be non-negative continuous functions and will satisfy to $b_{\textbf{D}_s} (\varphi)=\ell_0(\varphi)+\ell(\varphi)+\ell_1(\varphi)$ for all $\varphi \in [0, \pi).$ We call them \textbf{supplementary $\varphi$-measures} of $\textbf{D}_s.$ These characteristics are defined case by case in Section \ref{Quadrilateral}. For visualizations, see Figure~\ref{fig:supplementary_measures_case_1}, Figure~\ref{fig:supplementary_measures_case_2_1}, and Figure~\ref{fig:supplementary_measures_case_3}.
Readers, already familiar with the concept of X-ray (refer to Chapter 1 of \cite{Gardner}), may benefit while contemplating the origins and significance of the newly introduced orientation-dependent characteristics. To determine the ODCLD function, acquiring orientation-dependent X-rays is sufficient (see \cite{GGZ}). These X-rays, which exhibit convex functions with up to three graph pieces for a convex quadrilateral, can be accurately determined using $\varphi$-diameters and supplementary $\varphi$-measures as necessary parameters.


 The first compressed results are presented in Section \ref{ODCLD and the covariogram of a convex quadrilateral}, where the ODCLD function and the covariogram of a convex quadrilateral are found in terms of the lengths of orientation-dependent diameters and supplementary measures. 

{\bf Theorem \ref{Theorem CLD}.} \textit{Let $\textbf{D}_s$ be a standard image of a convex quadrilateral $\textbf{D}$ and $0\leq \varphi<\pi$. If $x_1, \, x_0$ are the lengths of respectively the first and the second-order $\varphi$-diameters, and $\ell_0,\, \ell,\, \ell_1$ are the supplementary $\varphi$-measures of $\textbf{D}_s$, then} 
$$
    F_{\textbf{D}_s}(x,\varphi) = \frac{1}{\ell_0+\ell+\ell_1}
    \begin{cases}
        0, & \mbox{if \, $x < 0$} \\
        \displaystyle{\bigg(\frac{\ell_0}{x_0}+\frac{\ell_1}{x_1} \bigg)x}, & \mbox{if \, $0 \leq x < x_{0}(\varphi)$} \\
        \displaystyle{\ell_0+\frac{x-x_0}{x_1-x_0}\ell + \frac{x}{x_1}\ell_1}, & \mbox{if \, $x_{0}(\varphi) \leq x < x_{1}(\varphi)$} \\
        \ell_0+\ell+\ell_1, & \mbox{if \, $x \geq x_{1}(\varphi)$}
    \end{cases}.
$$

{\bf Corollary \ref{Jump in planar case}.} \textit{The function $F_{\textbf{D}_s}(\cdot, \varphi)$ is continuous on the real axis if and only if the $\varphi$-diameter of $\textbf{D}_s$ is unique. If for some $\varphi$, the $\varphi$-diameter of $\textbf{D}_s$ is not unique then $F_{\textbf{D}_S}(\cdot, \varphi)$ holds a jump discontinuity at $x_{\max}(\varphi)$. The jump is equal to} 
$$\frac{\ell}{\ell_0+\ell+\ell_1}.$$

Below, the notation $C_{\textbf{D}_s}(t,\varphi)$ stands for the covariogram $C_{\textbf{D}_s}(t\phi)$, where $t\geq 0$.

{\bf Theorem \ref{Covariogram quadrilateral}.} \textit{Let $\textbf{D}_s$ be a standard image of a convex quadrilateral $\textbf{D}$ and $0\leq \varphi<\pi$. If $x_1, \, x_0$ are the lengths of respectively the first and the second-order $\varphi$-diameters, and $\ell_0,\, \ell,\, \ell_1$ are the supplementary $\varphi$-measures of $\textbf{D}_s$, then}
$C_{\textbf{D}_s}(t,\varphi) = $
$$
    =
    \begin{cases}
        
        \displaystyle{\frac{x_0\ell_0+(x_0+x_1)\ell+x_1\ell_1}{2}-(\ell_0+\ell+\ell_1)t+\frac{1}{2}\bigg(\frac{\ell_0}{x_0}+\frac{\ell_1}{x_1} \bigg)t^2}, & \mbox{if \, $0 \leq t < x_{0}$} \\
        \displaystyle{\frac{1}{2}\bigg(\frac{\ell_1}{x_1} + \frac{\ell}{x_1-x_0}}\bigg)(x_1-t)^2, & \mbox{if \, $x_{0} \leq t < x_{1}$} \\
        0, & \mbox{if \, $t \geq x_1$}
    \end{cases}.
    $$

All orientation-dependent computations are processed in Section \ref{Computative}.
For a standard image $\textbf{D}_s=[b, \alpha_0, \alpha, \beta, \beta_0]$, consider
$\Lambda=\{\alpha, \, \beta\}, \,\, \Delta=\{\alpha_0, \, \beta_0\}, \,\, \Sigma=\{0,\,\alpha, \, \gamma,\, \beta\},$ which are the sets of the inclination angles of the legs, diagonals, and the sides of $\textbf{D}_s$, respectively. For any $\varphi \in [0,\, \pi),$ we define the functions 
$X_{\varphi}:\Lambda \times \Delta \times \Sigma\setminus\{\varphi\} \longrightarrow \mathbb{R}$ and $L_{\varphi}:(\Lambda \times \Delta) \cup (\Delta \times \Lambda) \longrightarrow \mathbb{R}$ by
$$X_{\varphi}(x,\,y,\,z)=\frac{b\sin x \sin (y-z)}{\sin(y-x)\sin(z-\varphi)},\,\, L_{\varphi}(x,\,y)=\frac{b\sin (x-\varphi) \sin y}{\sin(x-y)}.$$

All five orientation-dependent characteristics,  $x_0(\varphi), x_1(\varphi), \ell_0(\varphi), \ell(\varphi), \ell_1(\varphi)$ are comfortably expressed by $X_{\varphi}$ and $L_{\varphi}$, see Theorems \ref{x values Type 1} - \ref{l values Type 2}. 

The last section of the first chapter is devoted to the question of finding the ODCLD function and the covariogram of a right quadrilateral prism. Denote by $\textbf{D}_{s}^h$ the right prism $\{(x,y,z): (x,y)\in \textbf{D}_s,\, 0 < z \leq h\}$, where $\textbf{D}_s$ is a standard image of a convex quadrilateral. For a vector 
$\omega =(\cos\varphi\cos\theta,\,\sin\varphi\cos\theta,\,\sin\theta) \in \mathbb{S}^2,$
 let $\omega^\perp$ be the orthogonal complement of $\{t\omega\,:\, t\in \mathbb{R}\}$ in $\mathbb{R}^3$, and $\Pi_{\textbf{D}_s^h}(\varphi, \theta)$ be the orthogonal projection of $\textbf{D}_s^h$ onto the plane $\omega^\perp$.

We define the chord length distribution function in direction $\omega$ for $\textbf{D}_s^h$ by 
$$
F_{\textbf{D}_s^h}(t,\varphi,\theta) = {\frac {L_{2}\{y\in \Pi_{\textbf{D}_s^h}(\varphi, \theta):\chi(l_{(\varphi, \theta)}+y) \leq t\}}{b_{\textbf{D}_s^h}(\varphi, \theta)}},
$$   
where $l_{(\varphi, \theta)}+y$ is the line that passes through $y\in \omega^\perp$ and has direction vector $\omega$, 
$$\chi(l_{(\varphi, \theta)}+y) = L_{1}\big((l_{(\varphi, \theta)}+y\big) \cap \textbf{D}_s^h),$$
and
$$b_{{\textbf{D}}_s^h}(\varphi, \theta)=L_2(\Pi_{\textbf{D}_s^h}(\varphi, \theta)).$$

As $\{z\in \mathbb{R}^3:\,\,z=\frac{h}{2}\}$ is a plane of symmetry of $\textbf{D}_s^h$, we notice that  
$F_{\textbf{D}_s^h}(t,\varphi,\theta)=F_{\textbf{D}_s^h}(t,\varphi-\pi,\theta), \,\,\text{for}\,\,\varphi\in [\pi, 2\pi)$ and
$F_{\textbf{D}_s^h}(t,\varphi,\theta)=F_{\textbf{D}_s^h}(t,\varphi,-\theta).$
Based on this observation, we will assume that $\varphi\in [0,\,\pi)$ and $\theta\in [0,\,\frac{\pi}{2}]$. 

Let $\|\textbf{D}_s\|$ be the area of $\textbf{D}_s$.
Denote
\vskip -8mm
$$x_{\max}(\varphi, \theta) = \max\limits_{y \in \Pi_{\textbf{D}_s^h}(\varphi, \theta)} \chi(l_{(\varphi, \theta)}+y).$$

 {\bf Theorem \ref{Theorem CLD prism}.} \textit{For a $\varphi\in [0,\,\pi)$, let $x_1$ and $x_0$ be the lengths of the first and the second-order $\varphi$-diameters of $\textbf{D}_s$, respectively. Let $\ell_0,\, \ell,\, \ell_1$ be the supplementary $\varphi$-measures of $\textbf{D}_s$, and denote $b_{\textbf{D}_s}=\ell_0+\ell+\ell_1$. Then, for the direction $\omega =(\cos\varphi\cos\theta,\,\sin\varphi\cos\theta,\,\sin\theta), \,0\leq\theta\leq \frac{\pi}{2}$ and the prism $\textbf{D}_{s}^h$, the following statements take place:}
 
\textit{\textbf{(a)} If $\tan^{-1}\frac{h}{x_0}<\theta\leq\frac{\pi}{2}$ and $0\leq t < x_{\max}(\varphi, \theta)$, or $0\leq\theta\leq\tan^{-1}\frac{h}{x_0}$ and $0\leq t<x_{0}\sec\theta$, then} 
    $$
    F_{\textbf{D}_s^h}(t,\varphi,\theta) =\frac{a_1t+a_2t^2}{\|\textbf{D}_s\|\sin\theta+b_{\textbf{D}_s}h\cos\theta},
$$
\textit{where} 
$$a_1=h\bigg(\frac{\ell_0}{x_0}+\frac{\ell_1}{x_1}\bigg)\cos^2\theta+b_{\textbf{D}_s}\sin2\theta,\,\,\,a_2=-\frac{3}{2}\bigg(\frac{\ell_0}{x_0}+\frac{\ell_1}{x_1}\bigg)\sin\theta\cos^2\theta;$$
\vskip 10pt
\textit{\textbf{(b)} If $0\leq\theta\leq\tan^{-1}\frac{h}{x_0}$ and $x_{0}\sec\theta\leq t<x_{\max}(\varphi, \theta)$, then $x_0<x_1$ and } 
 $$   
    F_{\textbf{D}_s^h}(t,\varphi,\theta) =\frac{c_0+c_1t+c_2t^2}{\|\textbf{D}_s\|\sin\theta+b_{\textbf{D}_s}h\cos\theta},
$$
 \textit{where}
 $$c_0=(h\cos\theta+\frac{x_0}{2}\sin\theta)\bigg(\ell_0-\frac{\ell x_0}{x_1-x_0}\bigg),$$
$$c_1=(h\cos^2\theta+x_1\sin2\theta)\bigg(\frac{\ell}{x_1-x_0}+\frac{\ell_1}{x_1}\bigg),\,\,\,c_2=-\frac{3}{2}\sin\theta\cos^2\theta\bigg(\frac{\ell}{x_1-x_0}+\frac{\ell_1}{x_1}\bigg).$$
 
 {\bf Corollary \ref{Jump suface}.} \textit{Let}
 $$\mu(\varphi, \theta)=L_2\bigg(\{y\in \Pi_{\textbf{D}_s^h}(\varphi, \theta):\chi(l_{(\varphi, \theta)}+y) = x_{max}(\varphi, \theta)\}\bigg).$$
 \textit{The function $F_{\textbf{D}_s^h}(\cdot, \varphi, \theta)$ is continuous on the real axis if and only if $\mu(\varphi, \theta)=0$. Otherwise, if $\mu(\varphi, \theta)>0$ for some pair $(\varphi,\theta)$, then $F_{\textbf{D}_s^h}(\cdot, \varphi,\theta)$ has a jump discontinuity at $x_{\max}(\varphi, \theta)$. The jump is equal to}
 $$\frac{\mu(\varphi, \theta)}{\|\textbf{D}_s\|\sin\theta+b_{\textbf{D}_s}h\cos\theta}.$$

 To visualize the possible breaks in continuity and smoothness of the ODCLD function, we plotted the function $z(t,h)=F_{\textbf{D}_s^h}(t,\varphi,\theta)$ for a given pair $(\varphi, \theta)$ and different values of the height $h$. Examples are demonstrated by Figure~\ref{fig:FIGURE1} and Figure~\ref{fig:FIGURE2}.

 {\bf Theorem \ref{Theorem covariogram prism}.} \textit{For a $\varphi\in [0,\,\pi)$, let $x_1$ and $x_0$ be the lengths of the first and the second-order $\varphi$-diameters of $\textbf{D}_s$, respectively. Let $\ell_0,\, \ell,\, \ell_1$ be the supplementary $\varphi$-measures of $\textbf{D}_s$, and denote $b_{\textbf{D}_s}=\ell_0+\ell+\ell_1$. Then, for the direction $\omega =(\cos\varphi\cos\theta,\,\sin\varphi\cos\theta,\,\sin\theta), \,0\leq\theta\leq \frac{\pi}{2}$, the covariogram $C_{\textbf{D}_s^h}(t\omega)=C_{\textbf{D}_s^h}(t, \varphi, \theta)$ of the prism $\textbf{D}_{s}^h$ has the following representation:}

 
\textit{\textbf{(a)} If $\tan^{-1}\frac{h}{x_0}<\theta\leq\frac{\pi}{2}$ and $0\leq t < x_{\max}(\varphi, \theta)$, or $0\leq\theta\leq\tan^{-1}\frac{h}{x_0}$ and $0\leq t<x_{0}\sec\theta$, then}
    $$
    C_{\textbf{D}_s^h}(t,\varphi,\theta) =\bigg(\|\textbf{D}_s\|-b_{\textbf{D}_s}\cos\theta\cdot t+\frac{1}{2}\bigg(\frac{\ell_0}{x_0}+\frac{\ell_1}{x_1}\bigg)\cos^2\theta\cdot t^2\bigg)(h-\sin\theta \cdot t);$$
\vskip 10pt
    \textit{\textbf{(b)} If $0\leq\theta\leq\tan^{-1}\frac{h}{x_0}$ and $x_{0}\sec\theta\leq t<x_{\max}(\varphi, \theta)$, then $x_0<x_1$ and}
 $$
    C_{\textbf{D}_s^h}(t,\varphi,\theta) =\frac{1}{2}\bigg(\frac{\ell}{x_1-x_0}+\frac{\ell_1}{x_1}\bigg)(x_1-\cos\theta\cdot t)^2(h-\sin\theta \cdot t).
$$

\vskip 15pt

Besides the basic characteristics of a planar convex body $D$, such as the perimeter $L$ and area $F$, which remain invariant under rigid motions, the integral geometry notions, such as the chord length distribution, the moments of the chord length, the distribution of the distance between two random points in $D$, etc. also contain some special information about $D$. For example, Blaschke's research \cite{Blaschke}, mentioned at the beginning of this introduction, particularly dealt with the sequence of chord length moments $I_k=\int_{[D]}|\chi(g)|^kdg, \,\,k=0, 1, 2, \dots$, where the measure element $dg$ is interpreted as $dg=dp d\varphi$, where $dp$ is the one-dimensional Lebesgue measure and $d\varphi$ is the uniform measure on the unit circle. He proposed the problem of finding necessary and sufficient conditions for a sequence of real numbers to be the sequence $I_k$ associated with a convex set and of determining, when those conditions are satisfied, whether or not the corresponding convex set is unique (see \cite{Santalo}, p. 48).

Another invariant, $U=\int_{g_1\cap g_2\in D}u(g_1, g_2)dg_1dg_2$, where $\chi(g)=g\cap D$ is the chord in $D$ produced by the line $g$, and $u(g_1, g_2)$ denotes the perimeter of the convex quadrilateral verticed at the points of intersections of the lines $g_1$ and $g_2$ with the boundary $\partial D$, was considered in \cite{Santalo}, chapter 4. It was in the context of finding the probabilities $p_{3k}$, $0\leq k \leq 3$, of three random lines producing $k$ intersection points inside $D$, given all three lines meet $D$.

Generally, let us consider $N_n$, the number of intersection points of $n$ random lines in $D$, given that all $n$ lines meet $D$, and denote $p_{nk}=\mathbb{P}(N_n=k)$. It is easy to obtain $p_{21}=\frac{2\pi F}{L^2}$ (see \cite{Santalo}, p. 53). The formulas for intersection probabilities $p_{3k}$, suggested in \cite{Santalo}, p. 65, contain a mistake. The correct formulas are  
\begin{equation}\tag{\ref{p_{3k}}}
    p_{33}=\frac{8I_2-U}{L^3},\,p_{32}=\frac{3U-12I_2}{L^3}, \, p_{31}=\frac{6\pi FL-3U}{L^3},
\end{equation}
established earlier by R. Sulanke in \cite{Sulanke}. These formulas imply
\begin{equation}\tag{\ref{I_2 and U in terms of prob}}
    I_2=\frac{L^3}{12}(p_{32}+3p_{33}),\,\,\,\,U=\frac{L^3}{3}(2p_{32}+3p_{33}).
\end{equation}

We consider this relationship between geometric and probabilistic characteristics of $D$ from the following perspective. Formulas \eqref{p_{3k}} indicate that if $D$ has a "good" shape, it allows for the determination of intersection probabilities. Conversely, from \eqref{I_2 and U in terms of prob}, we infer that if the intersection probabilities are known statistically, one can evaluate the invariants $F$, $I_2$, and $U$.

Motivated by this objective, the \textit{second chapter} of this dissertation is dedicated to deriving explicit formulas for probabilities $p_{4k}$, where $k=1,2, ..., 6$, expressed in terms of newly defined invariants of $D$. Additionally, we establish an analogue of \eqref{I_2 and U in terms of prob} for these invariants. To achieve this, we employed Ambartzumian's combinatorial algorithm (see \cite{Ambartzumian_1}, chapter 5 and \cite{Ambartzumian_2}). Before presenting the main outcomes, we adapted the combinatorial algorithm to the specific context, as detailed in Section \ref{Combinatorial Algorithm}. Towards the end of the section, we effortlessly reproduce all the formulas in \eqref{p_{3k}} using the developed method.

We introduced the new invariants in Section \ref{New invariants} and computed $p_{46}$ and $p_{45}$. 


{\bf Definition \ref{definition new invariants}.}
\textit{For any $g_1\cap g_2\in D$ we define}
$$d(g_1, g_2)=|\chi(g_1)|+|\chi(g_2)|, \,\,\,\, c(g_1, g_2)=\mu \big([\chi(g_1)]\cap[\chi(g_2)]\big),$$
$$u(g_1, g_2)=\big|\partial\big(conv\big(\cup_{i=1}^2g_i\cap D\big)\big)\big|,$$
\textit{and for any three lines $g_1, g_2, g_3$ such that $g_i\cap g_j\in D$, $1\leq i<j\leq 3$ we define}
$$v(g_1, g_2, g_3)=\big|\partial\big(conv\big(\cup_{i=1}^3g_i\cap D\big)\big)\big|,$$
\textit{where $conv(X)$ denotes the convex hull of $X\subset\mathbb{R}^2$, and $|\partial Y|$ denotes the perimeter of a convex domain $Y$.}

The new definition of $u(g_1, g_2)$ coincides with the one we have used so far.

Along with the well-known invariants $I_k=\int_{[D]}|\chi(g)|^kdg, \,\,k=0, 1, 2, \dots$ let's consider the following moments of the functions introduced in Definition~\ref{definition new invariants}. 
$$
\begin{aligned}
    D_k &=\int_{g_1\cap g_2 \in D}d^k(g_1, g_2)dg_1dg_2,\,\,\,\,
    C_k=\int_{g_1\cap g_2 \in D}c^k(g_1, g_2)dg_1dg_2, \\
    U_k &=\int_{g_1\cap g_2 \in D}u^k(g_1, g_2)dg_1dg_2,\,\,\,\, 
    V_k =\int_{g_i\cap g_j \in D,\,1\leq i<j\leq3}v^k(g_1, g_2, g_3)dg_1dg_2dg_3.
    \end{aligned}
$$

 {\bf Theorem \ref{p_46 and p_45}.}

   $$ p_{46}=\frac{3U_2+9C_2-12D_2+4V_1}{4L^4}, \,\,\,  p_{45}=\frac{36D_2-9U_2-15C_2-12V_1}{2L^4}. $$

   The remaining probabilities $p_{4k}$, $k\leq 4$ are computed in Section \ref{The rest of probabilities}. 
   Given $g_1\cap g_2 \in D$, we denote by $\rho_1,\rho_2, \rho_3, \rho_4$ the lengths of four consecutive sides of the quadrilateral $conv\big((g_1\cup g_2)\cap \partial D\big)$. To avoid ambiguity, we will always assume that the first two sides lie in different half-planes with respect to $g_1$. If two lines, e.g. $g_2$ and $g_3$, are from $[D]$ but do not meet inside $D$, then $d_1, d_2$ will stand for the lengths of the diagonals of $conv\big((g_2\cup g_3)\cap \partial D\big)$, and $s_1, s_2$ will represent the lengths of the sides of the quadrilateral which are different from $\chi(g_2), \chi(g_3)$.

   The new notation is illustrated in the Figure~\ref{fig:FIG1}. Those are used to define the following new invariants of $D$:     
$$R=\int_{g_1\cap g_2 \in D}\big((\rho_1+\rho_2)(\rho_3+\rho_4)+(\rho_2+\rho_3)(\rho_4+\rho_1)\big)dg_1dg_2,$$

$$Q_s=\int_{g_2\cap g_3 \not\in D}(s_1+s_2)(d_1+d_2-s_1-s_2)dg_2dg_3,$$

$$Q_d=\int_{g_2\cap g_3 \not\in D}(d_1+d_2)(d_1+d_2-s_1-s_2)dg_2dg_3.$$


{\bf Theorem \ref{theorem for p44}.}
\textit{Let $p_{44}^{(1)}$ be the probability that $g_1, g_2, g_3, g_4\in [D]$ produce 4 intersection points inside $D$ and some three of them intersect each other inside $D$. Then} $p_{44}=p_{44}^{(1)}+p_{44}^{(2)},$
\textit{where} 
$$
p_{44}^{(1)}=\frac{6}{L^4}(2V_1-4D_2+C_2+U_2), \,\,\, \textit{and}\,\,\,\, p_{44}^{(2)}=\frac{3}{L^4}\bigg(\frac{3U_2+C_2}{2}-8I_3-2R-Q_s\bigg).
$$

Three intersection points made by four lines from $[D]$ can occur in three ways:\\ 
Event 1: The lines produce three chords each possessing two intersection points, and one containing no intersection point;\\
Event 2: The lines produce two chords each possessing 2 intersection points, and the other two each possessing 1 intersection point;\\
Event 3: The lines produce three chords each possessing 1 intersection point, and one possessing 3 intersection points.   

We denote by $p_{43}^{(1)},\, p_{43}^{(2)},\, p_{43}^{(3)}$ the probabilities of Event 1, Event 2, and Event 3, respectively. 


{\bf Theorem \ref{theorem for p43}.}
$$p_{43}=p_{43}^{(1)}+ p_{43}^{(2)}+p_{43}^{(3)},$$  
\textit{where} 

$$p_{43}^{(1)}=\frac{4}{L^4}(C_1L-V_1),\,\,\, p_{43}^{(2)}=\frac{12}{L^4}(Q_s+2R-U_2),$$

$$
p_{43}^{(3)}=\frac{3}{L^4}(C_2-4D_2-U_2)+\frac{4}{L^4}(Q_d+2R)+\frac{64}{L^4}I_3.
$$

Two intersection points generated by four lines are possible in two scenarios:\\ 
Event 1: One chord possesses 2 intersection points,  two of the chords possess 1 intersection point each, and one chord does not possess any intersection point;\\
Event 2: Each chord of the four lines possesses exactly 1 intersection point. \\  
Let the probabilities of the above mentioned events be $p_{42}^{(1)}$ and $p_{42}^{(2)}$, respectively.  

{\bf Theorem \ref{theorem for p42}.}
$$p_{42}=p_{42}^{(1)}+ p_{42}^{(2)},$$  
\textit{where} 
$$
p_{42}^{(1)}=4p_{32}-\frac{3}{L^4}\big(C_2-4D_2-U_2-4(Q_s+2R)\big),
$$

$$
p_{42}^{(2)}=\frac{12\pi^2F^2}{L^4}+\frac{48I_3}{L^4}-\frac{3}{4L^4}\big(U_2-C_2+12D_2\big)-\frac{1}{4}\big(p_{44}^{(1)}+2p_{43}^{(2)}\big).
$$

 {\bf Theorem \ref{theorem for p41}.}
\begin{equation*} \label{p41}
p_{41}=2p_{31}-2p_{42}^{(2)}-\frac{6U_1}{L^3}+\frac{6U_2}{L^4}.
\end{equation*}

Finally, the probability of having no intersection points inside $D$ is $p_{40}=1 - \displaystyle{\sum_{k=1}^6}p_{4k}$. 

In Section \ref{I_3 and V_1 expressions}, we expressed the invariants $V_1$ and $I_3$ by intersection probabilities to establish an analogue of \eqref{I_2 and U in terms of prob}. $I_3$ is found by Crofton \cite{Crofton} (see also \cite{Santalo}, p. 47) to be equal to $3F^2$ but we did not need it below.  
  

{\bf Theorem \ref{I3 and V1}.}
The following identities hold:
$$
    V_1=L^4\big(p_{33}-\frac{1}{4}p_{43}^{(1)}\big),\,\,\,  I_3=\frac{L^4}{32}\big(4p_{33}+p_{43}^{(3)}-p_{43}^{(1)}\big).
$$

The formulas obtained for intersection probabilities motivated us to compute invariants of $D$ through simulations. For example, we used Python 3 software to approximate the values of $I_2, U_1, I_3,$ and $V_1$ for the unit disk. Simulations code can be found here: \url{http://rb.gy/1wei7h}.

Expressions of all the new invariants in terms of $r$ for a disc of radius $r$ are established in Section \ref{disc probabilities}. As a result, the following result is proved.


{\bf Theorem \ref{Probabilities for a disc}.}
\textit{If $D$ is a disc with radius $r$ then}
$$p_{46}=\frac{1}{4}-\frac{17}{8\pi^2},\,\,\,\,p_{45}=\frac{29}{8\pi^2} -\frac{1}{4},$$
$$p_{44}=\frac{43}{4\pi^2} -\frac{7}{8}, \,\,p_{44}^{(1)}=\frac{23}{2\pi^2} -1,\,\, p_{44}^{(2)}=\frac{1}{8}-\frac{3}{4\pi^2},$$
$$p_{43}=1-\frac{29}{4\pi^2},\,\,p_{43}^{(1)}=\frac{23}{4\pi^2} -\frac{1}{2},\,\, p_{43}^{(2)}=1-\frac{35}{4\pi^2}, \,\, p_{43}^{(3)}=\frac{1}{2}-\frac{17}{4\pi^2},$$
$$p_{42}=\frac{7}{4}-\frac{121}{8\pi^2}, \,\, p_{42}^{(1)}=\frac{3}{2} -\frac{13}{\pi^2},\,\, p_{42}^{(2)}=\frac{1}{4}-\frac{17}{8\pi^2},$$
$$p_{41}=\frac{29}{8\pi^2}-\frac{1}{4},\,\,\,\,p_{40}=\frac{13}{2\pi^2} -\frac{5}{8}.$$

\vskip 15pt

For a bounded set $\mathbb{D}\subset \mathbb{R}^d$, consider the Euclidean distance between two random points chosen independently and uniformly from $\mathbb{D}$. This is another well-known random variable studied in geometric probability (see, \cite{Santalo}, chapter 4). We denote it by  $D_d(\mathbb{D})$. 

Extensive research has been conducted on this random variable for various bounded sets $\mathbb{D}$, including computation of the average distance within a cube \cite{RobbinsBolis} (known as Robbins constant), on the surface of a cube \cite{BaileyBorweinCrandall}, within a hyperball \cite{BurgstallerPillichshammer}, as well as bounding the average distance within a hypercube \cite{AnderssenBrentDaleyMoran} or furthermore, within compact subsets of $\mathbb{R}^d$ with unit diameter \cite{BurgstallerPillichshammer}. The results known for a cube were extended to the 4th and 5th dimensions \cite{Philip} but for higher dimensions the increase of algebraic complexity associated with derivation procedures was a strong limiting factor.  In dimensions $d\leq 3$, closed-form expressions are obtained for the probability density function (PDF) of $D_d(\mathbb{D})$ in \cite{MathaiMoschopoulosPederzoli_Italiano} - \cite{OhanyanKhalatyan} 
% \cite{MathaiMoschopoulosPederzoli}, \cite{Aharonyan}, \cite{AharonyanOhanyan}, \cite{AK_distance}, 
for numerous geometric shapes of $\mathbb{D}$. For $d$-dimensional convex bodies, a relation between integrals for the powers of $D_d(\mathbb{D})$ and random chord length in $\mathbb{D}$ is well known (see, \cite{Santalo}, pp. 46-47). A relation between the chord length distribution function of $\mathbb{D}$ and the distribution function of $D_d(\mathbb{D})$, also a relation between conditional moments of $D_d(\mathbb{D})$ and random chord length in $\mathbb{D}$ are studied in \cite{Aramyan1} and \cite{Aramyan2}. A unified approach for determining the PDF of $D_d(\mathbb{D})$ for typical compact sets is suggested in \cite{LelloucheSouris}. It also provides a good list of references for related results of theoretical and applied character.

Along with $D_d(\mathbb{D})$, let us consider the covariogram of $\mathbb{D}$, denoted by $C_{\mathbb{D}}(\boldsymbol{t})$, where $\boldsymbol{t}\in \mathbb{R}^d$. When $\mathbb{D}$ is a bounded convex body in $\mathbb{R}^d$, then the two considered characteristics of $\mathbb{D}$ are interrelated as follows:
 \begin{equation}\tag{\ref{Ohanyan, Khalatyan intro}}
f_{D_d(\mathbb{D})}(h)=\frac{h^{d-1}}{L_{d}^{2}(\mathbb{D})} \int_{\mathbb{S}^{d-1}} C_{\mathbb{D}}(h\boldsymbol{u}) d \boldsymbol{u}, \,\, h>0,
 \end{equation}
where $\mathbb{S}^{d-1}$ is the $(d-1)$-dimensional unit sphere in $\mathbb{R}^d$, centered at the origin, and $L_d(\mathbb{D})$ is Lebesgue $d$-measure of $\mathbb{D}$.

\textit{In the third chapter} of this dissertation, we extended the concepts of covariogram $C_{\mathbb{D}}$ and interpoint distance $D_d(\mathbb{D})$ from bounded convex bodies to the entire space $\mathbb{R}^d$ and established a relation between them.

The first problem that arises in our way is the nature of randomness of choosing a point from $\mathbb{D}=\mathbb{R}^d$. The uniform distribution is no longer applicable to this case and therefore we naturally replace it with a multivariate normal distribution.  

 The second obstacle lies in the challenge of applying the language and sense of geometry to define the covariogram of $\mathbb{R}^d$. We will define it analytically based on the following observation. If $\mathbb{D}$ is a convex body and $\mathcal{P}_1$, $\mathcal{P}_2$ are chosen uniformly and independently from $\mathbb{D}$, then it is easy to check (see \cite{OhanyanKhalatyan}) that
 $$f_{\mathcal{P}_1-\mathcal{P}_2}(\boldsymbol{t})= \frac{C_{\mathbb
     {D}}(\boldsymbol{t})}{L_d^2(\mathbb{D})},$$    
which can be equivalently written as
 \begin{equation}\tag{\ref{Equivalent to Difference and covariogram}}
     f_{\mathcal{P}_1-\mathcal{P}_2}(\boldsymbol{t})= \frac{C_{\mathbb
     {D}}(\boldsymbol{t})}{C_{\mathbb
     {D}}^2(\boldsymbol{0})}.
 \end{equation}
Thus, the covariogram should be a positive function defined on the entire space that satisfies \eqref{Equivalent to Difference and covariogram}.

If $\textbf{X}$ is a $d$-variate normal random vector having mean $\boldsymbol{\mu}$ and covariance matrix $\boldsymbol{\Sigma}$ then we will denote this condition by $\boldsymbol{X}\sim N_d (\boldsymbol{\mu}, \boldsymbol{\Sigma}).$  
We denote $\boldsymbol{\lambda}=[\lambda_1, \lambda_2, ..., \lambda_d]^T$, where $\lambda_1\geq \lambda_2 \geq ...\geq \lambda_d >0$ are the eigenvalues of $\boldsymbol{\Sigma}$. We assume $\boldsymbol{\mu}=\boldsymbol{0}$ and the diagonal of $\boldsymbol{\Sigma}$ consisting of 1s. If $\boldsymbol{X_1, X_2}\sim N_d (\boldsymbol{0}, \boldsymbol{\Sigma})$ are independent, we denote $D_d=\|\boldsymbol{X_1}-\boldsymbol{X_2}\|,$ where $\|\cdot\|$ is the Euclidean norm in $\mathbb{R}^d$.

In section \ref{D_d density}, we independently addressed the scenario of uncorrelated coordinates and deduced the density and moments of the interpoint distance, drawing upon a result obtained in \cite{MathaiProvost}, p. 95. We easily established that (see Theorem \ref{Theorem 2.2})) if $\boldsymbol{\Sigma}=\boldsymbol{I}_d$ then $D_d\sim GG(2,d,2)$, where $\boldsymbol{I}_d$ is the identity $d\times d$ matrix, and $GG(a,d,p)$ is the generalized Gamma distribution (see \cite{Stacy}). Since the moments of the generalized Gamma distribution were known (see \cite{JohnsonKotzBalakrishnan}, section 17.8.7), as a corollary, for moments of $D_d$, we immediately concluded that if $\boldsymbol{\Sigma}=\boldsymbol{I}_d$, then 
$$
     \mathbb{E}\left(D_d^{r}\right)=2^{r} \frac{\Gamma\left(\frac{d+r}{2}\right)}{\Gamma\left(\frac{d}{2}\right)},\, r=0, 1, 2, ...\,\,.
$$ 
These findings don't claim to be new; they were observed in a longer proof presented in an arXiv paper \cite{arXiv}.

In general, when $\boldsymbol{\Sigma}\neq \boldsymbol{I}_d$, even when $d=2$, this method becomes impractical because of the demanding computations associated with complicated recursive formulas. In section \ref{Integral repr of D_d}, we established new results, including integral representations for the distribution and density functions of the Euclidean distance between two $d$-dimensional Gaussian points, characterized by correlated coordinates through a covariance matrix. 


{\bf Theorem \ref{Ellipse}.}
\textit{Let $F_{D_d}(\boldsymbol{\Sigma}, \cdot)$ be the distribution function of $D_d$ and $\mathcal{E}_d(\boldsymbol{\lambda}, R)$ be the ellipsoid}
$$\{\boldsymbol{y}=[y_1, y_2, ..., y_d]^T: \,\lambda_1 y_1^2+\lambda_2 y_2^2+...+\lambda_d y_d^2\leq R^2\}.$$
\textit{Then}
    $$
    F_{D_d}(\boldsymbol{\Sigma}, R)=\frac{1}{(2\sqrt{\pi})^d}\int_{\mathcal{E}(\boldsymbol{\lambda}, R)}\exp\bigg({-\frac{1}{4}\boldsymbol{y}^T\boldsymbol{y}}\bigg)d\boldsymbol{y}, \,\,R>0.
$$


{\bf Corollary \ref{Corollary}.}
   \textit{The probability density function of $D_d$ is representable as follows:}
$$
    f_{D_d}(\boldsymbol{\Sigma}, R)=\frac{R^{d-1}}{(2\sqrt{\pi})^d |\boldsymbol{\Sigma}|^{1/2}} \int_{\mathbb{S}^{d-1}}\exp\bigg(-\frac{R^2}{4}\boldsymbol{u}^T\boldsymbol{\Sigma}^{-1}\boldsymbol{u}\bigg)d\boldsymbol{u}.
$$

As an application of the obtained integral representations, in section \ref{applications}, we determined the probability density function of the Euclidean distance between two bivariate Gaussian points in the case when there is an inter-coordinate correlation $\rho$. 

{\bf Theorem \ref{Case d=2}.}
  \textit{If} $\boldsymbol{\Sigma}=
\begin{bmatrix} 
1 & \rho \\
\rho & 1 
\end{bmatrix},
$
\textit{then}
$$f_{D_2}(\boldsymbol{\Sigma}, R)=\frac{Re^{-\frac{R^2}{4|\boldsymbol{\Sigma}|}}}{2\sqrt{\bold{|\Sigma}|}}I_0 \bigg(\ \frac{\rho R^2}{4|\boldsymbol{\Sigma}|} \bigg),$$
\textit{where} $$
I_{0}(x)=1+\sum_{k=1}^{\infty} \frac{x^{2 k}}{((2 k) ! !)^{2}}
$$ \textit{is the modified  Bessel function of the first kind of order zero.} 

As another application, we established lower and upper bounds for the moments of $D_d$ in terms of the largest and the smallest eigenvalues of the covariance matrix.


{\bf Theorem \ref{Moments bounds}.}
   \textit{Let $\mathbb{E}\left(D_d^{r}\right)$ be the $r$-th moment of $D_d$. Then}
        $$
        \frac{2^r\Gamma\big(\frac{d+r}{2}\big)}{\Gamma\big(\frac{d}{2}\big)}\frac{\lambda_d^{\frac{d+r}{2}}}{|\boldsymbol{\Sigma}|^{1/2}}\leq \mathbb{E}\left(D_d^{r}\right) \leq \frac{2^r\Gamma\big(\frac{d+r}{2}\big)}{\Gamma\big(\frac{d}{2}\big)}\frac{\lambda_1^{\frac{d+r}{2}}}{|\boldsymbol{\Sigma}|^{1/2}},\, r=0, 1, 2, ...\,\,.
        $$
 Finally, in section \ref{NormCov}, we defined the normal covariogram of $\mathbb{R}^d$ and established an analogous relationship to \eqref{Ohanyan, Khalatyan intro}, with the foundational basis of the proof presented in section \ref{Integral repr of D_d}.


 {\bf Definition \ref{Definition of normal covariogram}.}
    \textit{Let $\mathcal{P}_1, \,\mathcal{P}_2 \sim N_d (\boldsymbol{0},\, \boldsymbol{\Sigma})$ be independent and $f_{\mathcal{P}_1-\mathcal{P}_2}$ be the probability density function of $\mathcal{P}_1-\mathcal{P}_2$. The function $C_{\boldsymbol{\Sigma}}: \mathbb{R}^d \rightarrow (0, \,+\infty)$ that satisfies to} 
    $$f_{\mathcal{P}_1-\mathcal{P}_2}(\boldsymbol{t})= \frac{C_{\boldsymbol{\Sigma}}(\boldsymbol{t})}{C_{\boldsymbol{\Sigma}}^2(\boldsymbol{0})},$$
    \textit{will be called the normal covariogram of $\mathbb{R}^d$ associated with $\boldsymbol{\Sigma}$.}

Taking into account \eqref{Ohanyan, Khalatyan intro}, the following theorem argues that the normal covariogram naturally extends the concept of covariogram.
     

{\bf Theorem \ref{Confirm sigma covariogram}.}
\textit{Let $\boldsymbol{\Sigma}$ be the covariance matrix of a non-singular $d$-variate normal distribution and $C_{\boldsymbol{\Sigma}}$ be the normal covariogram of $\mathbb{R}^d$ associated with $\boldsymbol{\Sigma}$. Then}
$$
   C_{\boldsymbol{\Sigma}}(\boldsymbol{t})=(2\sqrt{\pi})^d |\boldsymbol{\Sigma}|^{1/2}\exp\bigg(-\frac{1}{4}\boldsymbol{t}^T\boldsymbol{\Sigma}^{-1}\boldsymbol{t}\bigg), \, \boldsymbol{t}\in \mathbb{R}^d
$$
\textit{and}
  $$
      f_{D_d}(\boldsymbol{\Sigma}, R)=\frac{R^{d-1}}{C_{\boldsymbol{\Sigma}}^2(\boldsymbol{0})} \int_{\mathbb{S}^{d-1}} C_{\boldsymbol{\Sigma}}(R\boldsymbol{u}) d \boldsymbol{u}, \,\,R>0.
  $$  


{\bf Remark \ref{Remark on naturalness}.}
   \textit{It is remarkable that $C_{\boldsymbol{I}_d}(\boldsymbol{t})=(2\sqrt{\pi})^d\exp\big(-\frac{1}{4}\|\boldsymbol{t}\|^2\big)$. This illustrates that if $\mathbb{R}^d$ is considered as a space of points with uncorrelated coordinates then the covariogram of the space is naturally independent on the direction of translation.}

\vskip 15pt
All the main results presented in this dissertation can be found in papers \cite{OM1} - \cite{OM4}.
% \cite{OM2}, \cite{M3}, and
\vskip 15pt
I would like to express my sincere gratitude to my scientific advisor, Prof. Victor Ohanyan, for their guidance and support throughout the research process. 
\newpage

\chapter{ORIENTATION-DEPENDENT CHORD LENGTH DISTRIBUTION\\ (ODCLD) IN A RIGHT CONVEX QUADRILATERAL PRISM}

\section{Preliminaries}\label{Preliminaries 1}
Hereinafter, the abbreviation ODCLD will be used for "orientation-dependent chord length distribution". Terms "bounded convex body" and "convex body" will be used interchangeably referring to bounded convex sets with non-empty interior. We denote by $\mathbb{S}^n$ the unit sphere in $\mathbb{R}^{n+1}$, centered at the origin. $L_{n}(\cdot)$ will stand for the Lebesgue measure in $\mathbb{R}^n$. For a bounded convex body $D\subset \mathbb{R}^n$, the function    
\vskip -5mm
 $$C_{D}(x) = L_{n}(D \cap \{D+x\}), \hspace{5pt} x \in \mathbb{R}^n,$$ where $D+x=\{\mathcal{P}+x\,:\, \mathcal{P}\in D\}$, will be called the \textbf{covariogram} of $D$.

 Let $l_{\varphi}$ be the subspace of $\mathbb{R}^2$ spanned by the vector $\phi=(\cos\varphi, \sin\varphi )\in \mathbb{S}^1$. By $\phi^\perp$ we denote the orthogonal complement of $l_{\varphi}$ in $\mathbb{R}^2$. For any $y\in \phi^\perp$, let $l_{\varphi}+y$ be the line parallel to $\phi$ and passing through $y$. For a convex body $E\subset \mathbb{R}^2$, we denote $$\chi(l_{\varphi}+y)=L_1\big((l_{\varphi}+y) \cap E\big),$$ 
and, if the line $l_{\varphi}+y$ has a common segment with $E$, then we will say that it makes a chord in $E$ of length $\chi(l_{\varphi}+y)$. Look at Figure~\ref{fig:preliminary_fig_1} for a visual example.        

Let $\Pi_E(\varphi)$ be the orthogonal projection of $E$ onto $\phi^\perp$. Assuming that $y$ is uniformly distributed over $\Pi_E(\varphi)$, the ODCLD function in direction $\phi$ for $E$ is defined by  
$$
F_{E}(x,\varphi) = {\frac {L_{1}\{y\in \Pi_E(\varphi):\chi(l_{\varphi}+y) \leq x\}}{b_{E}(\varphi)}},
$$
where $b_E(\varphi)=L_1(\Pi_E(\varphi))$.


% \vskip 5pt
\begin{figure}[h]
    \centering
    \begin{subfigure}[t]{0.65\textwidth}
        \centering
        \includegraphics[width=\textwidth]{P1_P3_preliminary_1.png}
        \captionsetup{justification=centering}
    \end{subfigure}%    
    \caption{Illustration of $l_{\varphi}+y$ making a chord in $E$.}
    \label{fig:preliminary_fig_1}
\end{figure}

Throughout this chapter, we will be focused on finding the ODCLD functions and covariograms of prisms with convex quadrilateral bases.  

\section{ODCLD in a rectangular parallelepiped}\label{Rectangular Parallelepiped}
   
When $E\subset \mathbb{R}^2$ is a parallelogram, the function $F_E(x,\varphi)$ and the covariogram $C_E(t,\varphi)$ (which is an alternative notation for $C_E(t\phi)$), are explicitly found in \cite{GO_Parallelogram}. In particular, the following results can be extracted from \cite{GO_Parallelogram}, section 2.      

\begin{lemma} \label{lemma2_1}
\ Let $R$ be the rectangle $[0,b] \times [0,a] \subset \mathbb{R}^2$, where $a \leq b$, and let $\pi k-\arctan\frac{a}{b}\leq \varphi < \pi(k+1)-\arctan\frac{a}{b}$ for some integer $k$. Then  
\begin{equation}
    F_{R}(x,\varphi) = 
    \begin{cases}
        0, & \mbox{if \, $x \leq 0$} \\
        \displaystyle{{\frac{2x|\sin\varphi| \cdot |\cos\varphi|}{a|\cos\varphi| + b|\sin\varphi|}}}, & \mbox{if \, $0 < x < x_{\max}(\varphi)$} \\
        1, & \mbox{if \, $x \geq x_{\max}(\varphi)$}
    \end{cases}
    \label{eq:lemma21_1}
\end{equation}
and 
\begin{equation}
    C_{R}(t,\varphi) = 
    \begin{cases}
        ab - t(a|\cos\varphi| + b|\sin\varphi|) + t^2|\sin\varphi\cos\varphi|, & \mbox{if \, $0 \leq t \leq x_{\max}(\varphi)$} \\
        0, & \mbox{if \, $t > x_{\max}(\varphi)$}
    \end{cases},
    \label{eq:covariogram rectangle}
\end{equation}
\ where

$$
    x_{\max}(\varphi) = 
    \begin{cases}
        \displaystyle{\frac{b}{|\cos\varphi|}}, &  \mbox{if \, $-\arctan\frac{a}{b} + \pi k \leq \varphi < \arctan\frac{a}{b} + \pi k$}\\
        \displaystyle{\frac{a}{|\sin\varphi|}}, & \mbox{if \, $\arctan\frac{a}{b} + \pi k \leq \varphi < -\arctan\frac{a}{b} + \pi (k+1)$}  
    \end{cases}.
$$
\end{lemma}

\begin{remark}\label{first remark}
$x_{\max}(\varphi)$ represents the length of the maximal chord in $R$ in direction $\phi$, that is
$$x_{\max}(\varphi) = \max\limits_{y \in \Pi_R(\varphi)} \chi(l_{\varphi} + y).$$
\end{remark}
\begin{remark}
The formula 
\begin{equation}
b_{R}(\varphi) = a|\cos\varphi| + b|\sin\varphi| \label{eq:proof_lm21_2}
\end{equation}
holds for any real $\varphi$.
\end{remark}



For $\omega \in \mathbb{S}^2$, we denote by $\omega^\perp$ the orthogonal complement of $\{t\omega\,:\, t\in \mathbb{R}\}$ in $\mathbb{R}^3$. For a bounded convex body $D\subset \mathbb{R}^3$, let $\Pi_D(\omega)$ be the orthogonal projection of $D$ onto the plane $\omega^\perp$.
\newline
Let $l_{\omega}+y$ be the line passing through $y\in \omega^\perp$ with direction vector $\omega$, and $\chi(l_{\omega}+y) = L_{1}((l_{\omega}+y) \cap D)$. Assuming $y$ is uniformly distributed in $\Pi_D(\omega)$, we define the chord length distribution function in direction $\omega$ for $D$ by 
$$
F_{D}(t,\omega) = {\frac {L_{2}\{y\in \Pi_D(\omega):\chi(l_{\omega}+y) \leq t\}}{b_{D}(\omega)}},
$$
where $b_D(\omega)=L_2(\Pi_D(\omega))$.

Let $D$ be a cylinder with base $B$ (not necessarily convex) placed on the $OXY$ plane, and height $h$. If $\omega$ is given by its spherical coordinates $(1, \varphi, \theta)$, where $1$ is the radius, $\varphi \in [0,2\pi)$ is the azimuthal angle counted from the $OX$ axis anti-clockwise, and $\theta\in [0, \frac{\pi}{2}]$ is the elevation angle with respect to the horizontal plane $OXY$, then (see \cite{HO_Cylinder})
\begin{equation}
b_D(\omega)=\|B\| \sin \theta+b_{B}(\varphi) h \cos \theta,
    \label{eq:b_D omega}
\end{equation}
and
\begin{equation}
F_{D}(t,\omega)=\left\{\begin{array}{ll}0, & \mbox{if \, $t<0$} \\ \frac{b_{B}(\varphi) \cos \theta}{b_D(\omega)}\left[ (h-t \sin \theta) F_{B}(t \cos \theta, \varphi)+\right. \\ \left.+t \sin \theta+\sin \theta \int_{0}^{t}\left(1-F_{B}(u \cos \theta, \varphi)\right) d u\right], & \mbox{if \, $0 \leq t<x_{\max}(\omega)$} \\ 1, & \mbox{if \, $t \geq x_{\max }$}(\omega)\end{array}\right.
\label{eq:distribution D and B}
\end{equation}
where $\|B\|$ is the area of $B$, and $x_{\max}(\omega)$ is the length of the maximal chord in $D$ in direction $\omega$.  

\begin{theorem} \label{theroem3_1}
Let $D$ be the parallelepiped  $ [0,b] \times [0,a] \times [0,h] \subset{\mathbb{R}^3}$ and $F_{D}(t,\omega)$ be the ODCLD function of $D$ in direction $\omega = (\cos\varphi \cos\theta, \sin\varphi \cos\theta, \sin\theta)\in \mathbb{S}^2,$ where $0\leq \theta \leq \frac{\pi}{2}$. Then 
$$
    F_{D}(t,\omega) = 
    \begin{cases}
        0, & \mbox{if \, $t \leq 0$} \\
        \frac{\cos\theta}{ab \sin\theta + b_{R}(\varphi)\cdot h\cos\theta} \cdot \bigg( \big(h \cos\theta |\sin 2\varphi| + \\ + 2b_{R}(\varphi) \sin\theta\big)\cdot t - \frac{3}{4} \sin 2\theta  |\sin 2\varphi|\cdot t^2\bigg) , & \mbox{if \, $0 < t < x_{\max}(\omega)$} \\
        1, & \mbox{if \, $t \geq x_{\max}(\omega)$}
    \end{cases},
$$
where $R=[0,b]\times [0,a].$
\end{theorem}

\begin{proof} The validity of the formula is obvious when $t\leq 0$ or $t\geq x_{\max}(\omega)$. Let $0 < t < x_{\max}(\omega)$. Since
\begin{equation}
    x_{\max}(\omega) = 
    \begin{cases}
        \frac{x_{\max}(\varphi)}{\cos\theta}, & \mbox{if \, $0 \leq \theta \leq \arctan\frac{h}{x_{\max}(\varphi)}$} \\
        \frac{h}{\sin\theta}, & \mbox{if \, $\arctan\frac{h}{x_{\max}(\varphi)}< \theta \leq \frac{\pi}{2} $} 
    \end{cases},
    \label{eq:x_max}
\end{equation}
the inequality
$$x_{\max}(\omega)\cos\theta\leq x_{\max}(\varphi)$$ holds for any $\theta\in [0,
\frac{\pi}{2}]$. Thus, taking into account \eqref{eq:lemma21_1}, \eqref{eq:b_D omega}, and \eqref{eq:distribution D and B} we conclude that $$F_D(t,\omega)=\displaystyle{\frac{b_{R}(\varphi) \cos \theta}{ab \sin \theta+b_{R}(\varphi) h \cos \theta}}\times$$ 
$$
\times\left[ (h-t \sin \theta) \frac{t\cos\theta|\sin2\varphi|}{b_R(\varphi)}+ 
2t \sin \theta-\sin \theta \int_{0}^{t}\frac{u\cos\theta|\sin2\varphi|}{b_R(\varphi)} du\right]=$$
$$=\frac{\cos\theta}{ab \sin\theta + b_{R}(\varphi)\cdot h\cos\theta} \cdot \left[ \big(h \cos\theta |\sin 2\varphi| + 2b_{R}(\varphi) \sin\theta\big)\cdot t - \frac{3}{4} \sin 2\theta  |\sin 2\varphi|\cdot t^2\right]$$

\end{proof}


\begin{remark}
When $\theta=0$ then functions $F_D$ and $F_R$ coincide. If $\theta=\frac{\pi}{2}$ then $x_{\max}(\omega)=h$. In this case $F_D$ coincides with the indicator function of $(-\infty,\,h]$. For some other special cases the result of Theorem \ref{theroem3_1} is visualized by Figure~\ref{fig:F_D}.
\end{remark}
\vskip -5mm
 \begin{figure}[h]
    \centering
    \begin{subfigure}[t]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{P1_Rectangle_case1_v2.png}
        \captionsetup{justification=centering}
        \caption{$a=5, b=10, h=5, \varphi = \frac{\pi}{2}, \theta=\frac{\pi}{4}$}
    \end{subfigure}%
    \begin{subfigure}[t]{0.45\textwidth}  
        \centering 
        \includegraphics[width=\textwidth]{P1_Rectangle_case2_v2.png}
        \captionsetup{justification=centering}
        \caption{$a=5, b=10, h=6, \varphi = \frac{\pi}{2}, \theta=\frac{\pi}{4}$}
    \end{subfigure}
    \begin{subfigure}[t]{0.45\textwidth}   
        \centering 
        \includegraphics[width=\textwidth]{P1_Rectangle_case3_v2.png}
        \captionsetup{justification=centering}
        \caption{$a=10, b=10, h=10\sqrt{2}, \varphi = \frac{3\pi}{4}, \theta=\frac{\pi}{4}$}
    \end{subfigure}%
    \begin{subfigure}[t]{0.45\textwidth}   
        \centering 
        \includegraphics[width=\textwidth]{P1_Rectangle_case4_v2.png}
        \captionsetup{justification=centering}
        \caption{$a=10, b=10, h=10\sqrt{2}, \varphi = \frac{\pi}{4}, \theta=\frac{\pi}{3}$}
    \end{subfigure}
    \caption{Orientation dependent chord length distribution function $F_D$ for different cases}
    \label{fig:F_D}
\end{figure}

\begin{remark}
Direct use of \eqref{eq:distribution D and B} in the proof of the theorem avoided computation of the covariogram of $D$. The function $C_{D}(t \omega)$ could be found explicitly.   
\end{remark}
\ Indeed, if $0\leq t \leq x_{\max}(\omega)$ then $C_{D}(t \omega)=L_{3}(D\, \cap\,\{D+t \omega\})=$ 
$$
=L_{2}(\, R  \cap\ \,\{R+(t \cos \theta) \phi\}) \cdot(h-t \sin \theta)=(h-t \sin \theta) \cdot C_{R}(t \cos \theta, \varphi).
$$

Taking into account \eqref{eq:x_max} and \eqref{eq:covariogram rectangle} we obtain
$$
    C_{D}(t\omega) = 
    \begin{cases}
        (h-t\sin\theta)\big(ab - t\cos \theta\cdot b_R(\varphi) + \frac{t^2}{4}\cos^2 \theta|\sin2\varphi|\big), & \mbox{if \, $0 \leq t \leq x_{\max}(\varphi)$} \\
        0, & \mbox{if \, $t > x_{\max}(\varphi)$}
    \end{cases}.
$$

\section{ODCLD in a right trapezoidal prism}\label{Right prism on a right trapezoid}

 Let $T\subset \mathbb{R}^2$ be the right trapezoid with the vertices at $O(0,0), A(0,a), C(b-a\cot\psi,a),$ and $B(b,0)$, where $arctan\frac{a}{b}<\psi<\frac{\pi}{2}.$ For every right trapezoid one can choose the parameters $a, b,$ and $\psi$ such that it becomes congruent to $OACB$. 

In this section, we maintain the notations and terminology introduced earlier in the previous sections.   

\begin{proposition} \label{proposition4_1}
Let $\pi k\leq \varphi < \pi(k+1)$ for some integer $k$. Then 
$$
b_{T}(\varphi) =     
    \begin{cases}
        a|\cos\varphi| + b|\sin\varphi|, & \mbox{if \, $\pi k \leq \varphi < \frac{\pi}{2} + \pi k$} \\
        b|\sin\varphi|, & \mbox{if \, $\frac{\pi}{2} + \pi k \leq \varphi < \pi(k+1) - \psi$} \\
        a|\cos\varphi| + (b - a\cot\psi) |\sin\varphi|, & \mbox{if \, $\pi(k+1)-\psi \leq \varphi < \pi(k+1)$}
    \end{cases}.
$$
\end{proposition}

\begin{proof} To reduce the computational burden, from now on we'll use $b_1$ for the shorter base of $T$, that is  $b_1=b - a\cot\psi$.

If $\pi k \leq \varphi < \frac{\pi}{2} + \pi k$, then $\Pi_T(\varphi)=\Pi_R(\varphi)$. Therefore, due to \eqref{eq:proof_lm21_2}, we have
$$b_T(\varphi)=b_R(\varphi)=a|\cos\varphi| + b|\sin\varphi|.$$ 

Similarly, if $\pi(k+1)-\psi \leq \varphi < \pi(k+1)$, then $\Pi_T(\varphi)=\Pi_{[0,b_1]\times [0,a]}(\varphi)$, which implies    
$$b_T(\varphi)=L_1\big(\Pi_{[0,b_1]\times [0,a]}(\varphi)\big)=a|\cos\varphi| + b_1|\sin\varphi|.$$

Finally, if $\frac{\pi}{2} + \pi k \leq \varphi < \pi(k+1) - \psi$, then 
$$b_T(\varphi)=L_1\big(\Pi_{[0,b]\times \{0\}}(\varphi)\big)=b\cos(\varphi-\pi k - \frac{\pi}{2})=(-1)^k b\sin\varphi=b|\sin\varphi|.$$

\vskip -8mm

\end{proof}

\vskip -5mm

Let $\phi_v^\perp$ be the set of vectors $y \in \phi^\perp$ so that the line $l_{\varphi} + y$ passes through a vertex of trapezoid $T$ and makes a chord of positive Lebesgue measure there. The two quantities introduced below, 
$$
x_{0}(\varphi) = \min\limits_{y \in \phi_v^\perp} \chi(l_{\varphi} + y) \,\,\,\text{and}\,\,\, x_{1}(\varphi) = \max\limits_{y \in \phi_v^\perp} \chi(l_{\varphi} + y), 
$$
will play a crucial role in the determination of distribution function $F_T$. The diagrams shown in Figure~\ref{fig:Trapezoid_5_cases} facilitate case-by-case computations (see Proposition \ref{proposition4_2}) of the above-mentioned quantities. 
% \vskip 5pt
\begin{figure}[h]
    \centering
    \begin{subfigure}[t]{0.25\textwidth}
        \centering
        \includegraphics[width=\textwidth]{P1_5_cases_1_1.png}
    \end{subfigure}%    
    \hspace{3cm} 
    \begin{subfigure}[t]{0.25\textwidth}  
        \centering 
        \includegraphics[width=\textwidth]{P1_5_cases_1_2.png}
    \end{subfigure}
        
        \tiny{$$If \; \pi k \leq \varphi < \frac{\pi}{2} + \pi k, \; then \; |OO_{1}| = x_{1}(\varphi), |CC_{1}| = x_{0}(\varphi)$$}
    
    \begin{subfigure}[t]{0.25\textwidth}  \ContinuedFloat 
        \centering 
        \includegraphics[width=\textwidth]{P1_5_cases_2.png}
    \end{subfigure}
        
        \tiny{$$If \; \frac{\pi}{2} + \pi k \leq \varphi < \pi (k+1) - \psi, \; then \; |AA_{1}| = |CC_{1}| = x_{1}(\varphi) = x_{0}(\varphi)$$}
        
    \begin{subfigure}[t]{0.25\textwidth}   
        \centering 
        \includegraphics[width=\textwidth]{P1_5_cases_3_1.png}
    \end{subfigure}%
    \hspace{3cm} 
    \begin{subfigure}[t]{0.25\textwidth}   
        \centering 
        \includegraphics[width=\textwidth]{P1_5_cases_3_2.png}
    \end{subfigure}
    
    \tiny{$$If \; \pi (k+1) - \psi \leq \varphi < \pi (k+1), \; then \; |AA_{1}| = x_{0}(\varphi), |BB_{1}| = x_{1}(\varphi)$$}
    \caption{Possible dispositions of $x_0(\varphi)$ and $x_1(\varphi)$}
    \label{fig:Trapezoid_5_cases}
\end{figure}
\newpage
\begin{proposition} \label{proposition4_2}
$x_{1}(\varphi) = x_{\max}(\varphi)$ for any angle $\varphi$. Furthermore, if for some $k \in \mathbb{Z}$

\begin{enumerate}[(i)]
  \item \mbox{ $\pi k \leq \varphi < \frac{\pi}{2} + \pi k$, then}
$$
    x_{0}(\varphi) = 
    \begin{cases}
        \displaystyle{\frac{b_1}{|\cos\varphi|}}, & \mbox{if \, $\pi k \leq \varphi < \pi k + \arctan\frac{a}{b_{1}}$} \\
        \displaystyle{\frac{a}{|\sin\varphi|}}, & \mbox{if \, $\pi k + \arctan\frac{a}{b_{1}} \leq \varphi < \frac{\pi}{2} + \pi k$} 
    \end{cases},
$$

$$
    x_{\max}(\varphi) = 
    \begin{cases}
        \displaystyle{\frac{b\sin\psi}{|\sin(\varphi + \psi)|}}, & \mbox{if \, $\pi k \leq \varphi < \pi k + \arctan\frac{a}{b_{1}}$} \\
        \displaystyle{\frac{a}{|\sin\varphi|}}, & \mbox{if \, $\pi k + \arctan\frac{a}{b_{1}} \leq \varphi < \frac{\pi}{2} + \pi k$} 
    \end{cases};
$$

  \item \mbox{$\frac{\pi}{2} + \pi k \leq \varphi < \pi (k+1) - \psi$, then}
  $$
  x_{0}(\varphi) = x_{\max}(\varphi) = \frac{a}{|\sin\varphi|};
  $$
  
  \item \mbox{$ \pi (k+1) - \psi \leq \varphi < \pi (k+1)$, then}
$$
    x_{0}(\varphi) = 
    \begin{cases}
        \displaystyle{\frac{a}{|\sin\varphi|}}, & \mbox{if \, $\pi (k+1) - \psi \leq \varphi < \pi (k+1) - \arctan\frac{a}{b}$} \\
        \displaystyle{\frac{b_1 \sin\psi}{|\sin(\varphi + \psi)|}}, & \mbox{if \, $\pi (k+1) - \arctan\frac{a}{b} \leq \varphi < \pi (k+1) $} 
    \end{cases},
$$
$$
    x_{\max}(\varphi) = 
    \begin{cases}
        \displaystyle{\frac{a}{|\sin\varphi|}}, & \mbox{if \, $\pi (k+1) - \psi \leq \varphi < \pi (k+1) - \arctan\frac{a}{b}$} \\
        \displaystyle{\frac{b}{|\cos\varphi|}}, & \mbox{if \, $\pi (k+1) - \arctan\frac{a}{b} \leq \varphi < \pi (k+1) $} 
    \end{cases}.
$$

\end{enumerate}
\end{proposition}

\begin{proof} A chord of maximal length in a convex polygon with direction $\phi=(\cos\varphi, \sin\varphi )\in \mathbb{S}^1$, also known as $\varphi$-diameter of the polygon, is not necessarily unique (this is also seen in Figure~\ref{fig:Trapezoid_5_cases}: the second, third, and fourth cases) but for any given $\varphi$ there exists a $\varphi$-diameter such that at least one endpoint of the chord coincides with a vertex of the given polygon (\cite{Mount}, p. 248). Thus,    
 $$x_{\max}(\varphi)=\max\limits_{y \in \Pi_R(\varphi)} \chi(l_{\varphi} + y)=\max\limits_{y \in \phi_v^\perp} \chi(l_{\varphi} + y)=x_1(\varphi).$$
 
Case (i), sub-case 1 ($\pi k \leq \varphi < \pi k + \arctan\frac{a}{b_{1}}$). Observe the first trapezoid in Figure~\ref{fig:Trapezoid_5_cases}. Here we are given $\angle O_1OB=\varphi -\pi k$. By Sine Rule, 
$$x_0(\varphi)=|CC_1|=\frac{b_1}{\cos(\varphi -\pi k)}=\frac{b_1}{|\cos\varphi|};$$
$$x_{\max}(\varphi)=|OO_1|=\frac{b\sin\psi}{\sin(\varphi -\pi k+\psi)}=\frac{b\sin\psi}{|\sin(\varphi+\psi)|}.$$

Case (i), sub-case 2 ($\pi k + \arctan\frac{a}{b_{1}} \leq \varphi < \frac{\pi}{2} + \pi k$). Observe the second trapezoid in Figure~\ref{fig:Trapezoid_5_cases}. Since $\angle AO_1O=\angle O_1OB=\varphi -\pi k$, from the right triangle $AO_1O$ we obtain
$$x_0(\varphi)=x_{\max}(\varphi)=|OO_1|=\frac{a}{\sin(\varphi -\pi k)}=\frac{a}{|\sin\varphi|}.$$

Case (i) is completely proved. The proof of the case (iii) is similar to (i), hence omitted. It remains to discuss the case (ii), where $\frac{\pi}{2} + \pi k \leq \varphi < \pi (k+1) - \psi$ and the third (in the middle) trapezoid in Figure~\ref{fig:Trapezoid_5_cases} is relevant. In this case we have $\angle AA_1B=\varphi -\pi k \Rightarrow \angle AA_1O=\pi(k+1)-\varphi$, which implies
$$x_0(\varphi)=x_{\max}(\varphi)=|AA_1|=\frac{a}{\sin(\pi (k+1)-\varphi)}=\frac{a}{|\sin\varphi|}.$$

\end{proof}

By definition, for any angle $\varphi$, if $x<0$ then $F_{T}(x,\varphi) = 0$, and if $x \geq x_{\max}(\varphi)$ then $F_{T}(x,\varphi) = 1$. The  non-trivial case $0 \leq x < x_{\max}(\varphi)$ is explored below.

\begin{lemma} \label{lemma4_1}
$F_{T}(x,\varphi) = 0$ if $x<0$ and $F_{T}(x,\varphi) = 1$ if $x \geq x_{\max}(\varphi)$. For $0 \leq x < x_{\max}(\varphi), F_{T}(x,\varphi)$ is represented as follows $(k \in \mathbb{Z}):$
\begin{enumerate}[(i)]
    \item \mbox{For $\pi k \leq \varphi < \frac{\pi}{2} + \pi k$},
\begin{equation}
F_{T}(x,\varphi) = 
    \begin{cases}
        \displaystyle{\frac{x \sin\varphi [\sin(\varphi + \psi) + \cos\varphi \sin\psi]}{b_{T}(\varphi) \sin\psi}}, & \mbox{if \, $0 \leq x < x_{0}(\varphi)$} \\
        \displaystyle{\frac{x \sin^2(\varphi + \psi) - x_{0}(\varphi)\sin^2\psi \cos^2\varphi}{b_{T}(\varphi) \sin\psi \cos\psi}}, & \mbox{if \, $x_{0}(\varphi) \leq x < x_{\max}(\varphi)$} 
    \end{cases};
   \label{eq:F_T case 1} 
\end{equation}

    \item \mbox{if $\frac{\pi}{2} + \pi k \leq \varphi < \pi (k+1) - \psi$},
\begin{equation}
 F_{T}(x,\varphi) = \frac{x \sin^2\varphi \cot\psi}{b_{T}(\varphi)};
    \label{eq:F_T case 2}
\end{equation}

    \item \mbox{if $ \pi (k+1) - \psi \leq \varphi < \pi (k+1)$},
    \begin{equation}
     F_{T}(x,\varphi) = 
    \begin{cases}
        \displaystyle{\frac{-x \sin\varphi [\sin(\varphi + \psi) + \cos\varphi \sin\psi]}{b_{T}(\varphi) \sin\psi}}, & \mbox{if \, $0 \leq x < x_{0}(\varphi)$} \\
        \displaystyle{\frac{x \cos^2\varphi \sin^2\psi - x_{0}(\varphi)\sin^2(\varphi + \psi)}{b_{T}(\varphi) \sin\psi \cos\psi}}, & \mbox{if \, $x_{0}(\varphi) \leq x < x_{\max}(\varphi)$} 
    \end{cases}.
        \label{eq:F_T case 3}
    \end{equation}

\end{enumerate}
\end{lemma}

\begin{proof}
Let's notice that the function $F_T(x, \cdot)$ is $\pi$-periodic. This guarantees that generality will not be lost if we restrict the proof to the case $k=0$.
\vskip 5pt
\underline{Case (i), sub-case 1.1:}  let $0 \leq \varphi < \arctan\frac{a}{b_{1}}$ and $0 \leq x < x_{0}(\varphi)$. \\
This case is displayed below in Figure~\ref{fig:Trapezoid_prf_(i)}(a) which shows $|MM_1|=|NN_1|=x<x_0(\varphi)=|CC_1|<|OO_1|=x_{\max}(\varphi)$.  
\vskip 5pt
\begin{figure}[h]
    \centering
    \begin{subfigure}[t]{0.32\textwidth}
        \centering
        \includegraphics[width=\textwidth]{P1_7_cases_(i)_1.1.png}
        \captionsetup{justification=centering}
        \caption{\tiny{Case (i), sub-case 1.1: $0 \leq \varphi < \arctan\frac{a}{b_1}$, \\ $0 \leq x < x_{0}(\varphi)$}}
    \end{subfigure}%    
    \begin{subfigure}[t]{0.32\textwidth}  
        \centering 
        \includegraphics[width=\textwidth]{P1_7_cases_(i)_1.2.png}
        \captionsetup{justification=centering}
        \caption{\tiny{Case (i), sub-case 1.2: $0 \leq \varphi < \arctan\frac{a}{b_1}$, \\ $x_{0}(\varphi) \leq x < x_{\max}(\varphi)$}}
    \end{subfigure}%
    \begin{subfigure}[t]{0.36\textwidth}  
        \centering 
        \includegraphics[width=\textwidth]{P1_7_cases_(i)_2.png}
        \captionsetup{justification=centering}
        \caption{\tiny{Case (i), sub-case 2: $\arctan\frac{a}{b_1} \leq \varphi < \frac{\pi}{2}$, \\ $0 \leq x < x_{0}(\varphi) = x_{\max}(\varphi)$}}
    \end{subfigure}
    \caption{Chords in trapezoid in direction $\phi$, where $0 \leq \varphi < \frac{\pi}{2}$.}
    \label{fig:Trapezoid_prf_(i)}
\end{figure}
\vskip 5pt
In this case we have $F_T(x, \varphi)=\frac{1}{b_T(\varphi)}\big(b_{\Delta AMM_1}(\varphi)+b_{\Delta BNN_1}(\varphi)\big)$. The quantities $b_{\Delta AMM_1}(\varphi)$ and $b_{\Delta BNN_1}(\varphi)$ are equal to the heights of triangles $AMM_1$ (with base $MM_1$) and $BNN_1$ (with base $NN_1$), respectively. Those are computed below:
\begin{equation}
b_{\Delta AMM_1}(\varphi)=x\sin\varphi\cos\varphi.
 \label{eq:right triangle height, case (i), 1.1}   
\end{equation}
\begin{equation}
b_{\Delta BNN_1}(\varphi)=\frac{x\sin\varphi\sin(\varphi+\psi)}{\sin\psi}.
 \label{eq:triangle height, case (i), 1.1}   
\end{equation}
\underline{Case (i), sub-case 1.2:} let $0 \leq \varphi < \arctan\frac{a}{b_{1}}$ and $x_0(\varphi) \leq x < x_{\max}(\varphi)$. \\
This case is displayed in Figure~\ref{fig:Trapezoid_prf_(i)}(b), where $x_0(\varphi)=|CC_1|\leq x=|MM_1|=|NN_1|<|OO_1|=x_{\max}(\varphi)$. In this case we have

$F_T(x, \varphi)=\frac{1}{b_T(\varphi)}\big(b_{ACMM_1}(\varphi)+b_{\Delta BNN_1}(\varphi)\big)=\frac{1}{b_T(\varphi)}\big(b_{\Delta ACC_1}(\varphi)+b_{\Delta BNN_1}(\varphi)+b_{CC_1M_1M}(\varphi)\big)=\frac{1}{b_T(\varphi)}\big(x_0(\varphi)\sin\varphi\cos\varphi+\frac{x\sin\varphi\sin(\varphi+\psi)}{\sin\psi}+b_{CC_1M_1M}(\varphi)\big)$. The quantity 
\begin{equation}
b_{CC_1M_1M}(\varphi)=\frac{(x-x_0(\varphi))\cos\varphi\sin(\varphi+\psi)}{\cos\psi}
 \label{eq:trapezoid height, case (i), 1.2}   
\end{equation}
is computed from the trapezoid $CC_1M_1M$ with bases $CC_1$ and $MM_1$, as a height.

\underline{Case (i), sub-case 2:} let $\arctan\frac{a}{b_{1}} \leq \varphi < \frac{\pi}{2} $ and $0\leq x<x_0(\varphi)= x_{\max}(\varphi)$. \\
This case is displayed in Figure~\ref{fig:Trapezoid_prf_(i)}(c), where $x=|MM_1|=|NN_1|<|OO_1|=|CC_1|=x_0(\varphi)=x_{\max}(\varphi)$. Computation of the chord length distribution function in this case is absolutely identical to the case (i), sub-case 1.1.\\
Combining \eqref{eq:right triangle height, case (i), 1.1}, \eqref{eq:triangle height, case (i), 1.1}, and \eqref{eq:trapezoid height, case (i), 1.2}, for any $\varphi\in [0,\frac{\pi}{2})$ we obtain $F_{T}(x,\varphi) =$
$$ 
    \begin{cases}
        \displaystyle{\frac{x\sin\varphi\cos\varphi+\frac{x\sin\varphi\sin(\varphi+\psi)}{\sin\psi}}{b_{T}(\varphi)}}, & \mbox{ $0 \leq x < x_{0}(\varphi)$} \\
        \displaystyle{\frac{x_0(\varphi)\sin\varphi\cos\varphi+\frac{x\sin\varphi\sin(\varphi+\psi)}{\sin\psi}+\frac{(x-x_0(\varphi))\cos\varphi\sin(\varphi+\psi)}{\cos\psi}}{b_{T}(\varphi)}}, & \mbox{ $x_{0}(\varphi) \leq x < x_{\max}(\varphi)$} 
    \end{cases},$$
     which is equivalent to \eqref{eq:F_T case 1}.
    
\underline{Case (ii):} let $\frac{\pi}{2}\leq\varphi<\pi-\psi$ and see Figure~\ref{fig:Trapezoid_prf_(ii)} below. 
\vskip 5pt
\begin{figure}[h]
    \centering
    \begin{subfigure}[b]{0.34\textwidth}
        \centering
        \includegraphics[width=\textwidth]{P1_7_cases_(ii).png}
        \captionsetup{justification=centering}
        \caption*{\tiny{Case (ii):\\ $\frac{\pi}{2} \leq \varphi < \pi - \psi$, \\ $0 \leq x < x_{0}(\varphi) = x_{\max}(\varphi)$}}
    \end{subfigure}
    \caption{Chords in trapezoid in direction $\phi$, where $\frac{\pi}{2}\leq\varphi<\pi-\psi$.}
    \label{fig:Trapezoid_prf_(ii)}
\end{figure}
\vskip 5pt
For $x=|MM_1|=|NN_1|<|AA_1|=|CC_1|=x_0(\varphi)=x_{\max}(\varphi)$ we have 
$$F_T(x, \varphi)=\frac{1}{b_T(\varphi)}\big(b_{\Delta OMM_1}(\varphi)+b_{\Delta BNN_1}(\varphi)\big)=$$ $$=\frac{x\sin(\pi-\varphi)\cos(\pi-\varphi)+\frac{x\sin\varphi\sin(\varphi+\psi)}{\sin\psi}}{b_T(\varphi)}=\frac{x\sin^2\varphi\cos\psi}{b_T(\varphi)\sin\psi}=\frac{x\sin^2\varphi \cot\psi}{b_{T}(\varphi)}.$$

\underline{Case (iii):} let $\pi-\psi\leq\varphi<\pi$. Similar to case (i), the distribution function can be computed by  three sub-cases, as shown in Figure~\ref{fig:Trapezoid_prf_(iii)}.  
\vskip 5pt
\begin{figure}[h]
    \centering
    \begin{subfigure}[t]{0.34\textwidth}
        \centering
        \raisebox{7mm}{\includegraphics[width=\textwidth]{P1_7_cases_(iii)_1.png}}
        \captionsetup{justification=centering}
        \caption{\tiny{Case (iii), sub-case 1: $\pi - \psi \leq \varphi < \pi - \arctan\frac{a}{b}$, \\ $0 \leq x < x_{0}(\varphi) = x_{\max}(\varphi)$}}
    \end{subfigure}%  
    \begin{subfigure}[t]{0.3\textwidth}  
        \centering 
        \includegraphics[width=\textwidth]{P1_7_cases_(iii)_2.1.png}
        \captionsetup{justification=centering}
        \caption{\tiny{Case (iii), sub-case 2.1: $\pi - \arctan\frac{a}{b} \leq \varphi < \pi$, \\ $0 \leq x < x_{0}(\varphi)$}}
    \end{subfigure}%
    \begin{subfigure}[t]{0.3\textwidth}  
        \centering 
        \includegraphics[width=\textwidth]{P1_7_cases_(iii)_2.2.png}
        \captionsetup{justification=centering}
        \caption{\tiny{Case (iii), sub-case 2.2: $\pi - \arctan\frac{a}{b} \leq \varphi < \pi$, \\ $x_{0}(\varphi) \leq x < x_{\max}(\varphi)$}}
    \end{subfigure}
    \caption{Chords in trapezoid in direction $\phi$, where $\pi-\psi \leq \varphi < \pi$.}
    \label{fig:Trapezoid_prf_(iii)}
\end{figure}
\ If $\pi-\psi\leq\varphi<\pi$ and $0 \leq x < x_0(\varphi)\leq x_{\max}(\varphi)$, then (sub-cases 1 and 2.1)
\begin{equation}
   F_T(x, \varphi)=\displaystyle{\frac{x\sin(\pi-\varphi)\cos(\pi-\varphi)-\frac{x\sin\varphi\sin(\varphi+\psi)}{\sin\psi}}{b_{T}(\varphi)}}. 
   \label{eq:F_T case (iii), sub-cases 1 and 2.1}
\end{equation}
Inequality $x_0(\varphi)\leq x<x_{\max}(\varphi)$ is possible if only $\pi - \arctan\frac{a}{b} \leq \varphi < \pi$ (sub-case 2.2). The distribution function in this last case is equal to
\begin{equation}
   F_T(x, \varphi)=\displaystyle{\frac{x\sin(\pi-\varphi)\cos(\pi-\varphi)-\frac{x_0(\varphi)\sin\varphi\sin(\varphi+\psi)}{\sin\psi}+\frac{(x-x_0(\varphi))\cos\varphi\sin(\varphi+\psi)}{\cos\psi}}{b_{T}(\varphi)}}. 
   \label{eq:F_T case (iii), sub-case 2.2}
\end{equation}
By simplifying \eqref{eq:F_T case (iii), sub-cases 1 and 2.1} and \eqref{eq:F_T case (iii), sub-case 2.2}, we establish \eqref{eq:F_T case 3}.
\end{proof}


 
Due to Matheron's formula (see \cite{Matheron}, p. 86) we have  
$$
\frac{\partial C_{T}(t, \varphi)}{\partial t}=-L_{1}\left(\left\{y \in \phi^{\perp}: L_{1}\left(T \cap\left(l_{\varphi}+y\right)\right) \geq t\right\}\right),
$$
which can be rewritten in terms of the orientation-dependent chord length distribution function as 
$$\frac{\partial C_{T}(t,\varphi)}{\partial t} = -b_{T}(\varphi) \cdot [1-F_{T}(t,\varphi)].$$
Integration of both parts of the last formula yields
\begin{equation}
 C_{T}(t,\varphi) = C_{T}(0,\varphi) - b_{T}(\varphi) \cdot \int_{0}^{t} [1-F_{T}(u,\varphi)] du, \; t\geq 0.
\label{eq:Matheron_0}
\end{equation}

Using the formula \eqref{eq:Matheron_0} and Lemma \ref{lemma4_1} we immediately come to an explicit formula for $C_T(t,\varphi)$, the covariogram of $T$. Since $C_T(t, \cdot)$ has period equal to $\pi$, it is enough to have it computed for $\varphi\in [0, \pi)$.     
$$
 C_{T}(t,\varphi) =  \frac{a(b+b_{1})}{2} - tb_{T}(\varphi) + b_{T}(\varphi) \cdot \int_{0}^{t} F_{T}(u,\varphi) du =\frac{a(b+b_{1})}{2} - tb_{T}(\varphi) +
$$
    $$
    \begin{cases}
         \displaystyle{\frac{t^2 \sin\varphi [\sin(\varphi + \psi) + \cos\varphi \sin\psi]}{2\sin\psi}}, & \mbox{if \, $0 \leq \varphi < \frac{\pi}{2}$, \;
        $0\leq t<x_{0}(\varphi)$}   \\
        
         \displaystyle{\frac{t^2 \sin^2(\varphi + \psi)}{2\sin\psi \cos\psi} - \frac{t x_{0}(\varphi) \sin\psi \cos^2\varphi}{\cos\psi}}, & \mbox{if \, $0 \leq \varphi < \frac{\pi}{2} $, \; $x_{0}(\varphi) \leq t < x_{\max}(\varphi)$} \\
        
         \displaystyle{\frac{t^2}{2}\sin^2\varphi \cot\psi}, & \mbox{if \, $\frac{\pi}{2} \leq \varphi < \pi - \psi $, \; $0\leq t<x_{\max}(\varphi)$}   \\

        \displaystyle{- \frac{t^2 \sin\varphi [\sin(\varphi + \psi) + \cos\varphi \sin\psi]}{2\sin\psi}} , & \mbox{if \, $\pi - \psi \leq \varphi < \pi$, \; $0\leq t<x_{0}(\varphi)$ }   \\
        
         \displaystyle{\frac{t^2 \cos^2\varphi \sin\psi}{2 \cos\psi} - \frac{t x_{0}(\varphi) \sin^2(\varphi + \psi)}{\sin\psi \cos\psi}}, & \mbox{if \, $\pi - \psi \leq \varphi < \pi$, \; $x_{0}(\varphi) \leq t \leq x_{\max}(\varphi)$ }   \\

    \end{cases}.
$$ 
\vskip 5pt

Denote by $D_{T}$ the right prism $\{(x,y,z): (x,y)\in T,\, 0 \leq z \leq h\}$. As a result, for any $t\in [0, x_{\max}(\omega)]$, any $\varphi\in [\pi k, \pi(k+1))$, $k\in \mathbb{Z}$ and any  $\theta \in [0,\frac{\pi}{2}]$  the covariogram of $D_T$ is equal to 
$$
C_{D_T}(t \omega)=L_{2}(\, T  \cap\ \,\{T+(t \cos \theta) \phi\}) \cdot(h-t \sin \theta)=(h-t \sin \theta) \cdot C_{T}(t \cos \theta, \varphi-\pi k),
$$
where $\omega= (\cos\varphi \cos\theta, \sin\varphi \cos\theta, \sin\theta)$ and $x_{\max}(\varphi)$ satisfies \eqref{eq:x_max}.

\vskip 5pt
\ Computation of $F_{D_T}(x, \omega)$ requires more workload. Lemma \ref{lemma4_1} shows that if $\pi k \leq \varphi < \frac{\pi}{2} + \pi k$ or $ \pi (k+1) - \psi \leq \varphi < \pi (k+1)$ then the function $F_T(x, \varphi)$ is piecewise linear. To have those pieces written in slope-intercept form let's denote  
$$
m_{0}(\varphi) = \frac{\sin\varphi [\sin(\varphi + \psi) + \cos\varphi \sin\psi]}{b_{T}(\varphi) \sin\psi},\,\,\,\,\,
m_{1}(\varphi) = \frac{\sin^2(\varphi + \psi)}{b_{T}(\varphi)\sin\psi \cos\psi},
$$

$$c(\varphi) = \frac{x_0(\varphi) \tan\psi \cos^2\varphi}{b_{T}(\varphi)}.$$
Then \eqref{eq:F_T case 1} and \eqref{eq:F_T case 3} can be represented as
\begin{equation}
 F_{T}(x,\varphi) = 
    \begin{cases}
        m_{0}(\varphi)x, & \mbox{if \, $0 \leq x < x_{0}(\varphi)$} \\
        m_{1}(\varphi)x - c(\varphi), & \mbox{if \, $x_{0}(\varphi) \leq x < x_{\max}(\varphi)$} 
    \end{cases}
  \label{eq:F_T case 1 slope-intercept}  
\end{equation}
and 
\begin{equation}
 F_{T}(x,\varphi) = 
    \begin{cases}
        -m_{0}(\varphi)x, & \mbox{if \,$0 \leq x < x_{0}(\varphi)$} \\
        c(\varphi)x - m_{1}(\varphi), & \mbox{if \, $x_{0}(\varphi) \leq x < x_{\max}(\varphi)$} 
    \end{cases},
  \label{eq:F_T case 3 slope-intercept}  
\end{equation}
respectively.

\vskip 5pt

\ If $t\leq 0$ then $F_{D_T}(t,\omega) = 0$, and if $t \geq x_{\max}(\omega)$ then $F_{D_T}(t,\omega) = 1$. If $0 < t < x_{\max}(\omega)$, then $F_{D_T}$ (unlike $F_D$)  requires several pieces to be written explicitly. The classification of cases is based on two factors:
\begin{itemize}
    \item [1)] the choice of either of the intervals $[\pi k, \frac{\pi}{2}+\pi k)$, $[\frac{\pi}{2}+\pi k, \pi (k+1)-\psi)$, or $[\pi (k+1)-\psi, \pi (k+1))$ for $\varphi$ to be taken from;
    \item [2)] the magnitude of the orthogonal projection of $x_{\max}(\omega)$ onto the base $T$ compared to $x_0(\varphi)$ for the given $\varphi$ and $\theta$.
\end{itemize}
The result is formulated below.

\begin{theorem} \label{theorem_5_1}\ 
\begin{enumerate}[(i)]
      \item \mbox{If $\pi k \leq \varphi < \frac{\pi}{2} + \pi k$ and $x_{\max}(\omega)\cos\theta\leq x_0(\varphi)$}, then
$$
    F_{D_{T}}(t,\omega) = \frac{b_{T}(\varphi)}{b_{D_{T}}(\omega)} \bigg( \big(hm_{0}(\varphi)\cos^2\theta + \sin2\theta\big) \cdot t - \frac{3}{4}{m_{0}(\varphi) \sin2\theta \cos\theta}\cdot t^2 \bigg),$$  $0 < t < x_{\max}(\omega)$. 

\vskip 4pt
    \item \mbox{If $\pi k \leq \varphi < \frac{\pi}{2} + \pi k$ and  $x_{\max}(\omega)\cos\theta > x_0(\varphi)$}, then
$$
    F_{D_T}(t,\omega) =\frac{b_{T}(\varphi)}{b_{D_{T}}(\omega)}\times
$$
$$
    \begin{cases}
          \big(hm_{0}(\varphi)\cos^2\theta + \sin2\theta\big) \cdot t -\frac{3}{4}{m_{0}(\varphi) \sin2\theta \cos\theta}\cdot t^2, & \mbox{if \, $0 <t<\frac{x_{0}(\varphi)}{\cos\theta} $} \\
         -c(\varphi) \big(x_{0}(\varphi) \sin\theta + h \cos\theta\big) - \frac{m_{0}(\varphi) - m_{1}(\varphi)}{2} x_{0}^2(\varphi) \sin\theta +\\ +\big(h m_{1}(\varphi) \cos^2\theta + [c(\varphi)+1] \sin2\theta \big) \cdot t -\\ -\frac{3}{4} m_{1}(\varphi) \sin2\theta \cos\theta \cdot t^2, & \mbox{if \, $\frac{x_{0}(\varphi)}{\cos\theta} \leq t < x_{\max}(\omega)$} 
    \end{cases}.
$$
% \vskip 4pt
\item If $ \frac{\pi}{2} + \pi k \leq \varphi < \pi (k+1) - \psi$, then
$$F_{D_{T}}(t,\omega)=\frac{h \cos^2\theta \sin^2\varphi \cot\psi + b_{T}(\varphi) \sin2\theta}{b_{D_{T}}(\omega)} \cdot t - \frac{\sin2\theta \sin^2\varphi \cot\psi [2\cos\theta + 1]}{4 b_{D_{T}}(\omega)} \cdot t^2,$$  $0 < t < x_{\max}(\omega).$


% \vskip 4pt
\item \mbox{If $\pi (k+1) - \psi \leq \varphi < \pi (k+1)$ and $x_{\max}(\omega)\cos\theta\leq x_0(\varphi)$}, then
$$
    F_{D_{T}}(t,\omega) = \frac{b_{T}(\varphi)}{b_{D_{T}}(\omega)} \bigg(\big(\sin2\theta -h m_{0}(\varphi)\cos^2\theta \big) \cdot t + \frac{3}{4} m_{0}(\varphi)  \sin2\theta \cos\theta\cdot t^2\bigg),$$ $0 < t < x_{\max}(\omega)$.

% \vskip 4pt
\item \mbox{If $\pi (k+1) - \psi \leq \varphi < \pi (k+1)$ and $x_{\max}(\omega)\cos\theta > x_0(\varphi)$}, then
\begin{gather*} 
    F_{D_T}(t,\omega) =\frac{b_{T}(\varphi)}{b_{D_{T}}(\omega)}\times\\
    \begin{cases}
          \big(\sin2\theta -h m_{0}(\varphi)\cos^2\theta \big) \cdot t + \frac{3}{4} m_{0}(\varphi)  \sin2\theta \cos\theta\cdot t^2, & \mbox{if \, $0 <t<\frac{x_{0}(\varphi)}{\cos\theta} $} \\
         -m_1(\varphi) \big(x_{0}(\varphi) \sin\theta + h \cos\theta\big) - \frac{ m_{0}(\varphi) - c(\varphi)}{2} x_{0}^2(\varphi) \sin\theta +\\ +\big(h c(\varphi) \cos^2\theta + [m_{1}(\varphi)+1] \sin2\theta \big) \cdot t -\\- \frac{3}{4} c(\varphi) \sin2\theta \cos\theta \cdot t^2, & \mbox{if \, $\frac{x_{0}(\varphi)}{\cos\theta} \leq t < x_{\max}(\omega)$} 
    \end{cases}.
\end{gather*}

\end{enumerate}

\end{theorem}



\begin{proof} \underline{Case (i):}  Since  $t\cos\theta\leq x_0(\varphi)$, \eqref{eq:F_T case 1 slope-intercept} yields $F_T(\varphi)=tm_0(\varphi)\cos\theta$. Then \eqref{eq:distribution D and B} outputs
\begin{equation}
\begin{gathered}
    F_{D_{T}}(t,\omega) = 
    \frac{b_{T}(\varphi) \cos\theta}{b_{D_{T}}(\omega)}\times \\ \times \bigg((h - t\sin\theta) \cdot tm_0(\varphi)\cos\theta + 2t\sin\theta - \sin\theta \int_0^t u\cdot m_0(\varphi)\cos\theta du\bigg) =\\ = \frac{b_{T}(\varphi)}{b_{D_{T}}(\omega)} \bigg( \big(hm_{0}(\varphi)\cos^2\theta + \sin2\theta\big) \cdot t - \frac{3}{4}{m_{0}(\varphi) \sin2\theta \cos\theta}\cdot t^2 \bigg).
\end{gathered}
\label{eq:F_D_T_case_(i)_big}  
\end{equation}

 \ \underline{Case (ii):}  If $0 <t<\frac{x_{0}(\varphi)}{\cos\theta} $, then the formula \eqref{eq:F_D_T_case_(i)_big} still works. But if $\frac{x_{0}(\varphi)}{\cos\theta} \leq t < x_{\max}(\omega)$, then there are two expressions for $F_{T}(u\cos\theta,\varphi)$ to be used under the integral in \eqref{eq:distribution D and B}. Due to \eqref{eq:F_T case 1 slope-intercept}, those pieces are
\begin{equation*}
 F_{T}(u\cos\theta,\varphi) = 
    \begin{cases}
       u\cdot m_{0}(\varphi)\cos\theta, & \mbox{if \, $ u<\frac{x_{0}(\varphi)}{\cos\theta} $} \\
       u\cdot m_{1}(\varphi)\cos\theta - c(\varphi), & \mbox{if \, $\frac{x_{0}(\varphi)}{\cos\theta} \leq u $} 
    \end{cases}.
  \label{eq:F_T(ucos) case 1 slope-intercept}  
\end{equation*}
Therefore we get
\begin{equation*}
\begin{split}
    &F_{D_{T}}(t,\omega) = \frac{b_{T}(\varphi) \cos\theta}{b_{D_{T}}(\omega)} \bigg[(h-t\sin\theta) (m_{1}(\varphi) t \cos\theta - c(\varphi)) + 2t \sin\theta - \\ & - \sin\theta \int_{0}^{\frac{x_{0}(\varphi)}{\cos\theta}} m_{0}(\varphi) \cos\theta u du - \sin\theta \int_{\frac{x_{0}(\varphi)}{\cos\theta}}^{t} [m_{1}(\varphi) \cos\theta u - c{(\varphi)}] du\bigg] = \\ & = \frac{b_{T}(\varphi) \cos\theta}{b_{D_{T}}(\omega)} \bigg[- h c(\varphi) - \frac{m_{0}(\varphi) \tan\theta}{2} x_{0}^2(\varphi) + h m_{1}(\varphi)\cos\theta \cdot t + \sin\theta c(\varphi) t - \\
    & - \sin\theta \cos\theta m_{1}(\varphi) t^2 + 2t\sin\theta - \sin\theta \cdot \bigg(\frac{m_{1}(\varphi) \cos\theta t^2}{2} - c(\varphi) \cdot t - m_{1}{(\varphi)} \frac{x_{0}^2(\varphi)}{2 \cos\theta} +  \\
    & + c(\varphi) \frac{x_{0}(\varphi)}{ \cos\theta}\bigg)\bigg],
\end{split}
\end{equation*}
and finally
\begin{equation}
\begin{split}
    &F_{D_{T}}(t,\omega) = -c(\varphi) \big(x_{0}(\varphi) \sin\theta + h \cos\theta\big) - \frac{m_{0}(\varphi) - m_{1}(\varphi)}{2} x_{0}^2(\varphi) \sin\theta + \\ & \big(h m_{1}(\varphi) \cos^2\theta + [c(\varphi)+1] \sin2\theta \big) \cdot t -\frac{3}{4} m_{1}(\varphi) \sin2\theta \cos\theta \cdot t^2.
\end{split}
\label{eq:F_D_T_case_(ii)_big}  
\end{equation}
 \underline{Case (iii):} Using \eqref{eq:F_T case 2} in \eqref{eq:distribution D and B}, we obtain
  \begin{align*}
   & F_{D_{T}}(t,\omega) = 
    \frac{b_{T}(\varphi) \cos\theta}{b_{D_{T}}(\omega)} \bigg[(h - t\sin\theta) \cdot \frac{t \cos\theta \sin^2(\varphi) \cot\psi}{b_{T}(\varphi)} + 2t\sin\theta - \sin\theta \cdot \frac{t^2}{2} \times
    \\ & \times \frac{\sin^2\varphi \cot\psi}{b_{T}(\varphi)}\bigg]= \frac{b_{T}(\varphi) \cos\theta}{b_{D_{T}}(\omega)} \bigg[\bigg(\frac{h \cos\theta \sin^2\varphi \cot\psi}{b_{T}(\varphi)} + 2\sin\theta\bigg) \cdot t -
    \\ & - \bigg(\frac{\sin\theta \cos\theta \sin^2\varphi \cot\psi}{b_{T}(\varphi)} + \frac{\sin\theta \sin^2\varphi \cot\psi}{2 b_{T}(\varphi)}\bigg)\cdot t^2\bigg] = 
    \\ & =
    \frac{h \cos^2\theta \sin^2\varphi \cot\psi + b_{T}(\varphi) \sin2\theta}{b_{D_{T}}(\omega)} \cdot t - \frac{\sin2\theta \sin^2\varphi \cot\psi [2\cos\theta + 1]}{4 b_{D_{T}}(\omega)} \cdot t^2.
\end{align*}
\vskip 5pt
    \ \underline{Cases (iv) and (v):} Let's notice that replacing $m_0(\varphi)$ by $-m_0(\varphi)$ and interchanging $c(\varphi)$ with $m_1(\varphi)$ in \eqref{eq:F_T case 1 slope-intercept} will produce \eqref{eq:F_T case 3 slope-intercept}. Applying the mentioned changes to \eqref{eq:F_D_T_case_(i)_big} and \eqref{eq:F_D_T_case_(ii)_big}, we complete the proof of the theorem in cases (iv) and (v), respectively. 

\vskip -5mm
\end{proof}

% Jump occurs at $x_{\max}(\omega) \approx 10.09$
% $\frac{x_{0}(\varphi)}{\cos\theta} \approx 5.85$

\begin{remark}
It follows from \eqref{eq:b_D omega} that
$b_{D_T}(\omega)=\frac{a(b+b_1)}{2}+b_T(\varphi)h\cos\theta.$ This expansion has not been used in the theorem.
\end{remark}

\begin{remark}
When $\theta=0$, one can check that $F_{D_T}\equiv F_T$. If $\theta=\frac{\pi}{2}$, then $F_{D_T}$ is a step function, which can be seen in Figure~\ref{fig:F_D_T}, example (c). The case (d) illustrates an example where the graph of the distribution function comprises of 4 pieces, 2 horizontal lines and 2 arcs of parabolas.
\end{remark}

\begin{figure}[h]
\vskip -5mm
    \centering
    \begin{subfigure}[t]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{P1_Trapezoid_case1_v2.png}
        \captionsetup{justification=centering}
        \caption{$a=5, b=10, h=5, \varphi = \frac{\pi}{2}, \theta=\frac{\pi}{4}, \psi = \frac{\pi}{4}$}
    \end{subfigure}%
    \begin{subfigure}[t]{0.45\textwidth}  
        \centering 
        \includegraphics[width=\textwidth]{P1_Trapezoid_case2_v2.png}
        \captionsetup{justification=centering}
        \caption{$a=10\sqrt{3}, b=20, h=15, \varphi = \frac{\pi}{3}, \theta=\arctan\frac{3}{4}, \psi = \frac{\pi}{3}$}
    \end{subfigure}
    \begin{subfigure}[t]{0.45\textwidth}   
        \centering 
        \includegraphics[width=\textwidth]{P1_Trapezoid_case3_v2.png}
        \captionsetup{justification=centering}
        \caption{$a=5, b=10, h=5, \varphi = \frac{\pi}{7}, \theta=\frac{\pi}{2}, \psi = \frac{4\pi}{9}$}
    \end{subfigure}%
    \begin{subfigure}[t]{0.45\textwidth}   
        \centering 
        \includegraphics[width=\textwidth]{P1_Trapezoid_case4_v2.png}
        \captionsetup{justification=centering}
        \caption{$a=5, b=10, h=10, \varphi = \frac{\pi}{20}, \theta=\frac{\pi}{6}, \psi = \frac{\pi}{4}$}
    \end{subfigure}
    \caption{Orientation dependent chord length distribution function $F_{D_T}$ for different cases}
    \label{fig:F_D_T}
\vskip -5mm
\end{figure}


% \vskip 5pt


\section{A standard image of a quadrilateral and its orientation-dependent characteristics}\label {Quadrilateral}
In a Cartesian plane, for any convex quadrilateral $\textbf{D}$ there are points $B(b,0),\,b>0$, $A\in \{(x,y):\,x\geq 0, y>0\} $, and $C\in \{(x,y):\,x>0, y>0\}$ such that $\textbf{D}$ is congruent to the quadrilateral $OACB$, where $O$ is the origin of coordinates. We will call such a quadrilateral \textbf{an image} of $\textbf{D}$. The side $OB$ will be called \textbf{the base}, the sides $OA$ and $BC$ will be called \textbf{legs}, $\alpha$ and $\beta$ will stand for the inclination angles (measured anticlockwise from the positive direction of $x$-axis)  of the legs $OA$ and $BC$, respectively. If $\alpha \leq \beta$ then the quadrilateral $OABC$ will be called \textbf{a standard image} of $\textbf{D}$ (see Figure~\ref{fig:standard_image}).


\vskip 10pt
\begin{figure}[h]
    \centering
    \begin{subfigure}[t]{0.65\textwidth}
        \centering
        \includegraphics[width=\textwidth]{P3_standard_image.png}
        \captionsetup{justification=centering}
    \end{subfigure}%    
    \caption{A standard image of $\textbf{D}$}
    \label{fig:standard_image}
\end{figure}



\begin{proposition} \label{proposition2.1}
Every convex quadrilateral $\textbf{D}$ has a standard image.
\end{proposition}
\begin{proof} Let $OACB$  be an image of $\textbf{D}$. Then let $\theta_A$ and $\theta_C$ be the internal angles at the vertices $A$ and $C$, respectively. If $\beta <\alpha$ then $\theta_A+\theta_C < \pi$. 

If $\theta_A<\frac{\pi}{2}$, consider the Euclidean transformation $\mathcal{T}$ that rotates the plane clockwise about the origin by $\alpha$ and then reflects it on the $x$-axis. Then $OA'C'B'$ becomes a standard image of $\textbf{D}$, where $A'=\mathcal{T}(B)$, $B'=\mathcal{T}(A)$, and $C'=\mathcal{T}(C)$. Indeed, if $\alpha'$ and $\beta'$ are the corresponding inclination angles of the legs $OA'$ and $B'C'$, then $$\alpha'=\alpha\leq\frac{\pi}{2}<\pi-\theta_A=\beta'.$$   

If $\theta_C<\frac{\pi}{2}$, let $\mathcal{T}$ be the translation by $\overrightarrow{CO}$ followed by the clockwise rotation by $\alpha+\theta_A$ about $O$. Denoting $A'=\mathcal{T}(B)$, $B'=\mathcal{T}(A)$, and $C'=\mathcal{T}(O)$ we again obtain a standard image of $\textbf{D}$ since
$$\alpha'=\theta_C<\pi-\theta_A=\beta'.$$
\end{proof}

In addition to the length of the base, $b$ and inclination angles of legs, $\alpha$ and $\beta$, we introduce two more parameters for $OACB$, a standard image of $\textbf{D}$. Let $\alpha_0$ and $\beta_0$ be the inclination angles of the diagonals $OC$ and $BA$, respectively. Obviously,
$\alpha_0<\alpha\leq\beta<\beta_0,$ and any standard image is determined by the five parameters $b, \alpha_0, \alpha, \beta, \beta_0$. We will utilise the notation
$$\textbf{D}_s=[b, \alpha_0, \alpha, \beta, \beta_0]$$
for a standard image. For example, a rectangle with sides of lengths $1$ and $\sqrt{3}$ has two standard images, $\textbf{D}_s^{(1)}=[1, \frac{\pi}{3}, \frac{\pi}{2}, \frac{\pi}{2}, \frac{2\pi}{3}]$ and $\textbf{D}_s^{(2)}=[\sqrt{3}, \frac{\pi}{6}, \frac{\pi}{2}, \frac{\pi}{2}, \frac{5\pi}{6}]$, as shown below in Figure~\ref{fig:standard_rectangles}.


% \vskip 5pt
\begin{figure}[h]
    \centering
    \begin{subfigure}[t]{0.8\textwidth}
        \centering
        \includegraphics[width=\textwidth]{P3_standard_rectangles.png}
        \captionsetup{justification=centering}
    \end{subfigure}%
    \caption{An example of two standard images of the same rectangle}
    \label{fig:standard_rectangles}
\end{figure}


The values $\alpha_0, \alpha, \beta, \beta_0$ determine another parameter $\gamma$, the inclination angle of $AC$. It is easy to check that $$\tan\gamma=\frac{\cot\alpha+\cot\beta-\cot\alpha_0-\cot\beta_0}{\cot\alpha\cot\beta-\cot\alpha_0\cot\beta_0}.$$

We classify the standard images into two categories based on the value of $\gamma$. Due to convexity of $\textbf{D}$, either $0\leq \gamma<\alpha_0$, or $\beta_0<\gamma<\pi$. If the first inequality occurs, we will call the standard image to be of \textbf{Type 1}, otherwise - of \textbf{Type 2}. For example, as shown in Figure~\ref{fig:5_standard_images}, a right-angled trapezoid has five standard images, where three of them are of Type 1, and two are of Type 2.

\vskip 10pt
\begin{figure}[h]
    \centering
    \begin{subfigure}[t]{0.9\textwidth}
        \centering
        \includegraphics[width=\textwidth]{P3_5_standard_images.png}
        \captionsetup{justification=centering}
    \end{subfigure}%    
    \caption{The five standard images of a right-angled trapezoid}
    \label{fig:5_standard_images}
\end{figure}

\vskip 5pt
\begin{figure}[h]
    \centering
    \begin{subfigure}[t]{0.7\textwidth}
        \centering
        \includegraphics[width=\textwidth]{P3_parallelogram_and_kite.png}
        \captionsetup{justification=centering}
    \end{subfigure}%    
    \caption{A standard image example of either Type 1, or Type 2}
    \label{fig:parallelogram_and_kite}
\end{figure}

Any parallelogram has only standard images of Type 1, whereas any kite with three congruent obtuse internal angles permits only standard images of Type 2 (see Figure~\ref{fig:parallelogram_and_kite}).


Let $\textbf{D}_s$ be a standard image of a convex quadrilateral  $\textbf{D}\subset \mathbb{R}^2$. Below, we employ the notations and terminology introduced earlier in Section \ref{Preliminaries 1} for the planar convex body $\textbf{E}$ and the vector $\phi=(\cos\varphi, \sin\varphi )\in \mathbb{S}^1$. 
Denote  
$$\Pi_\textbf{E}^x (\varphi)=\{y\in \Pi_\textbf{E}(\varphi):\chi(l_{\varphi}+y) \leq x\},$$
where $\Pi_\textbf{E}(\varphi)$ is the orthogonal projection of $\textbf{E}\subset \mathbb{R}^2$ onto $\phi^\perp$.
Assuming that $y$ is uniformly distributed over $\Pi_{\textbf{D}_s}(\varphi)$, the ODCLD function in direction $\phi$ for $\textbf{D}_s$ must be defined as  
\begin{equation}\label{Distribution function}
    F_{\textbf{D}_s}(x,\varphi) = {\frac {L_{1}\big(\Pi_{\textbf{D}_s}^x (\varphi)\big)}{b_{\textbf{D}_s}(\varphi)}},
\end{equation}
where $b_{\textbf{D}_s}(\varphi)=L_1(\Pi_{\textbf{D}_s}(\varphi))$.

Hereinafter, since $l_{\varphi-\pi}=l_{\varphi}$, we will assume $\varphi \in [0,\,\pi)$.

To determine the ODCLD function $F_{\textbf{D}_s}(x,\varphi)$ we use the quantities (introduced earlier in Section \ref{Right prism on a right trapezoid}) 
$$
x_{0}(\varphi) = \min\limits_{y \in \phi_v^\perp} \chi(l_{\varphi} + y) \,\,\,\text{and}\,\,\, x_{1}(\varphi) = \max\limits_{y \in \phi_v^\perp} \chi(l_{\varphi} + y), 
$$
where $\phi_v^\perp$ is the set of vectors $y \in \phi^\perp$ so that the line $l_{\varphi} + y$ passes through a vertex of $\textbf{D}_s$ and makes a chord of positive Lebesgue measure there. 


\vskip 5pt
\begin{figure}[h]
    \centering
    \begin{subfigure}[t]{0.8\textwidth}
        \centering
        \includegraphics[width=\textwidth]{P3_1st_2nd_order_diameters.png}
        \captionsetup{justification=centering}
    \end{subfigure}%    
    \caption{Examples of some first and second-order $\varphi$-diameters}
    \label{fig:1st_2nd_order_diameters}
\end{figure}


The quantity $x_{1}(\varphi)$ coincides with
$$x_{\max}(\varphi)=\max\limits_{y \in \Pi_{\textbf{D}_s}(\varphi)} \chi(l_{\varphi} + y),$$
and any chord of length $x_{\max}(\varphi)$ is known as a \textbf{$\varphi$-diameter} of $\textbf{D}_s$ (see \cite{Mount}, p. 248). In the upcoming text, where convenient, we will call it a \textbf{first-order $\varphi$-diameter} of $\textbf{D}_s$. Any chord of length $x_0(\varphi)$ will be called a \textbf{second-order $\varphi$-diameter} of $\textbf{D}_s$. Visual examples are shown in Figure~\ref{fig:1st_2nd_order_diameters}.


In addition to $x_0(\varphi)$ and $x_1(\varphi)$, we aim to introduce three more orientation-dependent characteristics  $\ell_0(\varphi)$, $\ell(\varphi)$, and $\ell_1(\varphi)$ of the standard image $\textbf{D}_s=[b, \alpha_0, \alpha, \beta, \beta_0]$. These characteristics will be non-negative continuous functions and will satisfy to $b_{\textbf{D}_s} (\varphi)=\ell_0(\varphi)+\ell(\varphi)+\ell_1(\varphi)$ for all $\varphi \in [0, \pi).$ We will call them \textbf{supplementary $\varphi$-measures} of $\textbf{D}_s.$ 


\textit{Case 1: $\textbf{D}_s$ has no parallel sides.} We have $\gamma >0$ and $\alpha < \beta$. Then for any $\varphi$ the first and the second-order $\varphi$-diameters are unique. Let them be $(l_{\varphi}+y_1) \cap \textbf{D}_s$ and $(l_{\varphi}+y_0) \cap \textbf{D}_s$, respectively. If $\varphi\neq \alpha_0$ and $\varphi\neq \beta_0$ then $y_0 \neq y_1$. In the case when $y_0, \,y_1 \in int \big(\Pi_{\textbf{D}_s}(\varphi)\big)$, they partition $\Pi_{\textbf{D}_s}(\varphi)$ into three segments: the middle segment, the side-segment adjacent to $y_0$, and the other side-segment adjacent to $y_1$. We denote the lengths of those segments by $\ell(\varphi)$, $\ell_0(\varphi)$, and $\ell_1(\varphi)$, respectively. A visual example is shown in Figure~\ref{fig:supplementary_measures_case_1}. If $y_0\in \partial \Pi_{\textbf{D}_s}(\varphi) $ or $y_1 \in \partial \Pi_{\textbf{D}_s}(\varphi)$, we define correspondingly $\ell_0(\varphi)=0$ or $\ell_1(\varphi)=0$. 

\vskip 10pt
\begin{figure}[h]
    \centering
    \begin{subfigure}[t]{0.6\textwidth}
        \centering
        \includegraphics[width=\textwidth]{P3_supplementary_measures_case_1.png}
        \captionsetup{justification=centering}
    \end{subfigure}%   
    \caption{An example when $\textbf{D}_s$ has no parallel sides}
    \label{fig:supplementary_measures_case_1}
\end{figure}


When $\varphi=\alpha_0$ or $\varphi=\beta_0$, the first and the second-order $\varphi$-diameters coincide. We extend the definitions of $\ell$, $\ell_0$, and $\ell_1$ preserving their continuous dependence on $\varphi$:
$$\ell(\alpha_0)=\ell(\beta_0)=|y_0-y_1|=0,$$
$$\ell_0(\alpha_0)=\lim_{\varphi \rightarrow \alpha_0} \ell_0 (\varphi), \,\, \ell_0(\beta_0)=\lim_{\varphi \rightarrow \beta_0} \ell_0 (\varphi),\ell_1(\alpha_0)=\lim_{\varphi \rightarrow \alpha_0} \ell_1 (\varphi), \,\, \ell_1(\beta_0)=\lim_{\varphi \rightarrow \beta_0} \ell_1 (\varphi).$$
\vskip 5pt
\textit{Case 2: $\textbf{D}_s$ has exactly one pair of parallel sides.} 

\textit{Subcase 2.1:} Let $\gamma =0$ and $\alpha < \beta$. Uniqueness of the first and the second-order $\varphi$-diameters takes place if and only if $\varphi \in [0, \alpha_0] \cup [\beta_0, \pi)$. If $\varphi\neq \alpha_0$ and $\varphi\neq \beta_0$, we define $y_0$, $y_1$, and then $\ell(\varphi)$, $\ell_0(\varphi)$, $\ell_1(\varphi)$ the same way we did it in Case 1. An illustration of this scenario is presented in Figure~\ref{fig:supplementary_measures_case_2_1}. 



% \vskip 10pt
\begin{figure}[h]
    \centering
    \begin{subfigure}[t]{0.65\textwidth}
        \centering
        \includegraphics[width=\textwidth]{P3_supplementary_measures_case_2_1.png}
        \captionsetup{justification=centering}
    \end{subfigure}%    
    \caption{An example when $\textbf{D}_s$ has exactly one pair of parallel sides}
    \label{fig:supplementary_measures_case_2_1}
\end{figure}




The values at $\alpha_0$ and $\beta_0$ are defined below:
$$\ell (\alpha_0)=\ell(\beta_0)=0,$$
$$\ell_0(\alpha_0)=\ell_0(\alpha_0-), \,\, \ell_0(\beta_0)=\ell_0(\beta_0+),\,\,\ell_1(\alpha_0)=\ell_1(\alpha_0-), \,\, \ell_1(\beta_0)=\ell_1(\beta_0+).$$




The case $\alpha_0 < \varphi <\beta_0$ yields $x_0(\varphi)=x_1(\varphi)$, so we face infinitely many $\varphi$-diameters. Here by $\ell(\varphi)$ we denote the distance between the two farthest $\varphi$ -diameters, $(l_{\varphi}+y_0) \cap \textbf{D}_s$ and $(l_{\varphi}+y_1) \cap \textbf{D}_s$. Using these vectors $y_0$ and $y_1$, we define $\ell(\varphi)$, $\ell_0(\varphi)$, $\ell_1(\varphi)$ again by the algorithm provided in Case 1.



\textit{Subcase 2.2:} Now let $\gamma > 0$ and $\alpha = \beta$. The first and the second-order $\varphi$-diameters are unique if and only if $\varphi \in [\alpha_0, \beta_0]$. For $\varphi \in (\alpha_0, \beta_0)$ we define $y_0$, $y_1$, and then $\ell(\varphi)$, $\ell_0(\varphi)$, $\ell_1(\varphi)$ by the algorithm of Case 1. For the boundary values we define
$$\ell (\alpha_0)=\ell(\beta_0)=0,$$
$$\ell_0(\alpha_0)=\ell_0(\alpha_0+), \,\, \ell_0(\beta_0)=\ell_0(\beta_0-),\,\,\ell_1(\alpha_0)=\ell_1(\alpha_0+), \,\, \ell_1(\beta_0)=\ell_1(\beta_0-).$$

If $\varphi \notin [\alpha_0, \beta_0]$ then $x_0(\varphi)=x_1(\varphi)$, so $\textbf{D}_s$ has infinitely many $\varphi$-diameters. We define $\ell(\varphi)$, $\ell_0(\varphi)$, $\ell_1(\varphi)$ the same way as we did it in Subcase 2.1 for $\varphi \in (\alpha_0, \beta_0)$. 

\textit{Case 3: $\textbf{D}_s$ has two pairs of parallel sides.}
In a parallelogram,  $x_0(\varphi)=x_1(\varphi)$ holds for any value of $\varphi$. 

\vskip 5pt
\begin{figure}[h]
    \centering
    \begin{subfigure}[t]{0.65\textwidth}
        \centering
        \includegraphics[width=\textwidth]{P3_supplementary_measures_case_3.png}
        \captionsetup{justification=centering}
    \end{subfigure}% 
    \caption{An example when $\textbf{D}_s$ has two pairs of parallel sides ($\gamma=0$ and $\alpha = \beta$)}
    \label{fig:supplementary_measures_case_3}
\end{figure}


We define  $$\ell(\varphi)=|y_0-y_1|,$$ and 
$$\ell_0(\varphi)=\ell_1(\varphi)=\frac{b_{\textbf{D}_s}(\varphi)-\ell(\varphi)}{2},$$
where $(l_{\varphi}+y_0) \cap \textbf{D}_s$ and $(l_{\varphi}+y_1) \cap \textbf{D}_s$ are the two farthest $\varphi$ - diameters of $\textbf{D}_s$. 

A visual example of this case is presented in Figure~\ref{fig:supplementary_measures_case_3}.




\section{ODCLD and the covariogram of a convex quadrilateral}\label{ODCLD and the covariogram of a convex quadrilateral}

The following theorem represents the function defined by the formula \eqref{Distribution function} in terms of its orientation-dependent characteristics, namely the lengths of orientation-dependent diameters and supplementary measures.
\begin{theorem}\label{Theorem CLD} Let $\textbf{D}_s$ be a standard image of a convex quadrilateral $\textbf{D}$ and $0\leq \varphi<\pi$. If $x_1, \, x_0$ are the lengths of respectively the first and the second-order $\varphi$-diameters, and $\ell_0,\, \ell,\, \ell_1$ are the supplementary $\varphi$-measures of $\textbf{D}_s$, then 
\begin{equation}\label{FDs piecewise}
    F_{\textbf{D}_s}(x,\varphi) = \frac{1}{\ell_0+\ell+\ell_1}
    \begin{cases}
        0, & \mbox{if \, $x < 0$} \\
        \displaystyle{\bigg(\frac{\ell_0}{x_0}+\frac{\ell_1}{x_1} \bigg)x}, & \mbox{if \, $0 \leq x < x_{0}(\varphi)$} \\
        \displaystyle{\ell_0+\frac{x-x_0}{x_1-x_0}\ell + \frac{x}{x_1}\ell_1}, & \mbox{if \, $x_{0}(\varphi) \leq x < x_{1}(\varphi)$} \\
        \ell_0+\ell+\ell_1, & \mbox{if \, $x \geq x_{1}(\varphi)$}
    \end{cases}.
\end{equation}

\end{theorem}

\begin{proof} The statement is obvious when $x<0$ or $x\geq x_1$. Below we assume $0\leq x < x_1$.

    \textit{Case A: $\varphi$ is such that $x_0(\varphi)<x_1(\varphi)$.} Let $(l_{\varphi}+y_1) \cap \textbf{D}_s$ and $(l_{\varphi}+y_0) \cap \textbf{D}_s$ be the first and second-order $\varphi$ - diameters of $\textbf{D}_s$. If $y_0, \,y_1 \in int \big(\Pi_{\textbf{D}_s}(\varphi)\big)$, then the mentioned diameters partition $\textbf{D}_s$ into two triangles $\textbf{T}_0(\varphi), \,\textbf{T}_1(\varphi)$,  and a trapezoid $\textbf{T}(\varphi)$, where $\textbf{T}_0$ is based on the second-order diameter and has a height of length $\ell_0$, $\textbf{T}_1$ is based on the first-order diameter and has a height of length $\ell_1$, and the trapezoid $\textbf{T}$ is based on the mentioned diameters and has a height of length $\ell$. Then 
    \begin{equation}\label{x-projections}
     L_1\big(\Pi_{\textbf{D}_s}^x (\varphi)\big)=\sum_{i=0}^1 L_1\big(\Pi_{\textbf{T}_i}^x (\varphi)\big)+L_1\big(\Pi_{\textbf{T}}^x (\varphi)\big).    
    \end{equation}

If $0\leq x<x_0$ then $\Pi_{\textbf{T}}^x (\varphi)=\varnothing$ and
$$L_1\big(\Pi_{\textbf{T}_i}^x (\varphi)\big)=\frac{x}{x_i}L_1\big(\Pi_{\textbf{T}_i} (\varphi)\big)=\frac{x}{x_i}\ell_i.$$

If $x_0\leq x < x_1$ then

$$L_1\big(\Pi_{\textbf{T}_0}^x (\varphi)\big)=L_1\big(\Pi_{\textbf{T}_0} (\varphi)\big)=\ell_0,$$

$$L_1\big(\Pi_{\textbf{T}_1}^x (\varphi)\big)=\frac{x}{x_1}L_1\big(\Pi_{\textbf{T}_1} (\varphi)\big)=\frac{x}{x_1}\ell_1,$$
and
$$L_1\big(\Pi_{\textbf{T}}^x (\varphi)\big)=\frac{x-x_0}{x_1-x_0}L_1\big(\Pi_{\textbf{T}} (\varphi)\big)=\frac{x-x_0}{x_1-x_0}\ell.$$

Now according to \eqref{Distribution function} and \eqref{x-projections}, we obtain
\begin{equation}\label{Distribution function for small values of x}
    F_{\textbf{D}_s}(x,\varphi) = \frac{1}{b_{\textbf{D}_s}(\varphi)}\bigg(\frac{x}{x_0}\ell_0+\frac{x}{x_1}\ell_1\bigg),\, \text{for}\,\,  0\leq x<x_0,
\end{equation}
and
\begin{equation}\label{Distribution function for large values of x}
    F_{\textbf{D}_s}(x,\varphi) = \frac{1}{b_{\textbf{D}_s}(\varphi)}\bigg(\ell_0+\frac{x-x_0}{x_1-x_0}\ell+\frac{x}{x_1}\ell_1\bigg), \, \text{for}\,\,  x_0\leq x<x_1.
\end{equation}

Formula \eqref{x-projections} works for such values of $\varphi$ that imply $y_i \not\in int \big(\Pi_{\textbf{D}_s}\big)$ for $i=0$ or $i=1$. In this case, $\textbf{T}_i$ turns into the segment $(l_{\varphi}+y_i) \cap \textbf{D}_s$, and yields
$$L_1\big(\Pi_{\textbf{T}_i}^x (\varphi)\big)=L_1\big(\Pi_{\textbf{T}_i} (\varphi)\big)=\ell_i(\varphi)=0.$$

    Since $l_i(\varphi)$ has been defined as a continuous function, the formulas \eqref{Distribution function for small values of x} and \eqref{Distribution function for large values of x} remain valid.

    \textit{Case B: $\varphi$ is such that $x_0(\varphi)=x_1(\varphi)$.} Consider $(l_{\varphi}+y_1) \cap \textbf{D}_s$ and $(l_{\varphi}+y_0) \cap \textbf{D}_s$, the two farthest $\varphi$ - diameters of $\textbf{D}_s$. If $y_0 \neq y_1$ and they both belong to $int \big(\Pi_{\textbf{D}_s}(\varphi)\big)$ then $\textbf{D}_S$ will be partitioned into the two triangles $\textbf{T}_0(\varphi), \,\textbf{T}_1(\varphi)$,  and the trapezoid $\textbf{T}(\varphi)$ defined in Case A. If $y_0=y_1$ or $y_i \not\in int \big(\Pi_{\textbf{D}_s}\big)$ for $i=0$ or $i=1$, then $\textbf{T}$, or correspondingly, $\textbf{T}_i$, turns into the segment $(l_{\varphi}+y_i) \cap \textbf{D}_s$. In all these scenarios the formula \eqref{x-projections} does operate, and since the functions $\ell_i(\varphi)$ are continuous, it implies \eqref{Distribution function for small values of x}.    
\end{proof}

\begin{corollary}\label{Jump in planar case}
The function $F_{\textbf{D}_s}(\cdot, \varphi)$ is continuous on the real axis if and only if the $\varphi$-diameter of $\textbf{D}_s$ is unique. If for some $\varphi$, the $\varphi$-diameter of $\textbf{D}_s$ is not unique then $F_{\textbf{D}_S}(\cdot, \varphi)$ holds a jump discontinuity at $x_{\max}(\varphi)$. The jump is equal to
$$\frac{\ell}{\ell_0+\ell+\ell_1}.$$
\end{corollary}
\begin{proof}
    A $\varphi$-diameter is unique if and only if $x_0(\varphi) < x_1(\varphi),$ or $x_0(\varphi) = x_1(\varphi)$ but $\ell(\varphi)=0$. Due to \eqref{FDs piecewise}, this is equivalent to the continuity of $F_{\textbf{D}_S}(\cdot, \varphi)$. 
    
    If a $\varphi$-diameter is not unique then $x_0(\varphi) = x_1(\varphi) = x_{max}(\varphi)$ and $\ell(\varphi)>0$. Hence,   $F_{\textbf{D}_s}(x_{max}(\varphi)+,\varphi)=1$ whereas $F_{\textbf{D}_s}(x_{max}(\varphi)-,\varphi)=\frac{\ell_0+\ell_1}{\ell_0+\ell+\ell_1}=1-\frac{\ell}{\ell_0+\ell+\ell_1}.$  
\end{proof}
\vskip 10pt
Below, the notation $C_{\textbf{E}}(t,\varphi)$ stands for the covariogram $C_{\textbf{E}}(t\phi)$), where $\textbf{E}\subset \mathbb{R}^2$ and $t\geq 0$. Further in this chapter, $\|\textbf{E}\|$ will denote the area of $\textbf{E}$.

\begin{theorem}\label{Covariogram quadrilateral} Let $\textbf{D}_s$ be a standard image of a convex quadrilateral $\textbf{D}$ and $0\leq \varphi<\pi$. If $x_1, \, x_0$ are the lengths of respectively the first and the second-order $\varphi$-diameters, and $\ell_0,\, \ell,\, \ell_1$ are the supplementary $\varphi$-measures of $\textbf{D}_s$, then 
$C_{\textbf{D}_s}(t,\varphi) = $
$$
    =
    \begin{cases}
        
        \displaystyle{\frac{x_0\ell_0+(x_0+x_1)\ell+x_1\ell_1}{2}-(\ell_0+\ell+\ell_1)t+\frac{1}{2}\bigg(\frac{\ell_0}{x_0}+\frac{\ell_1}{x_1} \bigg)t^2}, & \mbox{if \, $0 \leq t < x_{0}$} \\
        \displaystyle{\frac{1}{2}\bigg(\frac{\ell_1}{x_1} + \frac{\ell}{x_1-x_0}}\bigg)(x_1-t)^2, & \mbox{if \, $x_{0} \leq t < x_{1}$} \\
        0, & \mbox{if \, $t \geq x_1$}
    \end{cases}.
    $$
\end{theorem}

\begin{proof} The case $t\geq x_1$ is obvious so below we assume $0\leq t < x_1$.
   
   Due to the Matheron's formula \cite{Matheron}, p. 86, we have  
$$
\frac{\partial C_{\textbf{D}_s}(t, \varphi)}{\partial t}=-L_{1}\left(\left\{y \in \phi^{\perp}: L_{1}\left(\textbf{D}_s \cap\left(l_{\varphi}+y\right)\right) \geq t\right\}\right),
$$
which can be rewritten in terms of the orientation-dependent chord length distribution function as 
$$\frac{\partial C_{\textbf{D}_s}(t,\varphi)}{\partial t} = -b_{\textbf{D}_s}(\varphi) \cdot [1-F_{\textbf{D}_s}(t,\varphi)].$$
Integration of both parts of the last formula yields
\begin{equation} \label{eq:Matheron}
 C_{\textbf{D}_s}(t,\varphi) = C_{\textbf{D}_s}(0,\varphi) - b_{\textbf{D}_s}(\varphi) \cdot t + b_{\textbf{D}_s}(\varphi) \cdot \int_{0}^{t} F_{\textbf{D}_s}(u,\varphi) du, \; t\geq 0.
\end{equation} 
Since 
$$C_{\textbf{D}_s}(0,\varphi)= \|\textbf{D}_s\|=\frac{x_0\ell_0+(x_0+x_1)\ell+x_1\ell_1}{2},$$
$$b_{\textbf{D}_s} (\varphi)=\ell_0(\varphi)+\ell(\varphi)+\ell_1(\varphi),$$
and 
$$\int_0^t{\bigg(\frac{\ell_0}{x_0}+\frac{\ell_1}{x_1} \bigg)u}du=\frac{1}{2}\bigg(\frac{\ell_0}{x_0}+\frac{\ell_1}{x_1} \bigg)t^2,$$
then the required form of $C_{\textbf{D}_s}(t,\varphi)$, where $0 \leq t < x_{0}$, immediately follows from \eqref{eq:Matheron} and Theorem \ref{Theorem CLD}. 

If $x_{0} \leq t < x_{1}$ then we use the corresponding part of Theorem \ref{Theorem CLD} in \eqref{eq:Matheron}:
$$C_{\textbf{D}_s}(t,\varphi) = C_{\textbf{D}_s}(0,\varphi) - b_{\textbf{D}_s}(\varphi) \cdot t + \frac{1}{2}\bigg(\frac{\ell_0}{x_0}+\frac{\ell_1}{x_1} \bigg)x_0^2 + \int_{x_0}^{t} \ell_0+\frac{u-x_0}{x_1-x_0}\ell + \frac{u}{x_1}\ell_1 du.$$
Computation of the integral followed by the regrouping of similar terms produces 
$$C_{\textbf{D}_s}(t,\varphi) = \frac{x_1^2\ell}{2(x_1-x_0)}+\frac{x_1\ell_1}{2}-\bigg(\frac{x_1\ell}{x_1-x_0}+\ell_1\bigg)\cdot t+\frac{1}{2}\bigg(\frac{\ell_1}{x_1}+\frac{\ell}{x_1-x_0}\bigg)\cdot t^2 =$$
$$=\displaystyle{\frac{1}{2}\bigg(\frac{\ell_1}{x_1} + \frac{\ell}{x_1-x_0}}\bigg)(x_1-t)^2.$$
\end{proof}

\section{Computation of orientation-dependent characteristics}\label{Computative}

For a standard image $\textbf{D}_s=[b, \alpha_0, \alpha, \beta, \beta_0]$, we denote
$$\Lambda=\{\alpha, \, \beta\}, \,\, \Delta=\{\alpha_0, \, \beta_0\}, \,\, \Sigma=\{0,\,\alpha, \, \gamma,\, \beta\},$$
which are the sets of the inclination angles of the legs, diagonals, and the sides of $\textbf{D}_s$, respectively. For any $\varphi \in [0,\, \pi),$ we define the functions 
$X_{\varphi}:\Lambda \times \Delta \times \Sigma\setminus\{\varphi\} \longrightarrow \mathbb{R}$ and $L_{\varphi}:(\Lambda \times \Delta) \cup (\Delta \times \Lambda) \longrightarrow \mathbb{R}$ by
$$X_{\varphi}(x,\,y,\,z)=\frac{b\sin x \sin (y-z)}{\sin(y-x)\sin(z-\varphi)},$$
$$L_{\varphi}(x,\,y)=\frac{b\sin (x-\varphi) \sin y}{\sin(x-y)}.$$

\begin{theorem}\label{x values Type 1}
    Let $\textbf{D}_s=[b, \alpha_0, \alpha, \beta, \beta_0]$ be a standard image of Type 1 of a convex quadrilateral $\textbf{D}$. If $x_1, \, x_0$ are the lengths of respectively the first and the second-order $\varphi$-diameters of $\textbf{D}_s$, then
    \begin{enumerate}
        \item [i.]  $x_0(\varphi)= X_{\varphi}(\alpha,\,\beta_0,\,\beta) \,\, \textit{and} \, \,\, x_1(\varphi)= X_{\varphi}(\beta,\,\alpha_0,\,\beta),$ for $0\leq\varphi<\gamma$;
        \item [ii.]  $x_0(\varphi)= X_{\varphi}(\beta,\,\alpha_0,\,\alpha) \,\, \textit{and} \, \,\, x_1(\varphi)= X_{\varphi}(\beta,\,\alpha_0,\,\beta),$ for $\gamma\leq\varphi<\alpha_0$;
        \item [iii.]  $x_0(\varphi)= X_{\varphi}(\beta,\,\alpha_0,\,\gamma) \,\, \textit{and} \, \,\, x_1(\varphi)= X_{\varphi}(\beta,\,\alpha_0,\,0),$ for $\alpha_0\leq\varphi<\alpha$;
        \item [iv.]  $x_0(\varphi)= -X_{\varphi}(\alpha,\,\beta_0,\,0) \,\, \textit{and} \, \,\, x_1(\varphi)= X_{\varphi}(\beta,\,\alpha_0,\,0),$ for $\alpha\leq\varphi<\beta$;
        \item [v.]  $x_0(\varphi)= -X_{\varphi}(\alpha,\,\beta_0,\,0) \,\, \textit{and} \, \,\, x_1(\varphi)= -X_{\varphi}(\alpha,\,\beta_0,\,\gamma),$ for $\beta\leq\varphi<\beta_0$;
        \item [vi.]  $x_0(\varphi)= -X_{\varphi}(\alpha,\,\beta_0,\,\beta) \,\, \textit{and} \, \,\, x_1(\varphi)= -X_{\varphi}(\alpha,\,\beta_0,\,\alpha),$ for $\beta_0\leq\varphi<\pi$.
    \end{enumerate}
\end{theorem}

\begin{proof} Let the quadrilateral $\textbf{D}_s=OACB$ not have any pair of parallel sides. The lengths of the diagonals $AB$ and $OC$ are 
\begin{equation}\label{diagonals}
    d_{AB}=\frac{b\sin\alpha}{\sin(\beta_0-\alpha)} \,\,\, \text{and}\,\,\, d_{OC}=\frac{b\sin\beta}{\sin(\beta-\alpha_0)}.
\end{equation}
    We denote $\Pi_{\{A\}}(\varphi)=y_A$, $\Pi_{\{C\}}(\varphi)=y_C$, and $\Pi_{\{B\}}(\varphi)=y_B$. Then the first and the second-order $\varphi$-diameters of $\textbf{D}_s$ are respectively equal to
\begin{equation}\label{diameters} 
    \begin{cases}
        l_{\varphi}\cap \textbf{D}_s\, \, \, \text{and} \,\,\,(l_{\varphi}+y_A)\cap \textbf{D}_s, & \mbox{if \, $0\leq\varphi<\gamma$} \\
        l_{\varphi}\cap \textbf{D}_s\, \, \, \text{and} \,\,\,(l_{\varphi}+y_C)\cap \textbf{D}_s, & \mbox{if \, $\gamma\leq\varphi<\alpha_0$} \\
        (l_{\varphi}+y_C)\cap \textbf{D}_s\, \, \, \text{and} \,\,\,l_{\varphi}\cap \textbf{D}_s, & \mbox{if \, $\alpha_0\leq\varphi<\alpha$} \\
        (l_{\varphi}+y_C)\cap \textbf{D}_s\, \, \, \text{and} \,\,\,(l_{\varphi}+y_A)\cap \textbf{D}_s, & \mbox{if \, $\alpha\leq\varphi<\beta$} \\
        (l_{\varphi}+y_B)\cap \textbf{D}_s\, \, \, \text{and} \,\,\,(l_{\varphi}+y_A)\cap \textbf{D}_s, & \mbox{if \, $\beta\leq\varphi<\pi$}
    \end{cases}.
\end{equation}

    To compute $x_0(\varphi)$ we initially assume that the chosen direction $\phi$ is not parallel to any side or a diagonal of $\textbf{D}_s$, which means $\varphi \not \in \Delta\cup \Sigma$. This allows us to determine uniquely the triangle, where one of its sides is the second-order diameter of $\textbf{D}_s$ and another side is the diagonal that shares an endpoint with the mentioned diameter. In that triangle, the internal angles that occurred in front of the second-order diameter and in front of the corresponding diagonal, are respectively equal to  
    $$\beta_0-\beta\, \, \, \text{and} \,\,\,\beta-\varphi,\, \, \text{if}\,\, 0<\varphi<\gamma;\,\,\,\, \alpha-\alpha_0\, \, \, \text{and} \,\,\,\pi-\alpha+\varphi,\, \, \text{if}\,\, \gamma<\varphi<\alpha_0; $$
 $$\alpha_0-\gamma\, \, \, \text{and} \,\,\,\pi-\varphi+\gamma,\, \, \text{if}\,\, \alpha_0<\varphi<\alpha;\,\,\,\, \pi-\beta_0\, \, \, \text{and} \,\,\,\varphi,\, \, \text{if}\,\, \alpha<\varphi<\beta; $$     
  $$\pi-\beta_0\, \, \, \text{and} \,\,\,\varphi,\, \, \text{if}\,\, \beta<\varphi<\beta_0;\,\,\,\, \beta_0-\beta\, \, \, \text{and} \,\,\,\pi-\varphi+\beta,\, \, \text{if}\,\, \beta_0<\varphi<\pi. $$ 

  Since $x_0 \in C[0,\pi)$, by \eqref{diagonals}, \eqref{diameters} and the Law of sines we conclude
\begin{equation}\label{x_0 values}
    x_0(\varphi) = 
    \begin{cases}
        d_{AB}\displaystyle{\frac{\sin(\beta_0-\beta)}{\sin(\beta-\varphi)}}=X_{\varphi}(\alpha,\,\beta_0,\,\beta), & \mbox{if \, $0\leq\varphi<\gamma$} \\
        d_{OC}\displaystyle{\frac{\sin(\alpha-\alpha_0)}{\sin(\alpha-\varphi)}}=X_{\varphi}(\beta,\,\alpha_0,\,\alpha), & \mbox{if \, $\gamma\leq\varphi<\alpha_0$} \\
        d_{OC}\displaystyle{\frac{\sin(\alpha_0-\gamma)}{\sin(\varphi-\gamma)}}=X_{\varphi}(\beta,\,\alpha_0,\,\gamma), & \mbox{if \, $\alpha_0\leq\varphi<\alpha$} \\
        d_{AB}\displaystyle{\frac{\sin\beta_0}{\sin\varphi}}=-X_{\varphi}(\alpha,\,\beta_0,\,0), & \mbox{if \, $\alpha\leq\varphi<\beta_0$} \\
        d_{AB}\displaystyle{\frac{\sin(\beta_0-\beta)}{\sin(\varphi-\beta)}}=-X_{\varphi}(\alpha,\,\beta_0,\,\beta), & \mbox{if \, $\beta_0\leq\varphi<\pi$}
    \end{cases}.
\end{equation}

To prove the required identities for  $x_1(\varphi)$ we assume again that $\varphi \not \in \Delta\cup \Sigma$. Consider the triangle, where one of its sides is the first-order diameter of $\textbf{D}_s$ and another side is the diagonal that shares an endpoint with the mentioned diameter. In this case, the internal angles of the triangle that occurred in front of the first-order diameter and in front of the corresponding diagonal, are respectively equal to
  $$\beta-\alpha_0\, \, \, \text{and} \,\,\,\pi-\beta+\varphi,\, \, \text{if}\,\, 0<\varphi<\gamma\,\,\text{or} \,\, \gamma<\varphi<\alpha_0; $$
 $$\alpha_0\, \, \, \text{and} \,\,\,\pi-\varphi,\, \, \text{if}\,\, \alpha_0<\varphi<\alpha \, \, \text{or} \,\, \alpha<\varphi<\beta; $$     
  $$\pi-\beta_0+\gamma\, \, \, \text{and} \,\,\,\varphi-\gamma,\, \, \text{if}\,\, \beta<\varphi<\beta_0;\,\,\,\, \beta_0-\alpha\, \, \, \text{and} \,\,\,\pi-\varphi+\alpha,\, \, \text{if}\,\, \beta_0<\varphi<\pi. $$

  As  $x_1 \in C[0,\pi)$, we obtain

\begin{equation}\label{x_1 values}
    x_1(\varphi) = 
    \begin{cases}
        d_{OC}\displaystyle{\frac{\sin(\beta-\alpha_0)}{\sin(\beta-\varphi)}}=X_{\varphi}(\beta,\,\alpha_0,\,\beta), & \mbox{if \, $0\leq\varphi<\alpha_0$} \\
        d_{OC}\displaystyle{\frac{\sin\alpha_0}{\sin\varphi}}=X_{\varphi}(\beta,\,\alpha_0,\,0), & \mbox{if \, $\alpha_0\leq\varphi<\beta$} \\
        d_{AB}\displaystyle{\frac{\sin(\beta_0-\gamma)}{\sin(\varphi-\gamma)}}=-X_{\varphi}(\alpha,\,\beta_0,\,\gamma), & \mbox{if \, $\beta\leq\varphi<\beta_0$} \\
        d_{AB}\displaystyle{\frac{\sin(\beta_0-\alpha)}{\sin(\varphi-\alpha)}}=-X_{\varphi}(\alpha,\,\beta_0,\,\alpha), & \mbox{if \, $\beta_0\leq\varphi<\pi$} \\
    \end{cases}.
\end{equation}

  It remains to notice that the formulas \eqref{x_0 values} and \eqref{x_1 values} also hold if $\gamma=0$ or $\alpha=\beta$.
 
\end{proof}

\begin{theorem}\label{l values Type 1}
    Let $\textbf{D}_s=[b, \alpha_0, \alpha, \beta, \beta_0]$ be a standard image of Type 1 of a convex quadrilateral $\textbf{D}$. If $\ell_0, \, \ell$ and $\ell_1$ are the supplementary $\varphi$-measures of $\textbf{D}_s$, then
\begin{equation}\label{ell_0 values}
   \ell_0(\varphi) = 
   \begin{cases}
       L_{\varphi}(\alpha,\,\beta_0)- L_{\varphi}(\alpha_0,\,\beta), & \mbox{if \, $0\leq\varphi<\gamma$} \\
       L_{\varphi}(\alpha_0,\,\beta)- L_{\varphi}(\alpha,\,\beta_0), & \mbox{if \, $\gamma\leq\varphi<\alpha_0$  \text{or}\,\,$\beta_0\leq\varphi<\pi$} \\
      -L_{\varphi}(\alpha,\,\beta_0), & \mbox{if \, $\alpha_0\leq\varphi<\alpha$} \\
       L_{\varphi}(\alpha,\,\beta_0), & \mbox{if \, $\alpha\leq\varphi<\beta_0$}
  \end{cases},
\end{equation}
\begin{equation}\label{ell values}
   \ell(\varphi) = 
   \begin{cases}
       -L_{\varphi}(\alpha,\,\beta_0), & \mbox{if \, $0\leq\varphi<\gamma$} \\
       -L_{\varphi}(\alpha_0,\,\beta), & \mbox{if \, $\gamma\leq\varphi<\alpha_0$} \\
      L_{\varphi}(\alpha_0,\,\beta), & \mbox{if \, $\alpha_0\leq\varphi<\alpha$} \\
      L_{\varphi}(\alpha_0,\,\beta)-L_{\varphi}(\alpha, \, \beta_0), & \mbox{if \, $\alpha\leq\varphi<\beta$}\\
       L_{\varphi}(\beta_0,\,\alpha), & \mbox{if \, $\beta\leq\varphi<\beta_0$}\\
     -L_{\varphi}(\beta_0,\,\alpha), & \mbox{if \, $\beta_0\leq\varphi<\pi$}
   \end{cases},
   \end{equation}
\begin{equation}\label{ell1 values}
   \ell_1(\varphi) = 
   \begin{cases}
       b\sin\varphi, & \mbox{if \, $0\leq\varphi<\alpha_0$  \text{or}\,\,$\beta_0\leq\varphi<\pi$} \\
       L_{\varphi}(\beta,\,\alpha_0), & \mbox{if \, $\alpha_0\leq\varphi<\beta$} \\
       -L_{\varphi}(\beta,\,\alpha_0), & \mbox{if \, $\beta\leq\varphi<\beta_0$}
  \end{cases}.
\end{equation}
    \end{theorem}
\begin{proof}
First of all we notice that
\begin{equation}\label{projection statement}
  L_1(\Pi_\textbf{E}(\varphi))=L_1(\textbf{E})\sin|\varepsilon-\varphi|,  
\end{equation}
for any line segment $\textbf{E}\subset \mathbb{R}^2$, $L_1(\textbf{E})<\infty$ inclined by $\varepsilon\in [0, \,\pi)$. When $\textbf{E}$ is a diagonal of $\textbf{D}_s$, then $L_1(\textbf{E})$ can be read from \eqref{diagonals}. If $\textbf{E}$ is a leg, we use either of the notations    
\begin{equation}\label{legs}
    s_{OA}=\frac{b\sin\beta_0}{\sin(\beta_0-\alpha)} \,\,\, \text{and}\,\,\, s_{CB}=\frac{b\sin\alpha_0}{\sin(\beta-\alpha_0)}
\end{equation}
for its length.
    
    Let us first prove \eqref{ell values}. For $\varphi$, being in either of the six intervals 
    $$[0,\gamma), \, [\gamma, \alpha_0), [\alpha_0, \alpha),\, [\alpha, \beta), \,[\beta, \beta_0), \, [\beta_0, \pi),$$
    the corresponding six-term sequence of the quantity $\ell(\varphi)$ becomes
    $$L_1(\Pi_{OA}(\varphi)),\, L_1(\Pi_{OC}(\varphi)),\, L_1(\Pi_{OC}(\varphi)),\, L_1(\Pi_{OC}(\varphi))-L_1(\Pi_{OA}(\varphi)),$$ $$ L_1(\Pi_{AB}(\varphi)),\,L_1(\Pi_{AB}(\varphi)).$$ 
    Since the inclination angles of $OA$, $OC$, and $AB$ are respectively $\alpha$, $\alpha_0$, and $\beta_0$, the formulas \eqref{projection statement}, \eqref{legs}, \eqref{diagonals} yield $\ell(\varphi) =$ 
    $$ 
   \begin{cases}
       s_{OA}\sin|\alpha-\varphi|=\displaystyle{\frac{b\sin\beta_0}{\sin(\beta_0-\alpha)}}\sin(\alpha-\varphi)=-L_{\varphi}(\alpha,\,\beta_0), & \mbox{if \, $0\leq\varphi<\gamma$} \\
       d_{OC}\sin|\alpha_0-\varphi|=\displaystyle{\frac{b\sin\beta}{\sin(\beta-\alpha_0)}}\sin(\alpha_0-\varphi)=-L_{\varphi}(\alpha_0,\,\beta), & \mbox{if \, $\gamma\leq\varphi<\alpha_0$} \\
      d_{OC}\sin|\alpha_0-\varphi|=\displaystyle{\frac{b\sin\beta}{\sin(\beta-\alpha_0)}}\sin(\varphi-\alpha_0)=L_{\varphi}(\alpha_0,\,\beta), & \mbox{if \, $\alpha_0\leq\varphi<\alpha$} \\
      d_{OC}\sin|\alpha_0-\varphi|-s_{OA}\sin|\alpha-\varphi|=L_{\varphi}(\alpha_0,\,\beta)-L_{\varphi}(\alpha,\,\beta_0), & \mbox{if \, $\alpha\leq\varphi<\beta$}\\
       d_{AB}\sin|\beta_0-\varphi|=\displaystyle{\frac{b\sin\alpha}{\sin(\beta_0-\alpha)}}\sin(\beta_0-\varphi)=L_{\varphi}(\beta_0,\,\alpha), & \mbox{if \, $\beta\leq\varphi<\beta_0$}\\
     d_{AB}\sin|\beta_0-\varphi|=\displaystyle{\frac{b\sin\alpha}{\sin(\beta_0-\alpha)}}\sin(\varphi-\beta_0)=-L_{\varphi}(\beta_0,\,\alpha), & \mbox{if \, $\beta_0\leq\varphi<\pi$}
   \end{cases}.
    $$
    Similarly, $\ell_0(\varphi)=$
     $$ 
   \begin{cases}
       d_{OC}\sin|\alpha_0-\varphi|-s_{OA}\sin|\alpha-\varphi|=L_{\varphi}(\alpha,\,\beta_0)-L_{\varphi}(\alpha_0,\,\beta), & \mbox{if \, $0\leq\varphi<\gamma$} \\
       s_{OA}\sin|\alpha-\varphi|-d_{OC}\sin|\alpha_0-\varphi|=L_{\varphi}(\alpha_0,\,\beta)-L_{\varphi}(\alpha,\,\beta_0), & \mbox{if \, $\gamma\leq\varphi<\alpha_0$} \\
      s_{OA}\sin|\alpha-\varphi|=-L_{\varphi}(\alpha,\,\beta_0), & \mbox{if \, $\alpha_0\leq\varphi<\alpha$} \\
      s_{OA}\sin|\alpha-\varphi|=L_{\varphi}(\alpha,\,\beta_0), & \mbox{if \, $\alpha\leq\varphi<\beta$}\\
        s_{OA}\sin|\alpha-\varphi|=L_{\varphi}(\alpha,\,\beta_0), & \mbox{if \, $\beta\leq\varphi<\beta_0$}\\
     d_{OC}\sin|\alpha_0-\varphi|-s_{OA}\sin|\alpha-\varphi|=L_{\varphi}(\alpha_0,\,\beta)-L_{\varphi}(\alpha,\,\beta_0), & \mbox{if \, $\beta_0\leq\varphi<\pi$}
   \end{cases},
    $$ 
and 
$$\ell_1(\varphi)= 
   \begin{cases}
       b\sin|0-\varphi|=b\sin\varphi, & \mbox{if \, $0\leq\varphi<\gamma$} \\
       b\sin|0-\varphi|=b\sin\varphi, & \mbox{if \, $\gamma\leq\varphi<\alpha_0$} \\
      s_{CB}\sin|\beta-\varphi|=L_{\varphi}(\beta,\,\alpha_0), & \mbox{if \, $\alpha_0\leq\varphi<\alpha$} \\
      s_{CB}\sin|\beta-\varphi|=L_{\varphi}(\beta,\,\alpha_0), & \mbox{if \, $\alpha\leq\varphi<\beta$}\\
         s_{CB}\sin|\beta-\varphi|=-L_{\varphi}(\beta,\,\alpha_0), & \mbox{if \, $\beta\leq\varphi<\beta_0$}\\
     b\sin|0-\varphi|=b\sin\varphi, & \mbox{if \, $\beta_0\leq\varphi<\pi$}
   \end{cases},
    $$
which are equivalent to \eqref{ell_0 values} and \eqref{ell1 values}, respectively.
\vskip -6mm
\end{proof}


    \begin{corollary} \label{bDs values Type 1}
       If a standard image $\textbf{D}_s=[b, \alpha_0, \alpha, \beta, \beta_0]$ of a convex quadrilateral is of Type 1 then 
       \begin{equation}\label{bDs values}
   b_{\textbf{D}_s}(\varphi) = 
   \begin{cases}
       L_{\varphi}(\beta,\,\alpha_0), & \mbox{if \, $0\leq\varphi<\gamma$} \\
       L_{\varphi}(\beta_0,\,\alpha), & \mbox{if \, $\gamma\leq\varphi<\alpha$} \\
      b\sin\varphi, & \mbox{if \, $\alpha \leq\varphi<\beta$} \\
       L_{\varphi}(\alpha_0,\,\beta), & \mbox{if \, $\beta\leq\varphi<\pi$}
  \end{cases}.
\end{equation}
    \end{corollary}
    \begin{proof}
    Since $b_{\textbf{D}_s}(\varphi)=\ell_0(\varphi)+\ell(\varphi)+\ell_1(\varphi)$, we substitute $\ell_0(\varphi)$, $\ell(\varphi)$, and $\ell_1(\varphi)$ by their corresponding expressions from \eqref{ell_0 values}, \eqref{ell values}, and \eqref{ell1 values}. To reach \eqref{bDs values}, it remains to check the identity $L_{\varphi}(x,y)+L_{\varphi}(y,x)=b\sin\varphi$ over the domain of $L_{\varphi}$.

\vskip 3pt
    
\end{proof}


The proofs of the following results for a standard image of Type 2 are omitted since they are similar to the ones provided for Type 1.  
\begin{theorem}\label{x values Type 2}
    Let $\textbf{D}_s=[b, \alpha_0, \alpha, \beta, \beta_0]$ be a standard image of Type 2 of a convex quadrilateral $\textbf{D}$. If $x_1, \, x_0$ are the lengths of respectively the first and the second-order $\varphi$-diameters of $\textbf{D}_s$, then
    \begin{enumerate}
        \item [i.]  $x_0(\varphi)= X_{\varphi}(\beta,\,\alpha_0,\,\alpha) \,\, \textit{and} \, \,\, x_1(\varphi)= X_{\varphi}(\beta,\,\alpha_0,\,\beta),$ for $0\leq\varphi<\alpha_0$;
        \item [ii.]  $x_0(\varphi)= X_{\varphi}(\beta,\,\alpha_0,\,0) \,\, \textit{and} \, \,\, x_1(\varphi)= X_{\varphi}(\beta,\,\alpha_0,\,\gamma),$ for $\alpha_0\leq\varphi<\alpha$;
        \item [iii.]  $x_0(\varphi)= X_{\varphi}(\beta,\,\alpha_0,\,0) \,\, \textit{and} \, \,\, x_1(\varphi)= -X_{\varphi}(\alpha,\,\beta_0,\,0),$ for $\alpha\leq\varphi<\beta$;
        \item [iv.]  $x_0(\varphi)= -X_{\varphi}(\alpha,\,\beta_0,\,\gamma) \,\, \textit{and} \, \,\, x_1(\varphi)= -X_{\varphi}(\alpha,\,\beta_0,\,0),$ for $\beta\leq\varphi<\beta_0$;
        \item [v.]  $x_0(\varphi)= -X_{\varphi}(\alpha,\,\beta_0,\,\beta) \,\, \textit{and} \, \,\, x_1(\varphi)= -X_{\varphi}(\alpha,\,\beta_0,\,\alpha),$ for $\beta_0\leq\varphi<\gamma$;
        \item [vi.]  $x_0(\varphi)= -X_{\varphi}(\beta,\,\alpha_0,\,\alpha) \,\, \textit{and} \, \,\, x_1(\varphi)= -X_{\varphi}(\alpha,\,\beta_0,\,\alpha),$ for $\gamma\leq\varphi<\pi$.
   \end{enumerate}
\end{theorem}

\newpage
\begin{theorem}\label{l values Type 2}
    Let $\textbf{D}_s=[b, \alpha_0, \alpha, \beta, \beta_0]$ be a standard image of Type 2 of a convex quadrilateral $\textbf{D}$. If $\ell_0, \, \ell$ and $\ell_1$ are the supplementary $\varphi$-measures of $\textbf{D}_s$, then
$$
   \ell_0(\varphi) = 
   \begin{cases}
       L_{\varphi}(\beta_0,\,\alpha)- L_{\varphi}(\beta,\,\alpha_0), & \mbox{if \, $0\leq\varphi<\alpha_0$ \text{or}\,\, $\beta_0\leq\varphi <\gamma$} \\
       L_{\varphi}(\beta,\,\alpha_0), & \mbox{if \, $\alpha_0\leq\varphi<\beta$} \\
      -L_{\varphi}(\beta,\,\alpha_0), & \mbox{if \, $\beta\leq\varphi<\beta_0$} \\
       L_{\varphi}(\beta,\,\alpha_0)- L_{\varphi}(\beta_0,\,\alpha), & \mbox{if \, $\gamma\leq\varphi<\pi$}
  \end{cases},
$$
$$
   \ell(\varphi) = 
   \begin{cases}
       -L_{\varphi}(\alpha_0,\,\beta), & \mbox{if \, $0\leq\varphi<\alpha_0$} \\
       L_{\varphi}(\alpha_0,\,\beta), & \mbox{if \, $\alpha_0\leq\varphi<\alpha$} \\
      L_{\varphi}(\beta_0,\,\alpha)-L_{\varphi}(\beta,\,\alpha_0), & \mbox{if \, $\alpha\leq\varphi<\beta$} \\
      L_{\varphi}(\beta_0,\,\alpha), & \mbox{if \, $\beta\leq\varphi<\beta_0$}\\
       -L_{\varphi}(\beta_0,\,\alpha), & \mbox{if \, $\beta_0\leq\varphi<\gamma$}\\
     -L_{\varphi}(\beta,\,\alpha_0), & \mbox{if \, $\gamma\leq\varphi<\pi$}
   \end{cases},
  $$
$$
   \ell_1(\varphi) = 
   \begin{cases}\label{ell_1 values}
       b\sin\varphi, & \mbox{if \, $0\leq\varphi<\alpha_0$  \text{or}\,\,$\beta_0\leq\varphi<\pi$} \\
       -L_{\varphi}(\alpha,\,\beta_0), & \mbox{if \, $\alpha_0\leq\varphi<\alpha$} \\
       L_{\varphi}(\alpha,\,\beta_0), & \mbox{if \, $\alpha\leq\varphi<\beta_0$}
  \end{cases}.
$$
    \end{theorem}

     \begin{corollary}\label{bDs values Type 2}
       If a standard image $\textbf{D}_s=[b, \alpha_0, \alpha, \beta, \beta_0]$ of a convex quadrilateral is of Type 2 then 
  $$     
    b_{\textbf{D}_s}(\varphi) = 
   \begin{cases}
       L_{\varphi}(\beta_0,\,\alpha), & \mbox{if \, $0\leq\varphi<\alpha$} \\
       b\sin\varphi, & \mbox{if \, $\alpha\leq\varphi<\beta$} \\
      L_{\varphi}(\alpha_0,\,\beta), & \mbox{if \, $\beta \leq\varphi<\gamma$} \\
       L_{\varphi}(\alpha,\,\beta_0), & \mbox{if \, $\gamma\leq\varphi<\pi$}
  \end{cases}.
$$
    \end{corollary}




\section{ODCLD and the covariogram of a convex quadrilateral prism}

Denote by $\textbf{D}_{s}^h$ the right prism $\{(x,y,z): (x,y)\in \textbf{D}_s,\, 0 < z \leq h\}$, where $\textbf{D}_s$ is a standard image of a convex quadrilateral. For a vector 
$$\omega =(\cos\varphi\cos\theta,\,\sin\varphi\cos\theta,\,\sin\theta) \in \mathbb{S}^2,$$
 let $\omega^\perp$ be the orthogonal complement of $\{t\omega\,:\, t\in \mathbb{R}\}$ in $\mathbb{R}^3$, and $\Pi_{\textbf{D}_s^h}(\varphi, \theta)$ be the orthogonal projection of $\textbf{D}_s^h$ onto the plane $\omega^\perp$.

We define the chord length distribution function in direction $\omega$ for $\textbf{D}_s^h$ by 
$$
F_{\textbf{D}_s^h}(t,\varphi,\theta) = {\frac {L_{2}\{y\in \Pi_{\textbf{D}_s^h}(\varphi, \theta):\chi(l_{(\varphi, \theta)}+y) \leq t\}}{b_{\textbf{D}_s^h}(\varphi, \theta)}},
$$   
where $l_{(\varphi, \theta)}+y$ is the line that passes through $y\in \omega^\perp$ and has direction vector $\omega$, 
$$\chi(l_{(\varphi, \theta)}+y) = L_{1}\big((l_{(\varphi, \theta)}+y\big) \cap \textbf{D}_s^h),$$
and
$$b_{{\textbf{D}}_s^h}(\varphi, \theta)=L_2(\Pi_{\textbf{D}_s^h}(\varphi, \theta)).$$

As $\{z\in \mathbb{R}^3:\,\,z=\frac{h}{2}\}$ is a plane of symmetry of $\textbf{D}_s^h$, we notice that  
$F_{\textbf{D}_s^h}(t,\varphi,\theta)=F_{\textbf{D}_s^h}(t,\varphi-\pi,\theta), \,\,\text{for}\,\,\varphi\in [\pi, 2\pi)$ and
$F_{\textbf{D}_s^h}(t,\varphi,\theta)=F_{\textbf{D}_s^h}(t,\varphi,-\theta).$
Based on this observation, from now on we will assume that $\varphi\in [0,\,\pi)$ and $\theta\in [0,\,\frac{\pi}{2}]$. 

Denote
$$x_{\max}(\varphi, \theta) = \max\limits_{y \in \Pi_{\textbf{D}_s^h}(\varphi, \theta)} \chi(l_{(\varphi, \theta)}+y).$$

It is easy to check that
\begin{equation}\label{x_max omega}
    x_{\max}(\varphi, \theta) = 
    \begin{cases}
        \frac{x_{\max}(\varphi)}{\cos\theta}, & \mbox{if \, $0 \leq \theta \leq \tan^{-1}\frac{h}{x_{\max}(\varphi)}$} \\
        \frac{h}{\sin\theta}, & \mbox{if \, $\tan^{-1}\frac{h}{x_{\max}(\varphi)}< \theta \leq \frac{\pi}{2} $} 
    \end{cases}.
\end{equation}


\begin{theorem}\label{Theorem CLD prism} For a $\varphi\in [0,\,\pi)$, let $x_1$ and $x_0$ be the lengths of the first and the second-order $\varphi$-diameters of $\textbf{D}_s$, respectively. Let $\ell_0,\, \ell,\, \ell_1$ be the supplementary $\varphi$-measures of $\textbf{D}_s$, and denote $b_{\textbf{D}_s}=\ell_0+\ell+\ell_1$. Then, for the direction $\omega =(\cos\varphi\cos\theta,\,\sin\varphi\cos\theta,\,\sin\theta), \,0\leq\theta\leq \frac{\pi}{2}$ and the prism $\textbf{D}_{s}^h$, the following statements take place:


    \textbf{(a)} If $\tan^{-1}\frac{h}{x_0}<\theta\leq\frac{\pi}{2}$ and $0\leq t < x_{\max}(\varphi, \theta)$, or $0\leq\theta\leq\tan^{-1}\frac{h}{x_0}$ and $0\leq t<x_{0}\sec\theta$, then 
    \begin{equation}\label{F_prism(i)}
    F_{\textbf{D}_s^h}(t,\varphi,\theta) =\frac{a_1t+a_2t^2}{\|\textbf{D}_s\|\sin\theta+b_{\textbf{D}_s}h\cos\theta},
\end{equation}
where 
$$a_1=h\bigg(\frac{\ell_0}{x_0}+\frac{\ell_1}{x_1}\bigg)\cos^2\theta+b_{\textbf{D}_s}\sin2\theta,\,\,\,a_2=-\frac{3}{2}\bigg(\frac{\ell_0}{x_0}+\frac{\ell_1}{x_1}\bigg)\sin\theta\cos^2\theta;$$
\vskip 10pt
 \textbf{(b)} If $0\leq\theta\leq\tan^{-1}\frac{h}{x_0}$ and $x_{0}\sec\theta\leq t<x_{\max}(\varphi, \theta)$, then $x_0<x_1$ and 
    \begin{equation}\label{F_prism(ii)}
    F_{\textbf{D}_s^h}(t,\varphi,\theta) =\frac{c_0+c_1t+c_2t^2}{\|\textbf{D}_s\|\sin\theta+b_{\textbf{D}_s}h\cos\theta},
\end{equation}
 where
 $$c_0=(h\cos\theta+\frac{x_0}{2}\sin\theta)\bigg(\ell_0-\frac{\ell x_0}{x_1-x_0}\bigg),$$
$$c_1=(h\cos^2\theta+x_1\sin2\theta)\bigg(\frac{\ell}{x_1-x_0}+\frac{\ell_1}{x_1}\bigg),\,\,\,c_2=-\frac{3}{2}\sin\theta\cos^2\theta\bigg(\frac{\ell}{x_1-x_0}+\frac{\ell_1}{x_1}\bigg).$$   
\end{theorem}

\begin{proof}
    Using the formula (see \cite{HO_Cylinder}) that establishes a relation between the orientation-dependent chord length distribution functions of a cylinder and its base, for $0 \leq t<x_{\max}(\varphi, \theta)$ we obtain 
\begin{equation}\label{CLDs}
\begin{gathered}
  F_{\textbf{D}_s^h}(t,\varphi, \theta)=\frac{b_{\textbf{D}_s}\cos \theta}{\|\textbf{D}_s\|\sin\theta+b_{\textbf{D}_s}h\cos\theta}\times \\ \times \bigg[ (h-t \sin \theta) F_{\textbf{D}_s}(t \cos \theta, \varphi)+2t \sin \theta-\sin \theta \int_{0}^{t}F_{\textbf{D}_s}(u \cos \theta, \varphi)du\bigg].
  \end{gathered}
\end{equation} 

    \textbf{(a)} By \eqref{x_max omega}, the inequality $\tan\theta>\frac{h}{x_0}$ implies $x_{\max}(\varphi, \theta)=\frac{h}{sin\theta}$, and then
    $$t\cos\theta < \frac{h}{\tan\theta}<x_0,$$
    for any $t\in [0,\,x_{\max}(\varphi, \theta))$.

    If $\tan\theta\leq\frac{h}{x_0}$ but $0\leq t<x_{0}\sec\theta$, the inequality $t\cos\theta<x_0$ still holds. Therefore, by Theorem \ref{Theorem CLD}, we substitute $F_{\textbf{D}_s}(t \cos \theta, \varphi)$ and $F_{\textbf{D}_s}(u \cos \theta, \varphi)$ in \eqref{CLDs} by 
    $$\frac{1}{b_{\textbf{D}_s}}\bigg(\frac{\ell_0}{x_0}+\frac{\ell_1}{x_1}\bigg)t\cos\theta\,\,\text{and}\,\,\,\frac{1}{b_{\textbf{D}_s}}\bigg(\frac{\ell_0}{x_0}+\frac{\ell_1}{x_1}\bigg)u\cos\theta,$$
    respectively. Computation of the integral in \eqref{CLDs} followed by combining the like terms results in \eqref{F_prism(i)}.

    \textbf{(b)} Let now $\tan\theta\leq\frac{h}{x_0}$ but $x_{0}\sec\theta\leq t<x_{\max}(\varphi, \theta)$. Then $x_0<x_1$, otherwise it will contradict to \eqref{x_max omega}. Theorem \ref{Theorem CLD} yields 
    \begin{equation}\label{F_d_s substitution}
        F_{\textbf{D}_s}(t \cos \theta, \varphi)=\frac{1}{b_{\textbf{D}_s}}\bigg(\displaystyle{\ell_0+\frac{t\cos\theta-x_0}{x_1-x_0}\ell + \frac{t\cos\theta}{x_1}\ell_1}\bigg),
    \end{equation}
    and 
    \begin{equation}\label{F_D_s long substitution}
        \begin{gathered}
            \int_{0}^{t}F_{\textbf{D}_s}(u \cos \theta, \varphi)du=\\ \int_{0}^{x_0\sec\theta}F_{\textbf{D}_s}(u \cos \theta, \varphi)du+\int_{x_0\sec\theta}^{t}F_{\textbf{D}_s}(u \cos \theta, \varphi)du=\frac{1}{b_{\textbf{D}_s}}\times\\
            \bigg[\int_{0}^{x_0\sec\theta}\bigg(\frac{\ell_0}{x_0}+\frac{\ell_1}{x_1}\bigg)u\cos\theta du+\int_{x_0\sec\theta}^{t}\bigg(\displaystyle{\ell_0+\frac{u\cos\theta-x_0}{x_1-x_0}\ell + \frac{u\cos\theta}{x_1}\ell_1}\bigg)du\bigg].
        \end{gathered}
    \end{equation}
    To reach \eqref{F_prism(ii)}, it remains to evaluate \eqref{F_D_s long substitution}, substitute its value along with \eqref{F_d_s substitution} into \eqref{CLDs}, and simplify.   
\end{proof}

\begin{corollary}\label{Jump suface}
Let 
$$\mu(\varphi, \theta)=L_2\bigg(\{y\in \Pi_{\textbf{D}_s^h}(\varphi, \theta):\chi(l_{(\varphi, \theta)}+y) = x_{max}(\varphi, \theta)\}\bigg).$$

The function $F_{\textbf{D}_s^h}(\cdot, \varphi, \theta)$ is continuous on the real axis if and only if $\mu(\varphi, \theta)=0$. Otherwise, if $\mu(\varphi, \theta)>0$ for some pair $(\varphi,\theta)$, then $F_{\textbf{D}_s^h}(\cdot, \varphi,\theta)$ has a jump discontinuity at $x_{\max}(\varphi, \theta)$. The jump is equal to
$$\frac{\mu(\varphi, \theta)}{\|\textbf{D}_s\|\sin\theta+b_{\textbf{D}_s}h\cos\theta}.$$    
\end{corollary}


\begin{proof}
For any $(\varphi,\theta)$, the continuity of $F_{\textbf{D}_s^h}(\cdot, \varphi,\theta)$ at $t=0$ immediately follows from \eqref{F_prism(i)}. The continuity at $t=x_0\sec\theta$ also takes place. Careful calculations show that the expressions in \eqref{F_prism(i)} and \eqref{F_prism(ii)} coincide when $t=x_0\sec\theta$. Thus, the only discontinuity may occur at $t=x_{max}(\varphi, \theta)$. 

Since 
$$F_{\textbf{D}_s^h}(x_{max}(\varphi, \theta)-, \varphi,\theta)={\frac {L_{2}\{y\in \Pi_{\textbf{D}_s^h}(\varphi, \theta):\chi(l_{(\varphi, \theta)}+y) < x_{max}(\varphi, \theta)\}}{b_{\textbf{D}_s^h}(\varphi, \theta)}}=$$
$$=1-\frac{\mu(\varphi, \theta)}{b_{\textbf{D}_s^h}(\varphi, \theta)},$$
the continuity at $x_{max}(\varphi, \theta)$ holds if and only if $\mu(\varphi, \theta)=0$. The jump is equal to $\frac{\mu(\varphi, \theta)}{b_{\textbf{D}_s^h}(\varphi, \theta)}=\frac{\mu(\varphi, \theta)}{\|\textbf{D}_s\|\sin\theta+b_{\textbf{D}_s}h\cos\theta}.$ 
\end{proof}

\begin{remark} 
One can verify that $\mu(\varphi, 0)=h\cdot\ell(\varphi)$, so we rediscover Corollary \ref{Jump in planar case}. For the other extreme, $\mu(\varphi, \frac{\pi}{2})=\|\textbf{D}_s\|$ holds. The jump in this case is the highest possible, $1$. We do not aim to compute $\mu(\varphi, \theta)$ for other directions.                   
\end{remark}

In order to visualize the possible breaks in continuity and smoothness of the ODCLD function, we plot the function $z(t,h)=F_{\textbf{D}_s^h}(t,\varphi,\theta)$ for a given pair $(\varphi, \theta)$ and different values of the height $h$. As an example, in Figure~\ref{fig:FIGURE1}, this is done for the prism based on the kite $\textbf{D}_s=[10,\frac{\pi}{6}, \frac{\pi}{3}, \frac{\pi}{2}, \frac{2\pi}{3}]$, where $\varphi=\frac{\pi}{6}$, $\theta=\frac{\pi}{3}$, and then $\varphi=\frac{\pi}{2}$, $\theta=\frac{\pi}{4}$. 

\vskip 15pt
\begin{figure}[h]
    \centering
    \begin{subfigure}[t]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{P3_kite 1.png}
        \captionsetup{justification=centering}
        \caption{The surface $z(t, h) = F_{\textbf{D}_s^h}(t, \frac{\pi}{6}, \frac{\pi}{3})$}
    \end{subfigure}%    
    \begin{subfigure}[t]{0.52\textwidth}  
        \centering 
        \includegraphics[width=\textwidth]{figures/P3_kite 2.png}
        \captionsetup{justification=centering}
        \caption{The surface $z(t, h) = F_{\textbf{D}_s^h}(t, \frac{\pi}{2}, \frac{\pi}{4})$}
    \end{subfigure}
    \caption{Examples of orientation-dependent chord length distribution functions in right prisms $\textbf{D}_s^h$ with base $\textbf{D}_s=[10,\frac{\pi}{6}, \frac{\pi}{3}, \frac{\pi}{2}, \frac{2\pi}{3}]$}
    \label{fig:FIGURE1}
\end{figure}

Each of the highlighted curves on the surface represents the graph of the ODCLD function for the prism of a given height. Figure~\ref{fig:FIGURE2} is created by the same logic for the prisms with a trapezoidal base $\textbf{D}_s=[10,\frac{\pi}{6}, \frac{\pi}{4}, \frac{2\pi}{3}, \pi-\tan^{-1}\frac{\sqrt{3}}{4-\sqrt{3}}]$.  

\begin{figure}[h]
    \centering
    \begin{subfigure}[t]{0.5\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/P3_trapezoid 1.png}
        \captionsetup{justification=centering}
        \caption{The surface $z(t, h) = F_{\textbf{D}_s^h}(t, \frac{\pi}{2}, \frac{2\pi}{5})$}
    \end{subfigure}%    
    \begin{subfigure}[t]{0.5\textwidth}  
        \centering 
        \includegraphics[width=\textwidth]{figures/P3_trapezoid 2.png}
        \captionsetup{justification=centering}
        \caption{The surface $z(t, h) = F_{\textbf{D}_s^h}(t, \frac{9\pi}{10}, \frac{2\pi}{7})$}
    \end{subfigure}
    \caption{Examples of orientation-dependent chord length distribution functions in right prisms $\textbf{D}_s^h$ with base $\textbf{D}_s=[10,\frac{\pi}{6}, \frac{\pi}{4}, \frac{2\pi}{3}, \pi-\tan^{-1}\frac{\sqrt{3}}{4-\sqrt{3}}]$}
    \label{fig:FIGURE2}
\end{figure}

\vskip 5pt
\begin{theorem}\label{Theorem covariogram prism} For a $\varphi\in [0,\,\pi)$, let $x_1$ and $x_0$ be the lengths of the first and the second-order $\varphi$-diameters of $\textbf{D}_s$, respectively. Let $\ell_0,\, \ell,\, \ell_1$ be the supplementary $\varphi$-measures of $\textbf{D}_s$, and denote $b_{\textbf{D}_s}=\ell_0+\ell+\ell_1$. Then, for the direction $\omega =(\cos\varphi\cos\theta,\,\sin\varphi\cos\theta,\,\sin\theta), \,0\leq\theta\leq \frac{\pi}{2}$, the covariogram $C_{\textbf{D}_s^h}(t\omega)=C_{\textbf{D}_s^h}(t, \varphi, \theta)$ of the prism $\textbf{D}_{s}^h$ has the following representation:


    \textbf{(a)} If $\tan^{-1}\frac{h}{x_0}<\theta\leq\frac{\pi}{2}$ and $0\leq t < x_{\max}(\varphi, \theta)$, or $0\leq\theta\leq\tan^{-1}\frac{h}{x_0}$ and $0\leq t<x_{0}\sec\theta$, then 
    $$
    C_{\textbf{D}_s^h}(t,\varphi,\theta) =\bigg(\|\textbf{D}_s\|-b_{\textbf{D}_s}\cos\theta\cdot t+\frac{1}{2}\bigg(\frac{\ell_0}{x_0}+\frac{\ell_1}{x_1}\bigg)\cos^2\theta\cdot t^2\bigg)(h-\sin\theta \cdot t);
$$
\vskip 10pt
 \textbf{(b)} If $0\leq\theta\leq\tan^{-1}\frac{h}{x_0}$ and $x_{0}\sec\theta\leq t<x_{\max}(\varphi, \theta)$, then $x_0<x_1$ and 
    $$
    C_{\textbf{D}_s^h}(t,\varphi,\theta) =\frac{1}{2}\bigg(\frac{\ell}{x_1-x_0}+\frac{\ell_1}{x_1}\bigg)(x_1-\cos\theta\cdot t)^2(h-\sin\theta \cdot t).
$$  
\end{theorem}
\begin{proof} Let $0\leq t < x_{max}(\varphi, \theta)$. Since
$$
\textbf{D}_{s}^{h} \cap\left(\textbf{D}_{s}^{h}+t \omega\right)=\left(\textbf{D}_{s} \cap\{\textbf{D}_s+(t \cos \theta) \phi\}\right) \times[t \sin \theta, h],
$$
we obtain
$$C_{\textbf{D}_s^h}(t\omega)=L_{2}(\, \textbf{D}_s  \cap\{\textbf{D}_s+(t \cos \theta) \phi\}) \cdot(h-t \sin \theta),$$
and then 
\begin{equation}\label{Covariograms related}
    C_{\textbf{D}_s^h}(t,\varphi,\theta)=C_{\textbf{D}_s}(t \cos \theta, \varphi)(h-t \sin \theta).
\end{equation}
   The proof now follows from \eqref{Covariograms related} and Theorem \ref{Covariogram quadrilateral}.
\end{proof}
\begin{remark} 
Taking $\theta=0$, it is easy to check that all the results obtained in Section \ref{ODCLD and the covariogram of a convex quadrilateral} are coherent with the results presented in the current section. 
\end{remark}


\chapter{INTERSECTION PROBABILITIES OF FOUR LINES INSIDE A PLANAR CONVEX DOMAIN}

\section{Preliminaries}\label{Preliminaries 2}

  
For a bounded open convex domain $D\subset \mathbb{R}^2$ we consider $N_n$, the number of intersection points of $n$ random lines in $D$, given that all $n$ lines meet $D$ (see Figure~\ref{fig:P2_preliminary_fig_1}). We will assume that $D$ contains the origin of the Cartesian plane, and for a line $g\subset \mathbb{R}^2$, we denote by $(p, \varphi)$ the polar coordinates of the foot of the perpendicular from the origin onto $g$.

% \vskip 5pt
\begin{figure}[h]
    \centering
    \begin{subfigure}[t]{0.5\textwidth}
        \centering
        \includegraphics[width=\textwidth]{P2_preliminary_1.png}
        \captionsetup{justification=centering}
    \end{subfigure}%    
    \caption{Random lines intersecting each other inside $D$}
    \label{fig:P2_preliminary_fig_1}
\end{figure}


Let $p_{nk}=\mathbb{P}(N_n=k)$. When $n\leq 3$, the values of these probabilities can be found in \cite{Santalo}, part I, chapter 4. It is relatively easy to prove that $p_{21}=\frac{2\pi F}{L^2}$, where $F$ and $L$ are the area and the perimeter of $D$, respectively. Computation of $p_{3k}$ requires more invariants of $D$ besides the area and the perimeter. Those are suggested to be   
$$
    I_2=\int_{g\cap D\neq\varnothing}|\chi(g)|^2dg \,\,\,\, \text{and}\,\,\,\,\, U=\int_{g_1\cap g_2\in D}u(g_1, g_2)dg_1dg_2,
$$
where $\chi(g)=g\cap D$ is the chord in $D$ produced by the line $g$, $|\chi(g)|$ is the length of $\chi(g)$, and $u(g_1, g_2)$ denotes the perimeter of the convex quadrilateral verticed at the points of intersections of the lines $g_1$ and $g_2$ with the boundary $\partial D$. The measure element $dg$ is interpreted as $dg=dp d\varphi$, where $dp$ is the one-dimensional Lebesgue measure and $d\varphi$ is the uniform measure on the unit circle.  

The formulas for intersection probabilities $p_{3k}$, suggested in \cite{Santalo}, p. 65 contain a mistake. The correct formulas are  
\begin{equation}\label{p_{3k}}
    p_{33}=\frac{8I_2-U}{L^3},\,p_{32}=\frac{3U-12I_2}{L^3}, \, p_{31}=\frac{6\pi FL-3U}{L^3},
\end{equation}
established earlier by R. Sulanke in \cite{Sulanke}. These formulas imply
\begin{equation}\label{I_2 and U in terms of prob}
    I_2=\frac{L^3}{12}(p_{32}+3p_{33}),\,\,\,\,U=\frac{L^3}{3}(2p_{32}+3p_{33}).
\end{equation}

In this chapter, we aim to obtain explicit formulas for probabilities $p_{4k}$, $k=1,2, ..., 6$ in terms of new invariants of $D$ and find an analogue of \eqref{I_2 and U in terms of prob} for those invariants. We will use Ambartzumian's combinatorial algorithm (see \cite{Ambartzumian_1}, chapter 5), so before passing on the main results, let us adapt it to the new situation. 

\section{The combinatorial algorithm}\label{Combinatorial Algorithm}
Let $\mathbb{G}$ be the space of all lines $g$ in $\mathbb{R}^2$. We equip $\mathbb{G}$ with a measure $\mu$ invariant under Euclidean motions in $\mathbb{R}^2$. Then, up to a constant factor,

$$\mu(X)=\int_X dg,$$
for the measurable subsets $X\subset \mathbb{G}$ (see \cite{Santalo}, p. 28).     

Let $\mathcal{P}=\{P_i\}_{i=1}^n$ be a finite set of points in the plane. For any line $g\in\mathbb{G}$ we consider $\Pi_1(g)$ and $\Pi_2(g)$, the two open half-planes generated by $g$. We call two lines $g_1, \, g_2$ \textbf{equivalent} if $\{\mathcal{P}\cap\Pi_1(g_1),\mathcal{P}\cap\Pi_2(g_1)\}=\{\mathcal{P}\cap\Pi_1(g_2),\mathcal{P}\cap\Pi_2(g_2)\}$. $\mathbb{G}$ is decomposed into subsets of equivalent lines, which we call \textbf{atoms}. We denote by $r(\mathcal{P})$ the minimal ring containing all bounded atoms.         

If $g\cap \mathcal{P}=\varnothing$ and none of sets $\mathcal{P}\cap\Pi_1(g)$ and $\mathcal{P}\cap\Pi_2(g)$ is empty, then consider the atom $B$ such that $g\in B$. We will say that the atom  $B$ \textbf{separates the points $\mathcal{P}\cap\Pi_1(g)$ from $\mathcal{P}\cap\Pi_2(g)$}. A visual example is provided below, in Figure~\ref{fig:P2_atom}.


% \vskip 5pt
\begin{figure}[h]
    \centering
    \begin{subfigure}[t]{0.6\textwidth}
        \centering
        \includegraphics[width=\textwidth]{P2_atom.png}
        \captionsetup{justification=centering}
    \end{subfigure}%    
    \caption{The atom separating $\{P_1, P_4, P_5\}$ from $\{P_2, P_3\}$}
    \label{fig:P2_atom}
\end{figure}


Let $\rho_{ij}$ be the Euclidean distance between points $P_i$ and $P_j$. The combinatorial algorithm below aims to express the $\mu$-measure of any set $B\in r(\mathcal{P})$ by linear combinations of $\rho_{ij}$ with integer coefficients belonging to $\{0, \pm 1, \pm 2\}$. The algorithm is introduced \cite{Ambartzumian_1} for the case where any three points from $\mathcal{P}$ are not collinear. If there are collinear triads, then (see \cite{Ambartzumian_2}) the linear combinations should be taken over those indices $(i,j), \, i<j$, for which the segment $P_iP_j$ contains no other points from $\mathcal{P}$. We call such points $P_i$ and $P_j$ \textbf{neighbor points}. For an illustration see Figure~\ref{fig:P2_neighbor_points}.

\vskip -5pt
\begin{figure}[h]
    \centering
    \begin{subfigure}[t]{0.3\textwidth}
        \centering
        \includegraphics[width=\textwidth]{P2_neighbor_points.png}
        \captionsetup{justification=centering}
    \end{subfigure}%    
    \caption{All $P_i$, $P_j$ are neighbors except for $P_1$, $P_5$}
    \label{fig:P2_neighbor_points}
\end{figure}


Let $g_{ij}$ be the line passing through the neighbor points $P_i$ and $P_j$. For sufficiently small positive numbers $\delta$ and $\theta$ we define two types of displacements for $g_{ij}$:

\textbf{$\delta$-translation} - This is a set of two lines which are parallel to $g_{ij}$ and distant from $g_{ij}$ by $\delta$. The set is denoted by $T_{\delta}(g_{ij})$; 

\textbf{$\theta$-rotation} - This is a set of two lines each passing through the midpoint of $P_iP_j$ and making angle $\theta$ with $g_{ij}$. The set is denoted by $R_{\theta}(g_{ij})$. 

If $B\in r(\mathcal{P})$, then let's  compose the numbers
$$
R_{ij}(B)=\lim_{\theta\to 0+} \# [R_{\theta}(g_{ij})\cap B], \,\,\,\,\,T_{ij}(B)=\lim_{\delta\to 0+}\#[T_{\delta}(g_{ij})\cap B],
$$
where $\#$ stands for the cardinality of a set. 

Obviously, $R_{ij}(B)$, $T_{ij}(B)\in \{0, 1, 2\}$. Ambartzumian's combinatorial algorithm/formula can now be reformulated as follows.       
\begin{theorem} \label{Ambartzumian's theorem}
Let $\mathcal{P}=\{P_i\}_{i=1}^n$ be a finite set of points in the plane and $B\in r(\mathcal{P})$. Then
\begin{equation}\label{Ambartzumian}
\mu(B)=\sum_{(i,j)\in I}[R_{ij}(B)-T_{ij}(B)]\rho_{ij},
\end{equation}
where  $I$ is the set of pairs $(i,j)$ for all neighbor points $P_i$ and $P_j$, $i<j$.  
\end{theorem}
As an application, one can easily re-obtain the formulas for $p_{nk}$, where $n=2,3$. For example, let's prove the second formula in \eqref{p_{3k}}.  

Here, and in the next sections for any set $X\subset \mathbb{R}^2$ we denote by $[X]$ the set of all lines $g\in \mathbb{G}$ such that $g\cap X\neq\varnothing$. Two intersection points can occur when two of the lines $g_1, g_2, g_3$ have no intersection inside $D$ and the third one intersects each of them inside $D$. The three events where either of $g_i$ is the third line, are equally probable, and therefore 
$$p_{32}=\frac{3}{L^3}\int_{g_1\cap g_2 \in D}dg_1dg_2\int_{[\chi(g_1)]\cap [\chi(g_2)]^c}dg_3=\frac{3}{L^3}\int_{g_1\cap g_2 \in D}\mu(B)dg_1dg_2,$$
where $B=[\chi(g_1)]\cap [\chi(g_2)]^c$ (the complement is taken over the sample space $[D]$).
One can check that among $T_{ij}(B)$ and $R_{ij}(B)$, the only non-zero coefficients  are
$T_{24}(B)=2$ and $R_{12}(B)=R_{23}(B)=R_{34}(B)=R_{14}(B)=1$. Then \eqref{Ambartzumian} yields 
$$p_{32}=\frac{3}{L^3}\int_{g_1\cap g_2 \in D}\bigg(-2|\chi(g_2)|+u(g_1, g_2)\bigg)dg_1dg_2.$$
It remains to notice that
$$
    \int_{g_1\cap g_2 \in D}|\chi(g_2)|dg_1dg_2=\int_{[D]}|\chi(g_2)|dg_2\int_{[\chi(g_2)]}dg_1=2\int_{[D]}|\chi(g)|^2dg=2I_2.
$$

\section{Introduction of new invariants. Computation of $p_{4k}$ for $k=6, 5$}\label{New invariants}

 
\begin{definition}\label{definition new invariants}
For any $g_1\cap g_2\in D$ we define 
$$d(g_1, g_2)=|\chi(g_1)|+|\chi(g_2)|, \,\,\,\, c(g_1, g_2)=\mu \big([\chi(g_1)]\cap[\chi(g_2)]\big),$$
$$u(g_1, g_2)=\big|\partial\big(conv\big(\cup_{i=1}^2g_i\cap D\big)\big)\big|,$$
and for any three lines $g_1, g_2, g_3$ such that $g_i\cap g_j\in D$, $1\leq i<j\leq 3$ we define
$$v(g_1, g_2, g_3)=\big|\partial\big(conv\big(\cup_{i=1}^3g_i\cap D\big)\big)\big|,$$
where $conv(X)$ denotes the convex hull of $X\subset\mathbb{R}^2$, and $|\partial Y|$ denotes the perimeter of a convex domain $Y$.
\end{definition}
The new definition of $u(g_1, g_2)$ coincides with the one we have used so far. Also, by \eqref{Ambartzumian}, we have $c(g_1, g_2)=2d(g_1, g_2)-u(g_1, g_2)$.

Along with the well-known invariants $I_k=\int_{[D]}|\chi(g)|^kdg, \,\,k=0, 1, 2, \dots$ let's consider the following moments of the functions introduced in Definition~\ref{definition new invariants}. 
$$
\begin{aligned}
    D_k &=\int_{g_1\cap g_2 \in D}d^k(g_1, g_2)dg_1dg_2,\,\,\,\,
    C_k=\int_{g_1\cap g_2 \in D}c^k(g_1, g_2)dg_1dg_2, \\
    U_k &=\int_{g_1\cap g_2 \in D}u^k(g_1, g_2)dg_1dg_2,\,\,\,\, 
    V_k =\int_{g_i\cap g_j \in D,\,1\leq i<j\leq3}v^k(g_1, g_2, g_3)dg_1dg_2dg_3.
    \end{aligned}
$$

It is easy to verify that
$$ I_0=L, \,\, \,\, D_0= C_0=U_0=2I_1=2\pi F, \,\, \,\, V_0= C_1=2D_1-U_1=8I_2-U_1$$
and 
\begin{equation}\label{old probabilities in new terms}
  p_{21}=\frac{U_0}{L^2},\,\,
  p_{33}=\frac{C_1}{L^3}, \,\, p_{32}=\frac{3(U_1-D_1)}{L^3}, \,\,p_{31}=\frac{3(U_0L-U_1)}{L^3}.
\end{equation}
In this section, we aim to express the probabilities $p_{46}$ and $p_{45}$ by the new invariants. In this way, we first obtain expressions for two useful integrals.  

\begin{proposition}\label{chi-chi and chi-u}
$$
    \int_{g_1\cap g_2\in D}|\chi(g_1)||\chi(g_2)|dg_1dg_2=\frac{D_2-4I_3}{2},
$$
$$
    \int_{g_1\cap g_2\in D}|\chi(g_1)|u(g_1, g_2)dg_1dg_2=\frac{4D_2+U_2-C_2}{8}.
$$
\end{proposition}
\begin{proof}
Direct computation of $D_2$ leads to
$$D_2=\int_{g_1\cap g_2\in D}\big(|\chi(g_1)|^2+|\chi(g_2)|^2\big)dg_1dg_2+2\int_{g_1\cap g_2\in D}|\chi(g_1)||\chi(g_2)|dg_1dg_2$$
$$=2\int_{[D]}|\chi(g_1)|^2\int_{[\chi(g_1)]}dg_2dg_1+2\int_{g_1\cap g_2\in D}|\chi(g_1)||\chi(g_2)|dg_1dg_2$$
$$=4\int_{[D]}|\chi(g_1)|^3dg_1+2\int_{g_1\cap g_2\in D}|\chi(g_1)||\chi(g_2)|dg_1dg_2,$$
which is equivalent to the first identity.

To prove the second identity we expand the integrand of $C_2$ and obtain
$$C_2=4D_2+U_2-4\int_{g_1\cap g_2\in D}|\chi(g_1)|u(g_1, g_2)dg_1dg_2-4\int_{g_1\cap g_2\in D}|\chi(g_2)|u(g_1, g_2)dg_1dg_2.$$
It remains to notice that the last two integrals coincide due to symmetry. 
\end{proof}

\begin{definition}\label{I_k(chi_12)}
For $g_1, g_2, \dots , g_n\in [D]$, let $\langle g_1, g_2, \dots, g_n \rangle$ be the set of all chords $\chi_{12}$ that join an endpoint of $\chi(g_i)$ to an endpoint of $\chi(g_j)$, $1 \leq i<j \leq n$. Then for any integer $k$, $0\leq k \leq n-2$ we define the function $I_k: \langle g_1, g_2, \dots, g_n \rangle \rightarrow{\{0, 1\}}$ by $$I_k(\chi_{12}) = 
    \begin{cases}
        1, & \mbox{if \, $\# \big(\chi_{12}\cap (\cup_{i=1}^n\overline{\chi(g_i)})\big)=k$}  \\
        0, & \mbox{otherwise}
    \end{cases},$$
    where $\overline{\chi(g_i)}$ is the closure of $\chi(g_i)$ in $\mathbb{R}^2$.
 
\end{definition}

The following two integrals are essential for our further work.
\begin{lemma}\label{Integrals over Omega_3}
\begin{equation}\label{chi over Omega_3}
   \displaystyle{\int_{g_1\cap g_2\in D}dg_1dg_2\int_{[\chi(g_1)]\cap [\chi(g_2)]}|\chi(g_1)|dg_3}=\frac{4D_2-U_2+C_2}{8},
\end{equation}
\begin{equation}\label{I_1 over Omega 3}
\begin{aligned}
&\int_{g_1\cap g_2\in D}dg_1dg_2\int_{[\chi(g_1)]\cap [\chi(g_2)]}\displaystyle{\sum_{\chi_{12}\in \langle g_1, g_2, g_3\rangle}|\chi_{12}|I_1(\chi_{12})} dg_3\\
&=\frac{12D_2-3C_2-3U_2-2V_1}{2}.
\end{aligned}
\end{equation}
\end{lemma}
\begin{proof}
The left-hand side of \eqref{chi over Omega_3} is equal to 
$$\int_{g_1\cap g_2\in D}|\chi(g_1)|\big(2d(g_1, g_2)-u(g_1, g_2)\big)dg_1dg_2$$
$$=2\int_{g_1\cap g_2\in D}|\chi(g_1)|^2dg_1dg_2+2\int_{g_1\cap g_2\in D}|\chi(g_1)||\chi(g_2)|dg_1dg_2$$
$$-\int_{g_1\cap g_2\in D}|\chi(g_1)|u(g_1, g_2)dg_1dg_2=4I_3+(D_2-4I_3)-\frac{4D_2+U_2-C_2}{8},$$
which coincides with the right-hand side of \eqref{chi over Omega_3}.
To prove \eqref{I_1 over Omega 3} we first notice that 
$$
 \displaystyle{\sum_{\chi_{12}\in \langle g_1, g_2, g_3\rangle}|\chi_{12}|I_1(\chi_{12})}=\displaystyle{\sum_{1\leq i<j \leq 3}u(g_i, g_j)}-v(g_1, g_2, g_3). 
$$
   
Consequently, due to symmetry, the left-hand side of \eqref{I_1 over Omega 3} becomes equal to
$$3\int_{g_1\cap g_2\in D}dg_1dg_2\int_{[\chi(g_1)]\cap [\chi(g_2)]}u(g_1, g_2)dg_3-V_1$$
$$=3\int_{g_1\cap g_2\in D}u(g_1, g_2)\big(2d(g_1, g_2)-u(g_1, g_2)\big)dg_1dg_2-V_1$$
$$=12\int_{g_1\cap g_2\in D}|\chi(g_1)|u(g_1, g_2)dg_1dg_2-3U_2-V_1=\frac{12(4D_2+U_2-C_2)}{8}-3U_2-V_1,$$
which coincides with the right-hand side of \eqref{I_1 over Omega 3}. 
\end{proof}

We are now prepared to compute $p_{46}$ and $p_{45}$.
\begin{theorem}\label{p_46 and p_45}
\begin{equation}\label{p_{46}}
    p_{46}=\frac{3U_2+9C_2-12D_2+4V_1}{4L^4},
\end{equation}
\begin{equation}\label{p_{45}}
    p_{45}=\frac{36D_2-9U_2-15C_2-12V_1}{2L^4}.
\end{equation}
\end{theorem}
\begin{proof}
Four lines $g_i\in[D]$, $i=1, 2, 3, 4$ generate six intersection points inside $D$ if and only if $g_1, g_2, g_3$ generate three intersections and $g_4\in \cap_{i=1}^3 [\chi(g_i)]$. Therefore,
\begin{equation}\label{p_{46} original}
  p_{46}=\frac{1}{L^4}\int_{g_1\cap g_2\in D}dg_1dg_2\int_{[\chi(g_1)]\cap [\chi(g_2)]}\mu(B_6)dg_3,
\end{equation}
where $B_6=\cap_{i=1}^3 [\chi(g_i)]$.

Let's fix $g_1, g_2, g_3$ and consider the set of points $\mathcal{P}=(g_1\cup g_2\cup g_3)\cap \partial D$. Without loss of generality one can assume that $g_1\cap \partial D=\{P_1, P_4\}$, $g_2\cap \partial D=\{P_2, P_5\}$, and $g_3\cap \partial D=\{P_3, P_6\}$, where the points $P_i$ are consecutively distributed over the boundary $\partial D$. 

The set $B_6$ belongs to the ring $r(\mathcal{P})$ and can be written as a union of three atoms $B_{61}, B_{62},$ and $B_{63}$, where $B_{6i}$ separates the points $P_i, P_{i+1}, P_{i+2}$ from the other points of $\mathcal{P}$. By Theorem \ref{Ambartzumian's theorem},
$$ \mu(B_{61})=\rho_{14}+\rho_{36}-\rho_{13}-\rho_{46},\,\,\,\,  \mu(B_{62})=\rho_{25}+\rho_{14}-\rho_{24}-\rho_{15},$$
 $$ \mu(B_{63})=\rho_{36}+\rho_{25}-\rho_{35}-\rho_{26},$$
where we notice that $\rho_{14}=|\chi(g_1)|$, $\rho_{25}=|\chi(g_2)|$, $\rho_{36}=|\chi(g_3)|$, and the six subtracted terms represent the lengths of all chords $\chi_{12}\in \langle g_1, g_2, g_2\rangle$ that meet exactly one of the closed chords $\overline{\chi(g_i)}$, $i=1, 2, 3$. Thus,
\begin{equation}\label{mu(B_6)}
    \mu(B_6)=\sum_{i=1}^3 \mu(B_{6i})=2\sum_{i=1}^3|\chi(g_i)|-\displaystyle{\sum_{\chi_{12}\in \langle g_1, g_2, g_3\rangle}|\chi_{12}|I_1(\chi_{12}).}
\end{equation}
Now \eqref{p_{46} original}, \eqref{mu(B_6)}, and Lemma \ref{Integrals over Omega_3} imply
$$p_{46}=6\cdot \frac{4D_2-U_2+C_2}{8L^4}-\frac{12D_2-3C_2-3U_2-2V_1}{2L^4}=\frac{3U_2+9C_2-12D_2+4V_1}{4L^4}.$$

Five intersection points may occur when three lines, e.g. $g_1, g_1, g_3$ produce three intersections,  and the fourth line, $g_4$ intersects only $g_1$ and $g_2$ inside $D$. In this scenario, the roles of $g_3$ and $g_4$ are interchangeable. Therefore, the probability $p_{45}$ can be written as
\begin{equation}\label{p_{45} original}
  p_{45}=\frac{1}{2} \cdot  {4\choose 3}\cdot \frac{1}{L^4}\int_{g_1\cap g_2\in D}dg_1dg_2\int_{[\chi(g_1)]\cap [\chi(g_2)]}\mu(B_5)dg_3,
\end{equation}
where $B_5=\big([\chi(g_1)]\cap[\chi(g_2)]\cap[\chi(g_3)]^c\big)  \bigcup \big([\chi(g_1)]\cap[\chi(g_2)]^c\cap[\chi(g_3)]\big)  \bigcup  \big([\chi(g_1)]^c\cap[\chi(g_2)]\cap[\chi(g_3)]\big)$.

Using the same set $\mathcal{P}$ as in the case of six intersection points, one can represent $B_5$ as a union of six atoms $B_{5i}\in r(\mathcal{P})$, $i=1,\dots, 6$, where $B_{5i}$ separates $\{P_i, P_{i+1}\}$ from the other points of $\mathcal{P}$ (when $i=6$ we replace $i+1$ by 1). 

By Theorem \ref{Ambartzumian's theorem},
$$
\begin{aligned}
    \mu(B_{51})=&\rho_{13}+\rho_{26}-\rho_{12}-\rho_{36},\,\,\,\,\, \mu(B_{52})=\rho_{24}+\rho_{31}-\rho_{23}-\rho_{41}, \\
   \mu(B_{53})=&\rho_{35}+\rho_{42}-\rho_{34}-\rho_{52}, \,\,\,\,\, \mu(B_{54})=\rho_{46}+\rho_{53}-\rho_{45}-\rho_{63},\\ 
    \mu(B_{55})=&\rho_{51}+\rho_{64}-\rho_{56}-\rho_{14},\,\,\,\,\, \mu(B_{56})=\rho_{62}+\rho_{15}-\rho_{61}-\rho_{25}.
  \end{aligned}
$$ 
Taking into account that $\rho_{ji}=\rho_{ij}$ and recognizing the type of each $\rho_{ij}$ participating in the above formulas, we come up with
\begin{equation}\label{mu(B_5)}
    \mu(B_5)=\sum_{i=1}^6 \mu(B_{5i})=2\cdot \displaystyle{\sum_{\chi_{12}\in \langle g_1, g_2, g_3\rangle}|\chi_{12}|I_1(\chi_{12})}-2\sum_{i=1}^3|\chi(g_i)|-v(g_1,g_2,g_3).
\end{equation}

Due to \eqref{p_{45} original} and \eqref{mu(B_5)},
$$p_{45}=\frac{4}{L^4}\int_{g_1\cap g_2\in D}dg_1dg_2\int_{[\chi(g_1)]\cap [\chi(g_2)]}\displaystyle{\sum_{\chi_{12}\in \langle g_1, g_2, g_3\rangle}|\chi_{12}|I_1(\chi_{12})}dg_3$$

$$-\frac{12}{L^4}\int_{g_1\cap g_2\in D}dg_1dg_2\int_{[\chi(g_1)]\cap [\chi(g_2)]}|\chi_(g_1)|dg_3-\frac{2V_1}{L^4}.$$
It remains to apply Lemma \ref{Integrals over Omega_3} and establish \eqref{p_{45}} by combining the like terms. \end{proof}

\section{Computation of $p_{4k}$ for $k\leq 4$}\label{The rest of probabilities}
We will use a few more notations in this section to make relevant calculations in all the scenarios that may occur when four lines meet inside $D$ at less than five points. 

Given $g_1\cap g_2 \in D$, we denote by $\rho_1,\rho_2, \rho_3, \rho_4$ the lengths of four consecutive sides of the quadrilateral $conv\big((g_1\cup g_2)\cap \partial D\big)$. To avoid ambiguity, we will always assume that the first two sides lie in different half-planes with respect to $g_1$. If two lines, e.g. $g_2$ and $g_3$, are from $[D]$ but do not meet inside $D$, then $d_1, d_2$ will stand for the lengths of the diagonals of $conv\big((g_2\cup g_3)\cap \partial D\big)$, and $s_1, s_2$ will represent the lengths of the sides of the quadrilateral which are different from $\chi(g_2), \chi(g_3)$.
\begin{figure}[h]
    \centering
    \begin{subfigure}[t]{0.4\textwidth}
        \centering
        \includegraphics[width=\textwidth]{P2_scenarios_2_lines_intersect_D_1.png}
        \captionsetup{justification=centering}
        \caption{The case $g_{1} \cap g_{2} \in D$}
    \end{subfigure}%    
    \begin{subfigure}[t]{0.46\textwidth}  
        \centering 
        \includegraphics[width=\textwidth]{P2_scenarios_2_lines_intersect_D_2.png}
        \captionsetup{justification=centering}
        \caption{The case $g_{2} \cap g_{3} \not\in D$}
    \end{subfigure}
    \caption{Scenarios of two lines intersecting $D$}
    \label{fig:FIG1}
\end{figure}

The new notation is illustrated in the Figure~\ref{fig:FIG1}. Those are used to define the following new invariants of $D$:     
$$R=\int_{g_1\cap g_2 \in D}\big((\rho_1+\rho_2)(\rho_3+\rho_4)+(\rho_2+\rho_3)(\rho_4+\rho_1)\big)dg_1dg_2,$$

$$Q_s=\int_{g_2\cap g_3 \not\in D}(s_1+s_2)(d_1+d_2-s_1-s_2)dg_2dg_3,$$

$$Q_d=\int_{g_2\cap g_3 \not\in D}(d_1+d_2)(d_1+d_2-s_1-s_2)dg_2dg_3.$$

To make upcoming formulas shorter, for the given pair of lines $g_1\cap g_2\in D$ we will use $\mathcal{S}$ to denote the symmetric difference of $[\chi(g_1)]$ and $[\chi(g_2)]$. $\mathcal{S}_1$ and $\mathcal{S}_2$ will stand for $[\chi(g_1)]\cap[\chi(g_2)]^c$ and $[\chi(g_1)]^c\cap[\chi(g_2)]$, respectively. Use of parentheses in integrands will be avoided if it does not lead to misreading.          
\begin{lemma}\label{The biggest lemma}
Let $I_{\mathcal{S}_1}$ and $I_{\mathcal{S}_2}$ be the indicator functions of $\mathcal{S}_1$ and $\mathcal{S}_2$, respectively. Then the following six identities hold:
\begin{equation}\label{chi over Omega 2}
    \int_{g_1\cap g_2\in D}dg_1dg_2\int_{\mathcal{S}}I_{\mathcal{S}_1}|\chi(g_1)|+I_{\mathcal{S}_2}|\chi(g_2)|dg_3=\frac{U_2-C_2-4D_2}{4}+8I_3,
\end{equation}
\begin{equation}\label{I_0 over Omega2}
    \int_{g_1\cap g_2\in D}dg_1dg_2\int_{\mathcal{S}}I_{\mathcal{S}_1}\displaystyle{\sum_{\langle g_2, g_3\rangle}|\chi_{12}|I_0(\chi_{12})}+I_{\mathcal{S}_2}\displaystyle{\sum_{\langle g_1, g_3\rangle}|\chi_{12}|I_0(\chi_{12})}dg_3=2Q_s,
\end{equation}

\begin{equation}\label{I_1 over Omega2}
    \int_{g_1\cap g_2\in D}dg_1dg_2\int_{\mathcal{S}}\displaystyle{\sum_{\langle g_1, g_2\rangle}|\chi_{12}|I_1(\chi_{12})}dg_3=\frac{7U_2-4D_2+C_2}{4}-2R,
\end{equation}

\begin{equation}\label{I_0 over Omega2 no proof}
    \int_{g_1\cap g_2\in D}dg_1dg_2\int_{\mathcal{S}}\displaystyle{\sum_{\langle g_1, g_2\rangle}|\chi_{12}|I_0(\chi_{12})}dg_3=\frac{C_2-4D_2-U_2}{4}+2R,
\end{equation}

\begin{equation}\label{I_1 over Omega2 without proof}
    \int_{g_1\cap g_2\in D}dg_1dg_2\int_{\mathcal{S}}I_{\mathcal{S}_1}\displaystyle{\sum_{\langle g_2, g_3\rangle}|\chi_{12}|I_1(\chi_{12})}+I_{\mathcal{S}_2}\displaystyle{\sum_{\langle g_1, g_3\rangle}|\chi_{12}|I_1(\chi_{12})}dg_3=2Q_d,
\end{equation}

\begin{equation}\label{chi over Omega 2 non-proven}
    \int_{g_1\cap g_2\in D}dg_1dg_2\int_{\mathcal{S}}I_{\mathcal{S}_1}|\chi(g_2)|+I_{\mathcal{S}_2}|\chi(g_1)|dg_3=\frac{U_2-C_2+4D_2}{4}-8I_3.
\end{equation}
\end{lemma}

\begin{proof} Since $\mathcal{S}=\mathcal{S}_1\cup \mathcal{S}_2$ and $\mathcal{S}_1\cap \mathcal{S}_2=\varnothing$, then 
 $$\int_{\mathcal{S}}I_{\mathcal{S}_1}|\chi(g_1)|+I_{\mathcal{S}_2}|\chi(g_2)|dg_3=|\chi(g_1)|\mu(\mathcal{S}_1)+|\chi(g_2)|\mu(\mathcal{S}_2).$$
 
  Using the technique developed in the previous two sections, one can check that $\mu(\mathcal{S}_1)=u(g_1, g_2)-2|\chi(g_2)|$, $\mu(\mathcal{S}_2)=u(g_1, g_2)-2|\chi(g_1)|$ and, consequently, the left-hand side of \eqref{chi over Omega 2} becomes equal to
  $$2\int_{g_1\cap g_2 \in D}|\chi(g_1)|u(g_1, g_2)dg_1dg_2-4\int_{g_1\cap g_2 \in D}|\chi(g_1)||\chi(g_2)|dg_1dg_2=$$
  $$\frac{4D_2+U_2-C_2}{4}-2D_2+8I_3=\frac{U_2-C_2-4D_2}{4}+8I_3.$$
 
 To prove \eqref{I_0 over Omega2}, we change the order of integration. The left-hand side of \eqref{I_0 over Omega2} becomes equal to 
$$\begin{aligned}
&\int_{g_2\cap g_3\not\in D}dg_2dg_3\int_{[\chi(g_2)]\cap[\chi(g_3)]}\displaystyle{\sum_{\langle g_2, g_3\rangle}|\chi_{12}|I_0(\chi_{12})}dg_1+\\
&+\int_{g_1\cap g_3\not\in D}dg_1dg_3\int_{[\chi(g_1)]\cap[\chi(g_3)]}\displaystyle{\sum_{\langle g_1, g_3\rangle}|\chi_{12}|I_0(\chi_{12})}dg_2=\\
& 2\int_{g_2\cap g_3\not\in D}\displaystyle{\sum_{\langle g_2, g_3\rangle}|\chi_{12}|I_0(\chi_{12})}\mu\big([\chi(g_2)]\cap[\chi(g_3)]\big)dg_2dg_3=2Q_s,
\end{aligned}$$
where the last equality holds due to  $\displaystyle{\sum_{\langle g_2, g_3\rangle}|\chi_{12}|I_0(\chi_{12})}=s_1+s_2$ and $\mu\big([\chi(g_2)]\cap[\chi(g_3)]\big)=d_1+d_2-s_1-s_2$ (see Figure~\ref{fig:FIG1}(b)).

Let's prove \eqref{I_1 over Omega2}. The inner integral in \eqref{I_1 over Omega2} can be written in the form of the sum
\begin{equation}\label{I_1 over S1 and S2} 
    \int_{\mathcal{S}_1}\displaystyle{\sum_{\langle g_1, g_2\rangle}|\chi_{12}|I_1(\chi_{12})}dg_3+\int_{\mathcal{S}_2}\displaystyle{\sum_{\langle g_1, g_2\rangle}|\chi_{12}|I_1(\chi_{12})}dg_3.
\end{equation}
  The integrand of the first integral in \eqref{I_1 over S1 and S2} is piecewise constant over the set of lines $g_3\in \mathcal{S}_1$. Indeed, look at the Figure~\ref{fig:FIG1} (a). The function is equal to $\rho_3+\rho_4$ over the atom $B^+\in r(\mathcal{P})$ that separates the point $P_3$ from the other points of $\mathcal{P}=\{P_1, P_2, P_3, P_4\}$. On the other hand, it is equal to $\rho_1+\rho_2$ over $B^-$, the atom that separates $P_1$ from $\mathcal{P}\setminus P_1$. Taking into account that $\mathcal{S}_1=B^+\cup B^-$, we obtain
  $$\int_{\mathcal{S}_1}\displaystyle{\sum_{\langle g_1, g_2\rangle}|\chi_{12}|I_1(\chi_{12})}dg_3=(\rho_3+\rho_4)\mu(B^+)+(\rho_1+\rho_2)\mu(B^-).$$
  By our main computational engine \eqref{Ambartzumian}, it is easy to verify that $\mu(B^+)=\rho_3+\rho_4-|\chi(g_2)|$ and $\mu(B^-)=\rho_1+\rho_2-|\chi(g_2)|$. Substitution of these values in the right-hand side of the last formula yields
  $$\int_{\mathcal{S}_1}\displaystyle{\sum_{\langle g_1, g_2\rangle}|\chi_{12}|I_1(\chi_{12})}dg_3=(\rho_3+\rho_4)^2+(\rho_1+\rho_2)^2-|\chi(g_2)|u(g_1, g_2),$$
  which is equivalent to
  \begin{equation}\label{Integral over S1}
      \int_{\mathcal{S}_1}\displaystyle{\sum_{\langle g_1, g_2\rangle}|\chi_{12}|I_1(\chi_{12})}dg_3=u^2(g_1, g_2)-|\chi(g_2)|u(g_1, g_2)-2(\rho_1+\rho_2)(\rho_3+\rho_4).
  \end{equation}
  The second integral in \eqref{I_1 over S1 and S2} can be obtained from \eqref{Integral over S1} by interchanging $g_1$ and $g_2$.
  \begin{equation}\label{Integral over S2}
      \int_{\mathcal{S}_2}\displaystyle{\sum_{\langle g_1, g_2\rangle}|\chi_{12}|I_1(\chi_{12})}dg_3=u^2(g_1, g_2)-|\chi(g_1)|u(g_1, g_2)-2(\rho_2+\rho_3)(\rho_4+\rho_1).
  \end{equation}
  Based on \eqref{I_1 over S1 and S2}, \eqref{Integral over S1}, \eqref{Integral over S2} and Proposition \ref{chi-chi and chi-u}, we conclude 
 $$\int_{g_1\cap g_2\in D}dg_1dg_2\int_{\mathcal{S}}\displaystyle{\sum_{\langle g_1, g_2\rangle}|\chi_{12}|I_1(\chi_{12})}dg_3=2U_2-\frac{4D_2+U_2-C_2}{4}-2R,$$
 which is equal to the right-hand side of \eqref{I_1 over Omega2}. 
 The proofs of \eqref{I_0 over Omega2 no proof}, \eqref{I_1 over Omega2 without proof}, and \eqref{chi over Omega 2 non-proven} are very similar to the ones provided for \eqref{I_1 over Omega2}, \eqref{I_0 over Omega2}, and \eqref{chi over Omega 2}, respectively, and thus  omitted.    
\end{proof}


\begin{theorem}\label{theorem for p44}
Let $p_{44}^{(1)}$ be the probability that $g_1, g_2, g_3, g_4\in [D]$ produce 4 intersection points inside $D$ and some three of them intersect each other inside $D$. Then
$$p_{44}=p_{44}^{(1)}+p_{44}^{(2)},$$
where 
\begin{equation} \label {p441}
p_{44}^{(1)}=\frac{6}{L^4}(2V_1-4D_2+C_2+U_2),
\end{equation}

\begin{equation} \label {p442}
p_{44}^{(2)}=\frac{3}{L^4}\bigg(\frac{3U_2+C_2}{2}-8I_3-2R-Q_s\bigg).
\end{equation}
\end{theorem}

\begin{proof}
There are two scenarios where four lines $g_i\in[D]$, $i=1, 2, 3, 4$ can generate four intersection points inside $D$. In the first scenario we require some three of the lines to make 3 intersection points inside $D$ (enclose a triangle inside $D$) and the fourth to cut exactly one out of those three inside $D$. Otherwise, in the second scenario, we require  any three out of the four lines to make exactly 2 intersections inside $D$ (the four lines enclose a convex quadrilateral inside $D$). We denote the mentioned two mutually exclusive events by $E_1$ and $E_2$, respectively, and need to prove that
$$
p(E_1)=\frac{6}{L^4}(2V_1-4D_2+C_2+U_2), \,\,\, p(E_2)=\frac{3}{L^4}\bigg(\frac{3U_2+C_2}{2}-8I_3-2R-Q_s\bigg).
$$
In the first scenario, there are four choices to select three out four lines to enclose a triangle inside $D$. Let those three be $g_1, g_2, g_3$. Consider the set of points $\mathcal{P}=(g_1\cup g_2\cup g_3)\cap \partial D$. Again, without loss of generality one can assume that $g_1\cap \partial D=\{P_1, P_4\}$, $g_2\cap \partial D=\{P_2, P_5\}$, and $g_3\cap \partial D=\{P_3, P_6\}$, where the points $P_i$ are consecutively distributed over the boundary $\partial D$.
Consider the set $B_4^{(1)}\in r(\mathcal{P})$ comprising of  six atoms $B_{4i}^{(1)}, i=1,2,\dots, 6$, where $B_{4i}^{(1)}$ separates the point $P_i$ from the other five points of $\mathcal{P}$.
Then
$$
  p(E_1)=\frac{4}{L^4}\int_{g_1\cap g_2\in D}dg_1dg_2\int_{[\chi(g_1)]\cap [\chi(g_2)]}\mu(B_4^{(1)})dg_3.
$$


The measure of each of the six atoms is computed below by Theorem \ref{Ambartzumian's theorem}.  
$$
\begin{aligned}
    \mu(B_{41}^{(1)})=&\rho_{12}+\rho_{16}-\rho_{26},\,\,\,\,\, \mu(B_{42}^{(1)})=\rho_{23}+\rho_{21}-\rho_{31}, \\
   \mu(B_{43}^{(1)})=&\rho_{34}+\rho_{32}-\rho_{42}, \,\,\,\,\, \mu(B_{44}^{(1)})=\rho_{45}+\rho_{43}-\rho_{53},\\ 
    \mu(B_{45}^{(1)})=&\rho_{56}+\rho_{54}-\rho_{64},\,\,\,\,\, \mu(B_{46}^{(1)})=\rho_{61}+\rho_{65}-\rho_{15}.
  \end{aligned}
$$

As a result, we obtain
$$
\begin{aligned}
  &p(E_1)=\frac{4}{L^4}\int_{g_1\cap g_2\in D}dg_1dg_2\int_{[\chi(g_1)]\cap [\chi(g_2)]}\sum_{i=1}^6\mu(B_{4i}^{(1)})dg_3=\\
  &\frac{4}{L^4}\int_{g_1\cap g_2\in D}dg_1dg_2\int_{[\chi(g_1)]\cap [\chi(g_2)]}2v(g_1,g_2,g_3)-\displaystyle{\sum_{ \langle g_1, g_2, g_3\rangle}|\chi_{12}|I_1(\chi_{12})}dg_3.
\end{aligned}
$$

Finally, using Lemma \ref{Integrals over Omega_3}, we arrive to
$$p(E_1)=\frac{4}{L^4}\bigg(2V_1-\frac{12D_2-3C_2-3U_2-2V_1}{2}
\bigg)=\frac{6}{L^4}(2V_1-4D_2+C_2+U_2).$$


In the second scenario, we have
\begin{equation}\label{p(E_2) original}
    p(E_2)=\frac{3}{2L^4}\int_{g_1\cap g_2\in D}dg_1dg_2\int_{\mathcal{S}}\mu(B_{4}^{(2)})dg_3,
\end{equation}
where
$$B_4^{(2)} = 
    \begin{cases}
        \mathcal{S}_2\cap [\chi(g_3)], & \mbox{if \, $g_3\in \mathcal{S}_1$}  \\
        \mathcal{S}_1\cap [\chi(g_3)], & \mbox{if \, $g_3\in \mathcal{S}_2$}
    \end{cases}.$$
    The measure $\mu(B_4^{(2)})$ can be computed by Theorem \ref{Ambartzumian's theorem} with reference to Figure~\ref{fig:FIG2}.

\begin{figure}[h]
    \centering
    \begin{subfigure}[t]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{P2_comb_decompose_muB4_1.png}
        \captionsetup{justification=centering}
        \caption{The case $g_{1} \cap g_{2} \in D$ and $g_{3}$ meets $\chi(g_1)$, but not $\chi(g_2)$}
    \end{subfigure}%    
    \begin{subfigure}[t]{0.45\textwidth}  
        \centering 
        \includegraphics[width=\textwidth]{P2_comb_decompose_muB4_2.png}
        \captionsetup{justification=centering}
        \caption{The case $g_{1} \cap g_{2} \in D$ and $g_{3}$ meets $\chi(g_2)$, but not $\chi(g_1)$}
    \end{subfigure}
    \caption{The distribution of signs over the chords participating in the combinatorial decomposition of $\mu(B_{4}^{(2)}).$}
    \label{fig:FIG2}
\end{figure}

  The formula \eqref{Ambartzumian} implies
  $$\mu(B_4^{(2)})=\displaystyle{\sum_{\langle g_1, g_2\rangle\cup \langle g_1, g_3\rangle}  |\chi_{12}|I_1(\chi_{12})}-\displaystyle{\sum_{\langle g_2, g_3\rangle}|\chi_{12}|I_0(\chi_{12})}-2|\chi(g_1)|, \,\,\text{if}\,\, g_3\in \mathcal{S}_1,$$
  and 
  $$\mu(B_4^{(2)})=\displaystyle{\sum_{\langle g_1, g_2\rangle\cup \langle g_2, g_3\rangle}  |\chi_{12}|I_1(\chi_{12})}-\displaystyle{\sum_{\langle g_1, g_3\rangle}|\chi_{12}|I_0(\chi_{12})}-2|\chi(g_2)|, \,\,\text{if}\,\, g_3\in \mathcal{S}_2.$$
 
 By incorporating the indicator functions $I_{\mathcal{S}_i}$, we plug in the obtained expressions into \eqref{p(E_2) original}.     
$$\begin{aligned}
  &p(E_2)=\frac{3}{2L^4}\int_{g_1\cap g_2\in D}dg_1dg_2\int_{\mathcal{S}}2\cdot\displaystyle{\sum_{\langle g_1, g_2\rangle}|\chi_{12}|I_1(\chi_{12})}dg_3-\\
  &-\frac{3}{2L^4}\int_{g_1\cap g_2\in D}dg_1dg_2\int_{\mathcal{S}}I_{\mathcal{S}_1}\displaystyle{\sum_{\langle g_2, g_3\rangle}|\chi_{12}|I_0(\chi_{12})}+I_{\mathcal{S}_2}\displaystyle{\sum_{\langle g_1, g_3\rangle}|\chi_{12}|I_0(\chi_{12})}dg_3-\\
  &-\frac{3}{2L^4}\int_{g_1\cap g_2\in D}dg_1dg_2\int_{\mathcal{S}}2\cdot I_{\mathcal{S}_1}|\chi(g_1)|+2\cdot I_{\mathcal{S}_2}|\chi(g_2)|dg_3. 
\end{aligned}$$ 
Finally, due to Lemma \ref{The biggest lemma} (the first three identities) we come up with
$$p(E_2)=\frac{3}{2L^4}\bigg(2\cdot\bigg(\frac{7U_2-4D_2+C_2}{4}-2R\bigg)-2Q_s-2\cdot\bigg(\frac{U_2-C_2-4D_2}{4}+8I_3\bigg) \bigg)=$$
$$=\frac{3}{L^4}\bigg(\frac{3U_2+C_2}{2}-8I_3-2R-Q_s\bigg).$$
The proof is thus complete.
\end{proof}

Three intersection points made by four lines from $[D]$ can occur in three ways:\\ 
Event 1: The lines produce three chords each possessing two intersection points, and one containing no intersection point;\\
Event 2: The lines produce two chords each possessing 2 intersection points, and the other two each possessing 1 intersection point;\\
Event 3: The lines produce three chords each possessing 1 intersection point, and one possessing 3 intersection points.   

We denote by $p_{43}^{(1)},\, p_{43}^{(2)},\, p_{43}^{(3)}$ the probabilities of Event 1, Event 2, and Event 3, respectively. 

\begin{theorem}\label{theorem for p43}
$$p_{43}=p_{43}^{(1)}+ p_{43}^{(2)}+p_{43}^{(3)},$$  
where 
\begin{equation} \label {p431}
p_{43}^{(1)}=\frac{4}{L^4}(C_1L-V_1),
\end{equation}

\begin{equation} \label {p432}
p_{43}^{(2)}=\frac{12}{L^4}(Q_s+2R-U_2),
\end{equation}

\begin{equation} \label {p433}
p_{43}^{(3)}=\frac{3}{L^4}(C_2-4D_2-U_2)+\frac{4}{L^4}(Q_d+2R)+\frac{64}{L^4}I_3.
\end{equation}
\end{theorem}

\begin{proof}
Events 1, 2, and 3 are mutually exclusive and cover all the cases of three intersections inside $D$.

Let's now define an undirected graph $T$ with the vertex set $\{1, 2, 3, 4\}$, where the vertices $i$ and $j$ are adjacent if and only if $g_i\cap g_j\in D$. If $g_1, g_2, g_3, g_4$ are placed as described in the Event 1, then there are four possibilities to make a graph $T$ (three vertices of degree 2, and one vertex of degree 0). Thus,  
\begin{equation*}\label{p_{Event 1} original}
  p_{43}^{(1)}=\frac{4}{L^4}\int_{g_1\cap g_2\in D}dg_1dg_2\int_{[\chi(g_1)]\cap [\chi(g_2)]}\mu(B_3^{(1)})dg_3,
\end{equation*}
where $B_3^{(1)}=[\chi(g_1)]^c\cap[\chi(g_2)]^c\cap[\chi(g_3)]^c.$

Since $\mu(B_3^{(1)})=L-v(g_1, g_2, g_3)$, we obtain
$$p_{43}^{(1)}=\frac{4}{L^3}\int_{g_1\cap g_2\in D}dg_1dg_2\int_{[\chi(g_1)]\cap [\chi(g_2)]}dg_3-\frac{4V_1}{L^4}=4p_{33}-\frac{4V_1}{L^4}.$$
As by \eqref{old probabilities in new terms}, $p_{33}=\displaystyle{\frac{C_1}{L^3}}$, we establish \eqref{p431}.

If $g_1, g_2, g_3, g_4$ are placed as described in Event 2, then the number of possible graphs $T$ (with two vertices of degree 2, and two vertices of degree 1) is 12. This number will be reduced to 4 if one additionally requires for the vertices 1 and 2 to be adjacent, the vertex 3 to be adjacent to either 1, or 2, but not both (see Figure~\ref{fig:FIG3}).  
\vskip 5pt
\begin{figure}[h]
    \centering
    \begin{subfigure}[t]{0.2\textwidth}
        \centering
        \includegraphics[width=\textwidth]{P2_versions_of_T_1.png}
        \captionsetup{justification=centering}
    \end{subfigure}\hfill%    
    \begin{subfigure}[t]{0.2\textwidth}  
        \centering 
        \includegraphics[width=\textwidth]{P2_versions_of_T_2.png}
        \captionsetup{justification=centering}
    \end{subfigure}\hfill%
    \begin{subfigure}[t]{0.2\textwidth}  
        \centering 
        \includegraphics[width=\textwidth]{P2_versions_of_T_3.png}
        \captionsetup{justification=centering}
    \end{subfigure}\hfill%
    \begin{subfigure}[t]{0.2\textwidth}  
        \centering 
        \includegraphics[width=\textwidth]{P2_versions_of_T_4.png}
        \captionsetup{justification=centering}
    \end{subfigure}
    \caption{Versions of $T$ where $1$ is adjacent to $2$, and $3$ is adjacent to either $2$, or $1$, but not both (Event 2).}
    \label{fig:FIG3}
\end{figure}
\vskip 5pt
Hence, we acquire 
\begin{equation}\label{p_{Event 2} original}
  p_{43}^{(2)}=\frac{12}{4L^4}\int_{g_1\cap g_2\in D}dg_1dg_2\int_{\mathcal{S}}\mu(B_3^{(2)})dg_3,
\end{equation}
where 
$$B_3^{(2)} = 
    \begin{cases}
        [\chi(g_1)]^c\cap \big([\chi(g_2)]\Delta [\chi(g_3)]\big), & \mbox{if \, $g_3\in \mathcal{S}_1$}  \\
        [\chi(g_2)]^c\cap \big([\chi(g_1)]\Delta [\chi(g_3)]\big), & \mbox{if \, $g_3\in \mathcal{S}_2$}
    \end{cases},$$ and $\Delta$ stands for the symmetric difference operation.
    

 In the last scenario, if $g_1, g_2, g_3, g_4$ are placed as described in Event 3, then there are only four graphs $T$ (three vertices of degree 1, and one vertex of degree 3). An extra restriction demanding the vertices 1 and 2 to be adjacent, and the vertex 3 to be adjacent to either 1, or 2, but not both, allows making only two graphs $T$. Those are displayed below in Figure~\ref{fig:FIG4}. 
\vskip 5pt
\begin{figure}[h]
    \centering
    \begin{subfigure}[t]{0.2\textwidth}
        \centering
        \includegraphics[width=\textwidth]{P2_versions_of_T_star_1.png}
        \captionsetup{justification=centering}
    \end{subfigure}\hspace{0.15\textwidth}%    
    \begin{subfigure}[t]{0.2\textwidth}  
        \centering 
        \includegraphics[width=\textwidth]{P2_versions_of_T_star_2.png}
        \captionsetup{justification=centering}
    \end{subfigure}
    \caption{Versions of $T$ where $1$ is adjacent to $2$, and $3$ is adjacent to either $2$, or $1$, but not both(Event 3).}
    \label{fig:FIG4}
\end{figure}
\vskip 5pt
 Consequently,
 \begin{equation}\label{p_{Event 3} original}
  p_{43}^{(3)}=\frac{4}{2L^4}\int_{g_1\cap g_2\in D}dg_1dg_2\int_{\mathcal{S}}\mu(B_3^{(3)})dg_3,
\end{equation}
where 
 $$B_3^{(3)} = 
    \begin{cases}
        [\chi(g_1)]\cap [\chi(g_2)]^c\cap [\chi(g_3)]^c, & \mbox{if \, $g_3\in \mathcal{S}_1$}  \\
        [\chi(g_1)]^c\cap [\chi(g_2)]\cap [\chi(g_3)]^c, & \mbox{if \, $g_3\in \mathcal{S}_2$}
    \end{cases}.$$


It remains to calculate $\mu(B_3^{(2)})$ and $\mu(B_3^{(3)})$, and then, the integrals \eqref{p_{Event 2} original} and \eqref{p_{Event 3} original}, accordingly. For the measures we apply the combinatorial formula \eqref{Ambartzumian}, while the integrals need the Lemma \ref{The biggest lemma} to be used. Computation is similar to the one used for proving \eqref{p442}, and therefore, omitted. 
\end{proof}


Two intersection points generated by four lines are possible in two scenarios:\\ 
Event 1: One chord possesses 2 intersection points,  two of the chords possess 1 intersection point each, and one chord does not possess any intersection point;\\
Event 2: Each chord of the four lines possesses exactly 1 intersection point. \\  
Let the probabilities of the above mentioned events be $p_{42}^{(1)}$ and $p_{42}^{(2)}$, respectively.  
\begin{theorem}\label{theorem for p42}
$$p_{42}=p_{42}^{(1)}+ p_{42}^{(2)},$$  
where 
\begin{equation} \label{p421}
p_{42}^{(1)}=4p_{32}-\frac{3}{L^4}\big(C_2-4D_2-U_2-4(Q_s+2R)\big),
\end{equation}

\vskip -7mm

\begin{equation} \label {p422}
p_{42}^{(2)}=\frac{12\pi^2F^2}{L^4}+\frac{48I_3}{L^4}-\frac{3}{4L^4}\big(U_2-C_2+12D_2\big)-\frac{1}{4}\big(p_{44}^{(1)}+2p_{43}^{(2)}\big).
\end{equation}

\end{theorem}

\begin{proof}
The Events 1 and 2 are mutually exclusive, so it remains to verify \eqref{p421} and \eqref{p422}. We first notice that
\begin{equation*}\label{p_{Event 1 p421} original}
  p_{42}^{(1)}=\frac{12}{2L^4}\int_{g_1\cap g_2\in D}dg_1dg_2\int_{\mathcal{S}}\mu(B_2^{(1)})dg_3,
\end{equation*}
where $B_2^{(1)}=[\chi(g_1)]^c\cap[\chi(g_2)]^c\cap[\chi(g_3)]^c$. Since $\mu\big(B_2^{(1)}\big)=L-v(g_1, g_2, g_3)$, we obtain
$$p_{42}^{(1)}=\frac{6}{L^3}\int_{g_1\cap g_2\in D}\mu(\mathcal{S})dg_1dg_2-\frac{6}{L^4}\int_{g_1\cap g_2\in D}dg_1dg_2\int_{\mathcal{S}}\displaystyle{\sum_{\langle g_1, g_2, g_3\rangle}|\chi_{12}|I_0(\chi_{12})}dg_3.$$
We recognize that the first term above is equal to $6\cdot \frac{2}{3}p_{32}=4p_{32}$. Evaluation of the second term is based on \eqref{I_0 over Omega2 no proof} and \eqref{I_0 over Omega2}. Indeed,
$$
\begin{aligned}
&\int_{g_1\cap g_2\in D}dg_1dg_2\int_{\mathcal{S}}\displaystyle{\sum_{\langle g_1, g_2, g_3\rangle}|\chi_{12}|I_0(\chi_{12})}dg_3=\\
&\int_{g_1\cap g_2\in D}dg_1dg_2\int_{\mathcal{S}}\displaystyle{I_{\mathcal{S}_1}\sum_{\langle g_1, g_2\rangle \cup \langle g_1, g_3\rangle }|\chi_{12}|I_0(\chi_{12})}+I_{\mathcal{S}_2}\displaystyle{\sum_{\langle g_1, g_2\rangle \cup \langle g_2, g_3\rangle }|\chi_{12}|I_0(\chi_{12})}+\\
&\displaystyle{I_{\mathcal{S}_1}\sum_{\langle g_2, g_3\rangle}|\chi_{12}|I_0(\chi_{12})}+\displaystyle{I_{\mathcal{S}_2}\sum_{\langle g_1, g_3\rangle}|\chi_{12}|I_0(\chi_{12})}dg_3=\\
&\int_{g_1\cap g_2\in D}dg_1dg_2\int_{\mathcal{S}}\displaystyle{2\sum_{\langle g_1, g_2\rangle}|\chi_{12}|I_0(\chi_{12})}+\displaystyle{I_{\mathcal{S}_1}\sum_{\langle g_2, g_3\rangle}|\chi_{12}|I_0(\chi_{12})}+\\
&\displaystyle{I_{\mathcal{S}_2}\sum_{\langle g_1, g_3\rangle}|\chi_{12}|I_0(\chi_{12})}dg_3=\frac{C_2-4D_2-U_2}{2}+4R+2Q_s,
\end{aligned}
$$
and \eqref{p421} is proved.

The other "partial" probability is expressible by the following integral.
\begin{equation}\label{p_{Event 1 p422} original}
  p_{42}^{(2)}=\frac{1}{2}{4 \choose 2}\frac{1}{L^4}\int_{g_1\cap g_3\not\in D}dg_1dg_3\int_{[\chi(g_1)]\cap[\chi(g_3)]^c}\mu(B_2^{(2)})dg_2,
\end{equation}
where $B_2^{(2)}=[\chi(g_3)]\cap[\chi(g_2)]^c\cap[\chi(g_1))]^c.$  Then
\begin{equation}\label{mu B22}
   \mu(B_2^{(2)})=2|\chi(g_3)|-\mu \big(\cap_{i=1}^3 [\chi(g_i)]\big)-\mu\big(\big([\chi(g_1)]\Delta [\chi(g_2)]\big)\cap[\chi(g_3)]\big). 
\end{equation}
Since
$$
  \frac{1}{L^4}\int_{g_1\cap g_3\not\in D}dg_1dg_3\int_{[\chi(g_1)]\cap[\chi(g_3)]^c}\mu\big(\cap_{i=1}^3 [\chi(g_i)]\big)dg_2=\frac{1}{12}p_{44}^{(1)}
$$
and 
$$
  \frac{1}{L^4}\int_{g_1\cap g_3\not\in D}dg_1dg_3\int_{[\chi(g_1)]\cap[\chi(g_3)]^c}\mu\big(\big([\chi(g_1)]\Delta [\chi(g_2)]\big)\cap[\chi(g_3)]\big)dg_2=\frac{1}{6}p_{43}^{(2)},
$$
then due to \eqref{p_{Event 1 p422} original}, the proof will be finished if we show that

\begin{equation}\label{chi over Omega 13}
    \int_{g_1\cap g_3\not\in D}dg_1dg_3\int_{[\chi(g_1)]\cap [\chi(g_3)]^c}|\chi(g_3)|dg_2=2\pi^2F^2+8I_3-\frac{U_2-C_2+12D_2}{8}.
\end{equation}

By the combinatorial formula,
$$\mu\big([\chi(g_1)]\cap [\chi(g_3)]^c\big)=s_1+s_2-d_1-d_2+2|\chi(g_1)|.$$
Then the integral in \eqref{chi over Omega 13} is equal to \begin{equation} \label{two integrals}
   2\int_{g_1\cap g_3\not\in D}|\chi(g_1)||\chi(g_3)|dg_1dg_3-\int_{g_1\cap g_3\not\in D}|\chi(g_3)|(d_1+d_2-s_1-s_2)dg_1dg_3. 
\end{equation}  
The first term in \eqref{two integrals} is equal to 
$$2\int_{[D]}dg_1\int_{[D]}|\chi(g_1)||\chi(g_3)|dg_3-2\int_{g_1\cap g_3\in D}|\chi(g_1)||\chi(g_3)|dg_1dg_3=2\pi^2F^2-D_2+4I_3,$$
while the second term is equal to
$$
\begin{aligned}
&\int_{g_1\cap g_3\not\in D}|\chi(g_3)|dg_1dg_3\int_{[\chi(g_1)]\cap [\chi(g_3)]}dg_2=\\
&\frac{1}{2}\int_{g_1\cap g_2\in D}dg_1dg_2\int_{\mathcal{S}}I_{\mathcal{S}_1}|\chi(g_2)|+I_{\mathcal{S}_2}|\chi(g_1)|dg_3=\frac{U_2-C_2+4D_2}{8}-4I_3,
\end{aligned}$$
where the last equality holds due to \eqref{chi over Omega 2 non-proven}. 

To complete the proof, it remains to subtract the last expression from $2\pi^2F^2-D_2+4I_3$ and check that it is equal to the right-hand side of \eqref{chi over Omega 13}.   



\end{proof}


\begin{theorem}\label{theorem for p41}

 
$$
p_{41}=2p_{31}-2p_{42}^{(2)}-\frac{6U_1}{L^3}+\frac{6U_2}{L^4}.
$$
\end{theorem}
\begin{proof}
 The only possible way to generate one intersection point inside $D$ is having two chords possessing 1 intersection point each, and two more chords possessing no intersection points. The model yields
 \begin{equation}\label{p41 original}
  p_{41}={4 \choose 2}\frac{1}{L^4}\int_{g_1\cap g_3\not\in D}dg_1dg_3\int_{[\chi(g_1)]\cap[\chi(g_3)]^c}\mu(B_1)dg_2,
\end{equation}
where $B_1=[\chi(g_3)]^c\cap[\chi(g_2)]^c\cap[\chi(g_1))]^c.$ We deliver the computation of $\mu(B_1)$ by the combinatorial algorithm through the Figure~\ref{fig:FIG5}. 

\begin{figure}[h]
    \centering
    \begin{subfigure}[t]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{P2_comb_decompose_muB1.png}
        \captionsetup{justification=centering}
    \end{subfigure}%    
    \caption{The distribution of signs over the chords participating in the combinatorial decomposition of $\mu(B_{1}).$}
    \label{fig:FIG5}
\end{figure}

Let's fix $g_1, g_2, g_3\in [D]$ such that the first two intersect each other inside $D$, and $g_3$ intersects none of the chords $\chi(g_1),\,\chi(g_2)$. Consider the set of points $\mathcal{P}=(g_1\cup g_2\cup g_3)\cap \partial D$. Without loss of generality, we assume that $g_1\cap \partial D=\{P_1, P_5\}$, $g_2\cap \partial D=\{P_2, P_6\}$, and $g_3\cap \partial D=\{P_3, P_4\}$, where the points $P_i$ are consecutively distributed over the boundary $\partial D$. As usual, we denote by $\rho_{ij}$ the Euclidean distance between points $P_i$ and $P_j$. Then $B_1$ consists of the lines that lie in the complement of the convex hull of $\mathcal{P}$ and the atom $A\in r(\mathcal{P})$ that separates the points $P_3,P_4$ from the other four. Hence, $\mu(B_1)=L-\rho_{12}-\rho_{23}-\dots-\rho_{61}+\mu(A).$ Since $\mu(A)=\rho_{24}+\rho_{35}-|\chi(g_3)|-\rho_{25},$
we obtain
$$\mu(B_1)=L-u(g_1,g_2)-2|\chi(g_3)|+\rho_{24}+\rho_{35}-\rho_{23}-\rho_{45}.$$
On the other hand, $\rho_{24}+\rho_{35}-\rho_{23}-\rho_{45}$ can be interpreted as the measure of the set of lines that cut $\chi(g_3)$ and meet at least one of the chords $\chi(g_1), \, \chi(g_2)$. From \eqref{mu B22}, that measure is equal to $2|\chi(g_3)|-\mu(B_2^{(2)})$, and therefore we establish
\begin{equation*}\label{muB1 nice}
    \mu(B_1)=L-u(g_1,g_2)-\mu(B_2^{(2)}).
\end{equation*}
It is easy to verify that
$$\frac{1}{L^4}\int_{g_1\cap g_3\not\in D}dg_1dg_3\int_{[\chi(g_1)]\cap[\chi(g_3)]^c}Ldg_2=\frac{1}{3}p_{31}$$
and 
$$\frac{1}{L^4}\int_{g_1\cap g_3\not\in D}dg_1dg_3\int_{[\chi(g_1)]\cap[\chi(g_3)]^c}\mu(B_2^{(2)})dg_2=\frac{1}{3}p_{42}^{(2)}.$$
Integration of $u(g_1, g_2)$ requires change of order. 
$$
\begin{aligned}
&\frac{1}{L^4}\int_{g_1\cap g_3\not\in D}dg_1dg_3\int_{[\chi(g_1)]\cap[\chi(g_3)]^c}u(g_1,g_2)dg_2=\\
&\frac{1}{L^4}\int_{g_1\cap g_2\in D}u(g_1, g_2)dg_1dg_2\int_{[\chi(g_1)]^c\cap[\chi(g_2)]^c}dg_3=\\
&\frac{1}{L^4}\int_{g_1\cap g_2\in D}u(g_1, g_2)\big(L-u(g_1, g_2)\big)dg_1dg_2=\frac{U_1}{L^3}-\frac{U_2}{L^4}.
\end{aligned}
$$

Now from \eqref{p41 original} we conclude 
$p_{41}=6\cdot\bigg(\frac{1}{3}p_{31}-\frac{1}{3}p_{42}^{(2)}-\frac{U_1}{L^3}+\frac{U_2}{L^4}\bigg)=2p_{31}-2p_{42}^{(2)}-\frac{6U_1}{L^3}+\frac{6U_2}{L^4}.$

\end{proof}

Finally, the probability of having no intersection points inside $D$ is $p_{40}=1 - \displaystyle{\sum_{k=1}^6}p_{4k}$.  
  

\section{Representation of $I_3$ and $V_1$ by intersection probabilities}\label{I_3 and V_1 expressions}

In this section, we first aim to express the invariants $V_1$ and $I_3$ by intersection probabilities to establish an analogue of \eqref{I_2 and U in terms of prob}. Looking through the formulas of $p_{4k}$ obtained in the previous two sections, we notice that the family of new invariants can be reduced to $U_2, C_2, D_2, K_d, K_s, V_1$ and $I_3$, where $K_s=Q_s+2R$ and $K_d=Q_d+2R$. $I_3$ is found by Crofton \cite{Crofton} (see also \cite{Santalo}, p. 47) to be equal to $3F^2$ but we will not be using this result below.  
  
\begin{theorem}\label{I3 and V1}
The following identities hold:
\begin{equation}\label{V1}
    V_1=L^4\big(p_{33}-\frac{1}{4}p_{43}^{(1)}\big),
\end{equation}
\begin{equation}\label{I3}
    I_3=\frac{L^4}{32}\big(4p_{33}+p_{43}^{(3)}-p_{43}^{(1)}\big).
\end{equation}
\end{theorem}
\begin{proof}
\eqref{V1} immediately follows from \eqref{old probabilities in new terms} and \eqref{p431}.

Let us compute the mean number of the intersection points generated by four lines inside $D$. We directly use the formulas for intersection probabilities $p_{4k}$, $k=6,5,\dots, 1$ obtained in the previous two sections. By combining the like terms accurately, we receive
\begin{equation}\label {mean number}
    \displaystyle{\sum_{k=1}^6kp_{4k}=\frac{12\pi F}{L^2}}+\frac{3}{L^4}(-3U_2+3C_2-12D_2+4V_1+4K_d+32I_3).
\end{equation}

On the other hand, the mean number of intersection points generated by $n$ lines inside $D$ is known (see \cite{Santalo}) to be equal to $\frac{n(n-1)\pi F}{L^2}$. Thus, from \eqref{mean number} we obtain
$$
    -3U_2+3C_2-12D_2+4V_1+4K_d+32I_3=0.
$$
Based on \eqref{p433}, the last identity can be rewritten as $p_{43}^{(3)}\cdot L^4+4V_1-32I_3=0$, i.e. 
\begin{equation}\label{new p433}
    p_{43}^{(3)}=\frac{4}{L^4}(8I_3-V_1).
\end{equation}
Now \eqref{I3} follows from \eqref{V1} and \eqref{new p433}.
\end{proof}
Below we check the results against the second moment of the number of intersection points generated by $n$ lines inside $D$ (for the formula below, see \cite{Santalo}, p. 53):
\begin{equation}\label{squared mean}
    E(v^2)=2\pi{n\choose 2}\frac{F}{L^2}+24\pi^2{n\choose 4}\frac{F^2}{L^4}+24{n\choose 3}\frac{I_2}{L^3}.
\end{equation}
We start with the direct substitution of the obtained probabilities into the second moment formula.
$$
\begin{aligned}
&\displaystyle{\sum_{k=1}^6k^2p_{4k}}=2p_{31}+16p_{32}-\frac{1}{2}p_{44}^{(1)}-p_{43}^{(2)}+\frac{1}{L^4}\bigg(-36U_2+30C_2-120D_2+\\
&+42V_1+288I_3+12K_s+36K_d+36LC_1+24\pi^2 F^2 -6LU_1\bigg).
\end{aligned}
$$
Further substitution of the known expressions for $p_{31}, p_{32}, p_{44}^{(1)}$, and $p_{43}^{(2)}$ results in

\begin{equation}\label{second moment continued}
    \begin{aligned}
&\displaystyle{\sum_{k=1}^6k^2p_{4k}}=\frac{12\pi F}{L^2}+\frac{24\pi^2 F^2}{L^4}+\frac{36(U_1+C_1)-192I_2}{L^3}+\\
&+\frac{1}{L^4}\bigg(27C_2-27U_2-108D_2+36K_d+288I_3+36V_1\bigg).
\end{aligned}
\end{equation}
Since $36(U_1+C_1)=72D_1=288I_2$ and,  from \eqref{p433},
$$27C_2-27U_2-108D_2+36K_d+576I_3=9L^4p_{43}^{(3)},$$
\eqref{second moment continued} implies
$$\displaystyle{\sum_{k=1}^6k^2p_{4k}}=\frac{12\pi F}{L^2}+\frac{24\pi^2 F^2}{L^4}+\frac{96I_2}{L^3}+\frac{9}{L^4}\bigg(p_{43}^{(3)}\cdot L^4+4V_1-32I_3\bigg).$$
Due to \eqref{new p433}, the last expression in the parentheses is equal to zero. This means that we reached the right-hand side of \eqref{squared mean} for $n=4$.


\section{Computation of intersection probabilities for a disc with radius $r$}\label {disc probabilities}

The formulas obtained for intersection probabilities motivated us to compute invariants of $D$ through simulations. For example, we used Python 3 software to approximate the values of $I_2, U_1, I_3,$ and $V_1$ for the unit disk. The code for the simulations can be found here: \url{http://rb.gy/1wei7h}. Expressions of all the new invariants in terms of $r$ for a disc of radius $r$ are established in the current section.  

Let $D$ be the disc of radius $r$ centered at the origin. For $g_1\cap g_2 \in D$, we consider $g_1$ to be the horizontal line $y=-r\sin a$ ($0 < a < \frac{\pi}{2}$) in the Cartesian plane, and $g_2$, the line that passes through the points $(r\cos w_1, r\sin w_1)$ and $(r\cos w_2, r\sin w_2)$, where $-a < w_1 < \pi +a < w_2 < 2\pi-a$ (see Figure~\ref{fig:FIG8}).

\vskip 10pt
\begin{figure}[h]
    \centering
    \begin{subfigure}[t]{0.65\textwidth}
        \centering
        \includegraphics[width=\textwidth]{P2_unit_disk.png}
        \captionsetup{justification=centering}
    \end{subfigure}%    
    \caption{The model of two random lines $g_1$ and $g_2$ intersecting each other inside $D = \{(x,y):x^2 + y^2 < r^2\}$}
    \label{fig:FIG8}
\end{figure}

Then
$$dg_1=2\pi r \cos a da \,\,\,\text{and}\,\,\,dg_2=\frac{1}{2} r \sin \frac{w_2-w_1}{2}dw_1dw_2,$$ and therefore  
\begin{equation}\label{dg_1dg_2}
    dg_1dg_2=\pi r^2 \cos a\sin\frac{w_2-w_1}{2}dw_1dw_2.
\end{equation}

\begin{lemma}\label{U_1 exact}
If $D$ is a disc with radius $r$ then 
$$U_1=(2\pi^3+\frac{32}{3}\pi)r^3. $$
\end{lemma}
\begin{proof}
It is easy to verify that 
\begin{equation*}\label{perimeter}
    u(g_1, g_2)=2r\bigg(\cos\frac{w_1-a}{2}-\cos\frac{w_2-a}{2}+\sin\frac{w_1+a}{2}+\sin\frac{w_2+a}{2}\bigg).
\end{equation*}
Then by \eqref{dg_1dg_2}, we obtain
\begin{equation*}\label{Integral for U_1}
\begin{aligned}
U_1&=2\pi r^3 \int_0^{\frac{\pi}{2}}\cos a da \int_{-a}^{\pi+a}dw_1\int_{\pi+a}^{2\pi-a} \bigg(\cos\frac{w_1-a}{2}-\cos\frac{w_2-a}{2}+\\
&+ \sin\frac{w_1+a}{2}+\sin\frac{w_2+a}{2}\bigg) \sin\frac{w_2-w_1}{2}dw_2,
\end{aligned}
\end{equation*}
and reduce it to
\begin{equation}\label{reduced U_1}
    U_1=8\pi^2r^3\int_0^{\frac{\pi}{2}}\cos^2a da + 16\pi r^3\int_0^{\frac{\pi}{2}}\cos^3a da = (2\pi^3+\frac{32}{3}\pi)r^3.
\end{equation}
\end{proof}
\begin{corollary}
If $D$ is a disc with radius $r$ then
\begin{equation*}\label{exact p_3k}
    p_{33}=p_{30}=\frac{4}{\pi^2} -\frac{1}{4}\,\,\text{and}\,\, p_{32}=p_{31}= \frac{3}{4}-\frac{4}{\pi^2}. 
\end{equation*}

\end{corollary}

\begin{proof}
The proof immediately follows from \eqref{p_{3k}}, the identity $I_2=\frac{16}{3}\pi r^3$ (see \cite{Santalo}, p. 48) and Lemma \ref{U_1 exact}. 
\end{proof}
The above technique can be applied to reveal the exact numerical values of further invariants of $D$. 
\begin{lemma}\label{U_2 and others exact}
If $D$ is a disc with radius $r$ then
\begin{equation}\label{D_2 exact}
 D_2=(\frac{2}{3}\pi^4+17\pi^2)r^4,   
\end{equation}
\begin{equation}\label{U_2 exact}
 U_2=(\frac{2}{3}\pi^4+41\pi^2)r^4,   
\end{equation}
\begin{equation}\label{C_2 exact}
 C_2=(\frac{10}{3}\pi^4-\frac{73}{3}\pi^2)r^4, 
\end{equation}
\begin{equation}\label{V_1 exact}
 V_1=(41\pi^2-2\pi^4)r^4,   
\end{equation}
\begin{equation}\label{R exact}
 R=(\frac{2}{3}\pi^4+\frac{47}{3}\pi^2)r^4,   
\end{equation}
\begin{equation}\label{Q_s exact}
 Q_s=(\frac{2}{3}\pi^4-2\pi^2)r^4,   
\end{equation}
\begin{equation}\label{Q_d exact}
 Q_d=(\frac{2}{3}\pi^4+\frac{11}{3}\pi^2)r^4.   
\end{equation}
\end{lemma}

\begin{proof}
For $g_1\cap g_2\in D$, the lengths of intersecting chords are   $|\chi(g_1)|=2r\cos a$ and $|\chi(g_2)|=2r\sin \frac{w_2-w_1}{2}$. Since 
$$D_2=4I_3+2\int_{g_1\cap g_2\in D}|\chi(g_1)||\chi(g_2)|dg_1dg_2,$$
then due to \eqref{dg_1dg_2}, we obtain (hereinafter, long intermediate steps of integration are omitted)
$$D_2= 12\pi^2r^4+8\pi r^4 \int_0^{\frac{\pi}{2}}\cos^2 a da \int_{-a}^{\pi+a}dw_1\int_{\pi+a}^{2\pi-a} \sin^2\frac{w_2-w_1}{2}dw_2=(\frac{2}{3}\pi^4+17\pi^2)r^4.$$
Evaluation of $U_2$ is provided below:
$$\begin{aligned}
U_2&=4\pi r^4 \int_0^{\frac{\pi}{2}}\cos a da \int_{-a}^{\pi+a}dw_1\int_{\pi+a}^{2\pi-a} \bigg(\cos\frac{w_1-a}{2}-\cos\frac{w_2-a}{2}+\\
&+ \sin\frac{w_1+a}{2}+\sin\frac{w_2+a}{2}\bigg)^2 \sin\frac{w_2-w_1}{2}dw_2=(\frac{2}{3}\pi^4+41\pi^2)r^4.
\end{aligned}$$
Now \eqref{C_2 exact} follows from \eqref{D_2 exact}, \eqref{U_2 exact}, the identity
$$C_2=4D_2+U_2- 8\cdot\int_{g_1\cap g_2\in D}|\chi(g_1)|u(g_1, g_2)dg_1dg_2,$$
and (see \eqref{reduced U_1})
$$\int_{g_1\cap g_2\in D}|\chi(g_1)|u(g_1, g_2)dg_1dg_2=16r^4\bigg(\pi^2\int_0^{\frac{\pi}{2}}\cos^3a da + 2\pi\int_0^{\frac{\pi}{2}}\cos^4 a da\bigg)=\frac{50}{3}\pi^2r^4.$$
\vskip 10pt

$V_1$ is an integral over three lines that produce three intersection points inside $D$. To compute $V_1$ with the already developed technique, we need to represent it by an integral over $g_1\cap g_2$. We complete this task in two steps. First, we apply the combinatorial algorithm to suggest an alternative expression for the left-hand side of \eqref{I_1 over Omega 3}. 
$$
\begin{aligned}
&\int_{g_1\cap g_2\in D}dg_1dg_2\int_{[\chi(g_1)]\cap [\chi(g_2)]}\displaystyle{\sum_{\chi_{12}\in \langle g_1, g_2, g_3\rangle}|\chi_{12}|I_1(\chi_{12})} dg_3=\\
& 3 \int_{g_1\cap g_2\in D}dg_1dg_2\int_{[\chi(g_1)]\cap [\chi(g_2)]}\displaystyle{\sum_{\chi_{12}\in \langle g_1, g_2\rangle}|\chi_{12}|I_1(\chi_{12})} dg_3=\\
& 3 \int_{g_1\cap g_2\in D}\bigg\{(\rho_1+\rho_3)\bigg[|\chi(g_1)|+|\chi(g_2)|-\rho_2-\rho_4\bigg]+(\rho_2+\rho_4)\times \\
& \times \bigg[|\chi(g_1)|+|\chi(g_2)|-\rho_1-\rho_3\bigg]\bigg\}dg_1dg_2=6\int_{g_1\cap g_2\in D}\bigg\{|\chi(g_1)|u(g_1, g_2)- \\
& - (\rho_1+\rho_3)(\rho_2+\rho_4)\bigg\}dg_1dg_2=100\pi^2r^4-6\int_{g_1\cap g_2\in D} (\rho_1+\rho_3)(\rho_2+\rho_4)dg_1dg_2. 
\end{aligned}
$$
In the second step, we make the obtained expression equal to the right-hand side of \eqref{I_1 over Omega 3}, substitute $C_2, D_2$, and $U_2$ by their known values, and figure out  
\begin{equation}\label{V_1 by rho}
    V_1=6\int_{g_1\cap g_2\in D} (\rho_1+\rho_3)(\rho_2+\rho_4)dg_1dg_2-(23\pi^2+2\pi^4)r^4.
\end{equation}
The pairs of the lengths of the opposite sides in the quadrilateral $conv\big((g_1\cup g_2)\cap \partial D\big)$ are  
$$2r\cos\frac{w_1-a}{2}, \,2r\sin\frac{w_2+a}{2}\,\,\, \text{and}\,\,\, -2r\cos\frac{w_2-a}{2}, \,2r\sin\frac{w_1+a}{2}.$$
This enables us to compute the integral in \eqref{V_1 by rho},
$$\begin{aligned}
&\int_{g_1\cap g_2\in D} (\rho_1+\rho_3)(\rho_2+\rho_4)dg_1dg_2=4\pi r^4 \int_0^{\frac{\pi}{2}}\cos a da \int_{-a}^{\pi+a}dw_1 \times\\
& \times \int_{\pi+a}^{2\pi-a} \bigg(\cos\frac{w_1-a}{2}+\sin\frac{w_2+a}{2}\bigg)\bigg(\sin\frac{w_1+a}{2}-\cos\frac{w_2-a}{2}\bigg) \sin\frac{w_2-w_1}{2}dw_2=\\
& 4\pi r^4\int_0^{\frac{\pi}{2}}\bigg(\frac{16}{3}\cos^2a+2\pi\cos^3 a\bigg) da = \frac{32}{3}\pi^2 r^4.
\end{aligned}$$
Now \eqref{V_1 exact} follows from \eqref{V_1 by rho}. We omit the proof of \eqref{R exact} since we have already established the expressions of $\rho_i$ in terms of parameters $a, \,w_1, \, w_2$.  

The proofs for \eqref{Q_s exact} and \eqref{Q_d exact} are similar. Let's prove the first. To model the case $g_1\cap g_2 \not\in D$, we simply need to adjust the position of parameters  $w_1$ and $w_2$. They must now satisfy either $-a < w_1 < w_2 < \pi +a,$ or $\pi+a < w_1 < w_2 <  2\pi - a.$

If $-a < w_1 < w_2 < \pi +a$ then
$$s_1+s_2=2r\bigg(\sin\frac{w_1+a}{2}+\cos\frac{w_2-a}{2}\bigg), \,\,\, d_1+d_2=2r\bigg(\cos\frac{w_1-a}{2}+\sin\frac{w_2+a}{2}\bigg).$$

If $\pi+a < w_1 < w_2 <  2\pi - a$ then
$$s_1+s_2=2r\bigg(\sin\frac{w_2+a}{2}-\cos\frac{w_1-a}{2}\bigg), \,\,\, d_1+d_2=2r\bigg(\sin\frac{w_1+a}{2}-\cos\frac{w_2-a}{2}\bigg).$$
As a result, 
$$\begin{aligned}
&Q_s=4\pi r^4 \int_0^{\frac{\pi}{2}}\cos a da \int_{-a}^{\pi+a}dw_1\int_{w_1}^{\pi+a} \bigg(\sin\frac{w_1+a}{2}+\cos\frac{w_2-a}{2}\bigg) \times\\
& \times \bigg(\cos\frac{w_1-a}{2}+\sin\frac{w_2+a}{2}-\sin\frac{w_1+a}{2}-\cos\frac{w_2-a}{2}\bigg) \sin\frac{w_2-w_1}{2}dw_2+\\
& + 4\pi r^4 \int_0^{\frac{\pi}{2}}\cos a da \int_{\pi+a}^{2\pi-a}dw_1\int_{w_1}^{2\pi-a} \bigg(\sin\frac{w_2+a}{2}-\cos\frac{w_1-a}{2}\bigg) \times\\
& \times \bigg(\sin\frac{w_1+a}{2}-\cos\frac{w_2-a}{2}-\sin\frac{w_2+a}{2}+\cos\frac{w_1-a}{2}\bigg) \sin\frac{w_2-w_1}{2}dw_2=\\
& =(\frac{2}{3}\pi^4-2\pi^2)r^4. 
\end{aligned}$$
\end{proof}

The following results directly follow from the last two lemmas and the theorems proved in Sections 3 and 4. 
\begin{theorem}\label{Probabilities for a disc}
If $D$ is a disc with radius $r$ then
$$p_{46}=\frac{1}{4}-\frac{17}{8\pi^2},\,\,\,\,p_{45}=\frac{29}{8\pi^2} -\frac{1}{4},$$
$$p_{44}=\frac{43}{4\pi^2} -\frac{7}{8}, \,\,p_{44}^{(1)}=\frac{23}{2\pi^2} -1,\,\, p_{44}^{(2)}=\frac{1}{8}-\frac{3}{4\pi^2},$$
$$p_{43}=1-\frac{29}{4\pi^2},\,\,p_{43}^{(1)}=\frac{23}{4\pi^2} -\frac{1}{2},\,\, p_{43}^{(2)}=1-\frac{35}{4\pi^2}, \,\, p_{43}^{(3)}=\frac{1}{2}-\frac{17}{4\pi^2},$$
$$p_{42}=\frac{7}{4}-\frac{121}{8\pi^2}, \,\, p_{42}^{(1)}=\frac{3}{2} -\frac{13}{\pi^2},\,\, p_{42}^{(2)}=\frac{1}{4}-\frac{17}{8\pi^2},$$
$$p_{41}=\frac{29}{8\pi^2}-\frac{1}{4},\,\,\,\,p_{40}=\frac{13}{2\pi^2} -\frac{5}{8}.$$
\end{theorem}





\chapter{THE EUCLIDEAN DISTANCE BETWEEN TWO GAUSSIAN POINTS AND THE NORMAL COVARIOGRAM OF $\mathbb{R}^d$}

\section{Preliminaries}\label{Preliminaries 3}
Consider two fundamental characteristics of a bounded convex body $\mathbb{D}\subset \mathbb{R}^d$. Let the first be the covariogram of $\mathbb{D}$ which has a geometric nature: for any vector $\boldsymbol{t}\in \mathbb{R}^d$, it represents the $d$-dimensional Lebesgue measure of the region shared between $\mathbb{D}$ and its translated copy by vector $\boldsymbol{t}$. We denote the covariogram of $\mathbb{D}$ by $C_{\mathbb{D}}(\boldsymbol{t})$. 

Let the second characteristic be the Euclidean distance between two random points chosen independently and uniformly from $\mathbb{D}\subset \mathbb{R}^d$. We denote it by  $D_d(\mathbb{D})$. 

The two considered characteristics of $\mathbb{D}$ are interrelated as follows (see \cite{OhanyanKhalatyan}):
 \begin{equation}\label{Ohanyan, Khalatyan intro}
f_{D_d(\mathbb{D})}(h)=\frac{h^{d-1}}{L_{d}^{2}(\mathbb{D})} \int_{\mathbb{S}^{d-1}} C_{\mathbb{D}}(h\boldsymbol{u}) d \boldsymbol{u}, \,\, h>0,
 \end{equation}
where $\mathbb{S}^{d-1}$ is the $(d-1)$-dimensional unit sphere in $\mathbb{R}^d$, centered at the origin, and $L_d(\mathbb{D})$ is Lebesgue $d$-measure of $\mathbb{D}$. 

If $\mathbb{D}$ is a convex body and $\mathcal{P}_1$, $\mathcal{P}_2$ are chosen uniformly and independently from $\mathbb{D}$, then (see \cite{OhanyanKhalatyan})
 $$f_{\mathcal{P}_1-\mathcal{P}_2}(\boldsymbol{t})= \frac{C_{\mathbb
     {D}}(\boldsymbol{t})}{L_d^2(\mathbb{D})},$$    
and therefore, one can imagine the covariogram as a positive function defined on the entire space that satisfies 
 \begin{equation}\label{Equivalent to Difference and covariogram}
     f_{\mathcal{P}_1-\mathcal{P}_2}(\boldsymbol{t})= \frac{C_{\mathbb
     {D}}(\boldsymbol{t})}{C_{\mathbb
     {D}}^2(\boldsymbol{0})}.
 \end{equation}
 
In the upcoming text, a $d$-dimensional vector $\textbf{v}\in \mathbb{R}^d$ will be assumed to be a column vector, or, equivalently, a $d\times 1$ matrix. The transpose of matrix $\textbf{A}$ will be denoted by $\textbf{A}^T$. $\textbf{0}$ will stand for the vector with all zero coordinates, $\boldsymbol{1}$ for the vector whose all coordinates are equal to 1. $\textbf{I}_d$ will represent the identity $d\times d$ matrix, $\|\cdot\|$ the Euclidean norm in $\mathbb{R}^d$, and $|\textbf{A}|$ the determinant of matrix $\textbf{A}$. 

If $\textbf{X}$ is a $d$-variate non-singular normal random vector with mean $\boldsymbol{\mu}$ and covariance matrix $\boldsymbol{\Sigma}$ then we will denote this condition by $\boldsymbol{X}\sim N_d (\boldsymbol{\mu}, \boldsymbol{\Sigma}).$  
We denote $\boldsymbol{\lambda}=[\lambda_1, \lambda_2, ..., \lambda_d]^T$, where $\lambda_1\geq \lambda_2 \geq ...\geq \lambda_d >0$ are the eigenvalues of $\boldsymbol{\Sigma}$. 

From now onwards, we assume $\boldsymbol{\mu}=\boldsymbol{0}$ and the diagonal of $\boldsymbol{\Sigma}$ consisting of 1s. If $\boldsymbol{X_1, X_2}\sim N_d (\boldsymbol{0}, \boldsymbol{\Sigma})$ are independent, we denote $$D_d=\|\boldsymbol{X_1}-\boldsymbol{X_2}\|.$$ 

 
\section{The density of $D_d$} \label{D_d density}

Let $\boldsymbol{U}=\boldsymbol{X_1}-\boldsymbol{X_2}$. Since $\boldsymbol{U}\sim N_d (\boldsymbol{0}, 2\boldsymbol{\Sigma})$ and $D_d^2=\boldsymbol{U}^T\boldsymbol{U}$, then the distribution function of $D_d^2$ can be written in the following form (see \cite{MathaiProvost}, page 95):  
\begin{theorem} \label{MathaiProvost}
\begin{equation}{\label{CDFDd2}}
    \mathbb{P}(D_d^2\leq y) \stackrel{\text{def}}{=} F_{D_d^2}(\boldsymbol{\Sigma},\, y)=\sum_{k=0}^{\infty}(-1)^k c_k\frac{y^{\frac{d}{2}+k}}{\Gamma\left(\frac{d}{2}+k+1\right)},\,\, y>0,
\end{equation}
where 
\begin{equation}\label{c_k}
    c_0=\frac{1}{2^d \sqrt{|\boldsymbol{\Sigma}|}},\,\,
c_{k}=\frac{1}{k} \sum_{r=0}^{k-1} \delta_{k-r} c_{r}, \,\, k\geq 1,
\end{equation}
\begin{equation}\label{delta_k}
    \delta_k=\frac{1}{2^{2k+1}}\sum_{i=1}^{d}\frac{1}{\lambda_i^k},
\end{equation}
and $\Gamma$ is the Euler's Gamma function
$$
\Gamma(x)=\int_{0}^{\infty} t^{x-1} e^{-t} d t, \quad x>0.
$$
\end{theorem}

When the coordinates of the Gaussian points are uncorrelated univariate standard normal variables, then $\boldsymbol{\Sigma}=\boldsymbol{I}_d$ is the identity $d\times d$ matrix and, consequently, $\boldsymbol{\lambda}=\boldsymbol{1}$. In this case, we obtain from Theorem \ref{MathaiProvost} that $D_d$ follows $GG(a,d,p)$, a generalized Gamma distribution introduced in \cite{Stacy}, which has the probability density function
$$
f(x ; a, d, p)=\frac{\left(p / a^{d}\right) x^{d-1} e^{-(x / a)^{p}}}{\Gamma(d / p)},\,\,x>0,
$$
where 
$d>0$ and $p>0$ are the shape parameters, and $a$ is a scale parameter. To prove this result (formulated as Theorem \ref{Theorem 2.2}) we first need the following lemma.
\begin{lemma}\label{Lemma by Induction}
    For any constants $\mu$ and $\nu_0$, if
    \begin{equation}\label{weighted average}
        \nu_k=\frac{\nu_0+\nu_1+...+\nu_{k-1}}{k} \mu,\,\,\,  k\geq 1,
    \end{equation} 
    then
    $$\nu_k=\frac{\nu_0}{k!}\cdot{\prod_{j=0}^{k-1}\big(\mu+j\big)}, \, k\geq 1.$$
\end{lemma}
\begin{proof}
    We prove this lemma by mathematical induction. The case $k=1$ is easy to verify. Let now for some natural $n$, the identity
    \begin{equation}\label{inductive hyp}
        \nu_n=\frac{\nu_0}{n!}\cdot{\prod_{j=0}^{n-1}\big(\mu+j\big)}
    \end{equation}
    holds. Since
    $$\nu_{n+1}=\frac{\nu_0+\nu_1+...+\nu_{n}}{n+1} \mu=\mu \bigg(\frac{\nu_0+\nu_1+...+\nu_{n-1}}{n}\frac{n}{n+1}+\frac{\nu_n}{n+1}\bigg)=$$
    $$=\mu\bigg(\frac{\nu_n}{\mu}\frac{n}{n+1}+\frac{\nu_n}{n+1}\bigg)=\frac{n+\mu}{n+1}\nu_n,$$
    the hypothesis \ref{inductive hyp} yields
    $$\nu_{n+1}=\frac{\nu_0}{(n+1)!}\cdot{\prod_{j=0}^{n}\big(\mu+j\big)}.$$
\end{proof}
\vskip 10pt
Let $f_{D_d}(\boldsymbol{\Sigma}, \cdot)$ be the probability density function of $D_d$.
\begin{theorem} \label{Theorem 2.2}
    \begin{equation}{\label{PDFDd}}
    f_{D_d}(\boldsymbol{I}_d,\, R)=
\frac{R^{d-1}e^{-\frac{R^{2}}{4}}}{2^{d-1}\Gamma\left(\frac{d}{2}\right)}, \,\, R>0,
\end{equation} 
that is, if $\boldsymbol{\Sigma}=\boldsymbol{I}_d$ then $D_d\sim GG(2,d,2)$. 
\end{theorem}
 \begin{proof} Since $\boldsymbol{\lambda}=\boldsymbol{1}$, \eqref{delta_k} and \eqref{c_k} imply $c_0=2^{-d}$ and $$c_{k}=\frac{d}{k2^{2k+1}} \sum_{r=0}^{k-1} 4^rc_r, \,\, k\geq 1.$$
 After rewriting the last equation in this form,
 $$4^kc_{k}=\frac{d}{2}\frac{1}{k} \sum_{r=0}^{k-1} 4^rc_r, \,\, k\geq 1,$$
we notice that it is equivalent to \ref{weighted average}, where $\mu=\frac{d}{2}$ and $\nu_k=4^{k}c_k$, for $k\geq 0$. 
 From Lemma \ref{Lemma by Induction}, we immediately come up with
 $$c_k=\frac{1}{2^dk!4^k}{\prod_{j=0}^{k-1}\bigg(\frac{d}{2}+j\bigg)}, \, k\geq 1,$$
which, due to the identity $x\Gamma(x)=\Gamma(x+1), \, x>0$, can be rewritten as
 \begin{equation}\label{c_k_Gamma}
    c_k=\frac{\Gamma (\frac{d}{2}+k)}{2^dk!4^k\Gamma(\frac{d}{2})}, \, k\geq 1. 
 \end{equation}
By substituting \eqref{c_k_Gamma} in \eqref{CDFDd2} and using $f_{D_d}(\boldsymbol{I}_d,\, R)=2R\frac{\partial}{\partial R}F_{D_d^2}(\boldsymbol{I}_d,\, R^2)$, we obtain



$$
    f_{D_d}(\boldsymbol{I}_d,\, R)=2R\sum_{k=0}^{\infty}(-1)^k \frac{\Gamma (\frac{d}{2}+k)(R^2)^{\frac{d}{2}+k-1}(\frac{d}{2}+k)}{2^dk!4^k\Gamma(\frac{d}{2})\Gamma(\frac{d}{2}+k+1)}=
$$
 $$
=2R\cdot\frac{R^{d-2}}{2^d\Gamma(\frac{d}{2})}\sum_{k=0}^{\infty}\frac{1}{k!}\bigg(-\frac{R^2}{4}\bigg)^k=\frac{R^{d-1}e^{-\frac{R^{2}}{4}}}{2^{d-1}\Gamma\left(\frac{d}{2}\right)}.
 $$
 \end{proof} 

The moments of the generalized Gamma distribution are well known. If $X\sim GG(a,d,p)$, then (see \cite{JohnsonKotzBalakrishnan}, section 17.8.7)
 $$
\mathbb{E}\left(X^{r}\right)=a^{r} \frac{\Gamma\left(\frac{d+r}{p}\right)}{\Gamma\left(\frac{d}{p}\right)}, \, r=0, 1, 2, ...\,\,.
$$
As a result, from Theorem \ref{Theorem 2.2} we immediately obtain the corresponding formula for the moments of $D_d$. 
\begin{corollary}
    If $\boldsymbol{\Sigma}=\boldsymbol{I}_d$, then 
 \begin{equation}\label{moments}
     \mathbb{E}\left(D_d^{r}\right)=2^{r} \frac{\Gamma\left(\frac{d+r}{2}\right)}{\Gamma\left(\frac{d}{2}\right)},\, r=0, 1, 2, ...\,\,.
\end{equation}
\end{corollary}
 
In general, when $\boldsymbol{\Sigma}\neq \boldsymbol{I}_d$, even when $d=2$, it is hard to compute the coefficients $c_k$ from the recursive formulas \eqref{c_k} and evaluate the infinite sum \eqref{CDFDd2}.     

\vskip 20pt
\section{An integral representation of the distribution function of $D_d$} \label{Integral repr of D_d}
 
\begin{theorem}\label{Ellipse}
Let $F_{D_d}(\boldsymbol{\Sigma}, \cdot)$ be the distribution function of $D_d$ and $\mathcal{E}_d(\boldsymbol{\lambda}, R)$ be the ellipsoid
$$\{\boldsymbol{y}=[y_1, y_2, ..., y_d]^T: \,\lambda_1 y_1^2+\lambda_2 y_2^2+...+\lambda_d y_d^2\leq R^2\}.$$
Then
    \begin{equation}\label{Ellipse]}
    F_{D_d}(\boldsymbol{\Sigma}, R)=\frac{1}{(2\sqrt{\pi})^d}\int_{\mathcal{E}_d(\boldsymbol{\lambda}, R)}\exp\bigg({-\frac{1}{4}\boldsymbol{y}^T\boldsymbol{y}}\bigg)d\boldsymbol{y}, \,\,R>0.
\end{equation}
\end{theorem}
\noindent \textit{Proof.}
    Consider the probability density function of $\boldsymbol{U}=\boldsymbol{X_1}-\boldsymbol{X_2}$:
    \begin{equation}\label{fUu}
        f_{\boldsymbol{U}}(\boldsymbol{u})=\frac{1}{(2\sqrt{\pi})^d |\boldsymbol{\Sigma}|^{1/2}}\exp\bigg(-\frac{1}{4}\boldsymbol{u}^T\boldsymbol{\Sigma}^{-1}\boldsymbol{u}\bigg), \,\boldsymbol{u}\in \mathbb{R}^d.
    \end{equation}
    We denote
$$
  \textbf{diag}(\boldsymbol{\lambda}) =
  \begin{bmatrix}
    \lambda_{1} & & \\
    & \ddots & \\
    & & \lambda_{d}
  \end{bmatrix},\,\,\,\textbf{diag}(\boldsymbol{\lambda}^{-1}) =
  \begin{bmatrix}
    \lambda_{1}^{-1} & & \\
    & \ddots & \\
    & & \lambda_{d}^{-1}
  \end{bmatrix}.
$$
Due to orthogonal diagonalization theorem for symmetric matrices, there exists an orthogonal matrix $\boldsymbol{Q}=[q_{ij}]_{d\times d}$ such that $\boldsymbol{\Sigma}=\boldsymbol{Q}\,\textbf{diag}(\boldsymbol{\lambda})\boldsymbol{Q}^T$, and therefore, $\boldsymbol{\Sigma}^{-1}=\boldsymbol{Q}\,\textbf{diag}(\boldsymbol{\lambda}^{-1})\boldsymbol{Q}^T$. Denoting the $i$-th column of $\boldsymbol{Q}$ by $\boldsymbol{q}_i$, we obtain
$$\boldsymbol{u}^T\boldsymbol{\Sigma}^{-1}\boldsymbol{u}=[\boldsymbol{u}^T\boldsymbol{q}_1, \, \boldsymbol{u}^T\boldsymbol{q}_2, \, ... ,\,\boldsymbol{u}^T\boldsymbol{q}_d \,]\,\textbf{diag}(\boldsymbol{\lambda}^{-1})\, \begin{bmatrix} \boldsymbol{q}_1^T\boldsymbol{u} \\ \boldsymbol{q}_2^T\boldsymbol{u} \\ \vdots \\ \boldsymbol{q}_d^T\boldsymbol{u} \end{bmatrix}=\sum_{i=1}^d \frac{(\boldsymbol{q}_i^T \boldsymbol{u})^2}{\lambda_i}, $$
and therefore,
\begin{equation}\label{f_U(u)}
    f_{\boldsymbol{U}}(\boldsymbol{u})=\frac{1}{(2\sqrt{\pi})^d |\boldsymbol{\Sigma}|^{1/2}}\exp\bigg(-\frac{1}{4}\sum_{i=1}^d \frac{(\boldsymbol{q}_i^T \boldsymbol{u})^2}{\lambda_i}\bigg), \,\boldsymbol{u}\in \mathbb{R}^d.
\end{equation}
Let $x_1,\,x_2, \, ...,\,x_d >0$, $\boldsymbol{U}=[U_1,\,U_2, \, ...,\,U_d]^T$, ${\boldsymbol{U}}^*=[|U_1|,\,|U_2|, \, ...,\,|U_d|]^T$ and $\boldsymbol{u}=[u_1,\,u_2, \, ...,\,u_d]^T$. Then, due to \eqref{f_U(u)},
$$\mathbb{P}(|U_1|\leq x_1, |U_2|\leq x_2, ..., |U_d|\leq x_d))\stackrel{\text{def}}{=}F_{\boldsymbol{U}^*}(x_1, x_2, ..., x_d)=$$
$$=\frac{1}{(2\sqrt{\pi})^d |\boldsymbol{\Sigma}|^{1/2}}\int_{-x_1}^{x_1}du_1\int_{-x_2}^{x_2}du_2 ... \int_{-x_d}^{x_d}\exp\bigg(-\frac{1}{4}\sum_{i=1}^d \frac{(\boldsymbol{q}_i^T \boldsymbol{u})^2}{\lambda_i}\bigg)du_d.$$
The joint probability density function of the random variables $|U_1|,\, |U_2|, \,..., \,|U_d|$ can be reached by partial differentiation of the last iterated integral, i.e.
$$f_{\boldsymbol{U}^*}(x_1, x_2, ..., x_d)=\frac{\partial^d}{\partial x_d \partial x_{d-1}\,...\, \partial x_1}F_{\boldsymbol{U}^*}(x_1, x_2, ..., x_d).$$
Applying the Leibnitz's rule of differentiation $d$ times, we conclude
\begin{equation}\label{fU*}
    f_{\boldsymbol{U}^*}(x_1, x_2, ..., x_d)=\frac{1}{(2\sqrt{\pi})^d |\boldsymbol{\Sigma}|^{1/2}}\sum_{\boldsymbol{w}\in \Omega(x_1, x_2, ..., x_d)}\exp\bigg(-\frac{1}{4}\sum_{i=1}^d \frac{(\boldsymbol{q}_i^T \boldsymbol{w})^2}{\lambda_i}\bigg),
\end{equation}
where $\Omega(x_1, x_2, ..., x_d)=\{\boldsymbol{w}=[w_1, w_2, ..., w_d]^T\,:\, |w_i|=x_i, \,i=1, 2, ..., d\}.$ For any given $(x_1, x_2, ..., x_d)$, the cardinality of $\Omega (x_1, x_2, ..., x_d)$ is equal to $2^d$.

We now aim to replace the summing index in \eqref{fU*} and run it over all the binary strings of length $d$. For any $\boldsymbol{s}=(s_1, s_2, ..., s_d)\in \{0,\,1\}^d$ consider the unique vector $\boldsymbol{w_s}=[w_1^{(\boldsymbol{s})}, w_2^{(\boldsymbol{s})}, ..., w_d^{(\boldsymbol{s})}]^T \in \Omega (x_1, x_2, ..., x_d)$ such that    
$$ w_i^{(\boldsymbol{s})} = \begin{cases}
  x_i & \mbox{ if $ s_i=0 $}\\
  -x_i & \mbox{ if $ s_i=1 $}
  \end{cases}.
  $$

Formula \eqref{fU*} can be equivalently written in the following form:
\begin{equation}\label{fU*_2}
    f_{\boldsymbol{U}^*}(x_1, x_2, ..., x_d)=\frac{1}{(2\sqrt{\pi})^d |\boldsymbol{\Sigma}|^{1/2}}\sum_{\boldsymbol{s}\in \{0,\, 1\}^d }\exp\bigg(-\frac{1}{4}\sum_{i=1}^d \frac{(\boldsymbol{q}_i^T \boldsymbol{w_s})^2}{\lambda_i}\bigg).
\end{equation}

Since 
$$F_{D_d}(\boldsymbol{\Sigma}, R)=\mathbb{P}(\sqrt{U_1^2+U_2^2+...+U_d^2}\leq R)=$$
$$=\mathbb{P}(\|U^*\|\leq R)=\int_{\sqrt{x_1^2+x_2^2...+x_d^2}\leq R,\,\, x_i>0}f_{\boldsymbol{U}^*}(x_1, x_2, ..., x_d)dx_1dx_2 ... dx_d,$$
the formula \eqref{fU*_2} implies
\begin{equation}\label{FDd over B0}
    F_{D_d}(\boldsymbol{\Sigma}, R)=\frac{1}{(2\sqrt{\pi})^d |\boldsymbol{\Sigma}|^{1/2}}\int_{B_d^{\boldsymbol{0}}(R)} \sum_{\boldsymbol{s}\in \{0,\, 1\}^d }\exp\bigg(-\frac{1}{4}\sum_{i=1}^d \frac{(\boldsymbol{q}_i^T \boldsymbol{w_s})^2}{\lambda_i}\bigg)d\boldsymbol{x},
\end{equation}
where $B_d^{\boldsymbol{0}}(R)=\{(x_1, x_2, ..., x_d)\,:\, x_1^2+x_2^2+ ... +x_d^2\leq R^2, \, x_i>0, \, i=1, 2, ..., d\}$ is an $2^d$-quadrant of the $d$-dimensional ball $B_d(R)$ of radius $R$ centered at the origin, and $d\boldsymbol{x}=dx_1dx_2 ... dx_d$. Hereinafter, for any $\boldsymbol{s}=(s_1, s_2, ..., s_d)\in \{0, \,1\}^d$, the symbol $B_d^{\boldsymbol{s}}(R)$ will stand for the $2^d$-quadrant of $B_d(R)$ consisting of the points $(x_1, x_2, ..., x_d)$ such that $x_i>0$, if $s_i=0$ and $x_i<0$, if $s_i=1$. 

By interchanging the sum with the integral in \eqref{FDd over B0} and denoting 
$$g_{\boldsymbol{s}}(x_1, x_2, ..., x_n)=\exp\bigg(-\frac{1}{4}\sum_{i=1}^d \frac{(\boldsymbol{q}_i^T \boldsymbol{w_s})^2}{\lambda_i}\bigg),$$
we receive
\begin{equation}\label{FDd with g_s}
    F_{D_d}(\boldsymbol{\Sigma}, R)=\frac{1}{(2\sqrt{\pi})^d |\boldsymbol{\Sigma}|^{1/2}} \sum_{\boldsymbol{s}\in \{0,\, 1\}^d }\int_{B_d^{\boldsymbol{0}}(R)}g_{\boldsymbol{s}}(x_1, x_2, ..., x_d)dx_1dx_2...dx_d.
\end{equation}
Let us perform the following change of variable in the integral of $g_{\boldsymbol{s}}$ over $B_d^{\boldsymbol{0}}(R)$: 
$$t_i=x_i, \,\text{if}\, s_i=0,$$
$$t_i=-x_i, \,\text{if}\, s_i=1.$$
The Jacobian $$\frac{D(x_1, x_2, ..., x_d)}{D(t_1, t_2, ..., t_d)}=\det \begin{bmatrix}
    (-1)^{s_1} & & \\
    & \ddots & \\
    & & (-1)^{s_d}
  \end{bmatrix}=(-1)^{\sum_{i=1}^d s_i}$$ is equal to $1$ or $-1$, therefore after this change of variable we obtain

\begin{equation}\label{variable change g_s}
    \int_{B_d^{\boldsymbol{0}}(R)}g_{\boldsymbol{s}}(x_1, x_2, ..., x_d)dx_1dx_2...dx_d=\int_{B_d^{\boldsymbol{s}}(R)}g_{\boldsymbol{0}}(x_1, x_2, ..., x_d)dx_1dx_2...dx_d.
\end{equation}
Since the sets $B_d^{\boldsymbol{s}}(R), \, \boldsymbol{s}\in \{0,\,1\}^d$ are pairwise disjoint and the union of their closures is exactly equal to $B_d(R)$, from \eqref{FDd with g_s} and \eqref{variable change g_s} we establish
\begin{equation}\label{FDd over ball}
    F_{D_d}(\boldsymbol{\Sigma}, R)=\frac{1}{(2\sqrt{\pi})^d |\boldsymbol{\Sigma}|^{1/2}} \int_{B_d(R)}g_{\boldsymbol{0}}(x_1, x_2, ..., x_d)dx_1dx_2...dx_d.
\end{equation}
We have $\boldsymbol{w_0}=\boldsymbol{x}=[x_1, x_2, ..., x_d]^T$, which means that
\begin{equation}\label{g_0 simple}
    g_{\boldsymbol{0}}(x_1, x_2, ..., x_d)=\exp\bigg(-\frac{1}{4}\sum_{i=1}^d \frac{(\boldsymbol{q}_i^T \boldsymbol{x})^2}{\lambda_i}\bigg).
\end{equation}
To finish the proof, we make one more change of variable in the integral of $g_{\boldsymbol{0}}$ over the ball $B_d(R)$.  Consider a new variable $\boldsymbol{y}=[y_1, y_2, ..., y_d]$, where
\begin{equation} \label{the last variable change}
    y_i=\frac{\boldsymbol{q}_i^T \boldsymbol{x}}{\sqrt{\lambda_i}}, \,\,i=1, 2, ..., d.
\end{equation}
It is easy to check that 
$$\boldsymbol{y}=\frac{1}{\sqrt{\lambda_1}\sqrt{\lambda_2} ... \sqrt{\lambda_d}}\boldsymbol{Q}^T\boldsymbol{x},$$
and then, using orthogonality of $\boldsymbol{Q}$, we can express $\boldsymbol{x}$ in terms of $\boldsymbol{y}$:
$$\boldsymbol{x}=\sqrt{\lambda_1}\sqrt{\lambda_2} ... \sqrt{\lambda_d} \boldsymbol{Q}\boldsymbol{y}.$$
The Jacobean becomes equal to
\begin{equation}\label{Jacobian}
    \frac{D(x_1, x_2, ..., x_d)}{D(y_1, y_2, ..., y_d)}=\sqrt{\lambda_1}\sqrt{\lambda_2} ... \sqrt{\lambda_d}\,| \boldsymbol{Q}|=|\boldsymbol{\Sigma}|^{1/2}.
\end{equation}
Let us now compute $\sum_{i=1}^{d}x_i^2$ to see that the domain of integration, namely $B_d(R)$, turns to the ellipsoid $\mathcal{E}_d(\boldsymbol{\lambda}, R)$. Indeed, 
$$
\sum_{i=1}^{d}x_i^2=\sum_{i=1}^{d}(\sqrt{\lambda_1}q_{i1}y_1+\sqrt{\lambda_2}q_{i2}y_2+ ... + \sqrt{\lambda_d}q_{id}y_d)^2= $$
$$=\lambda_1y_1^2\sum_{i=1}^{d}q_{i1}^2+\lambda_2y_2^2\sum_{i=1}^{d}q_{i2}^2+...+\lambda_dy_d^2\sum_{i=1}^{d}q_{id}^2+2\sum_{i=1}^{d}\sum_{1 \leq m < n\leq d}\sqrt{\lambda_m}\sqrt{\lambda_n}q_{im}q_{in}y_my_n=$$
$$=\lambda_1y_1^2+\lambda_2y_2^2+...+\lambda_dy_d^2 +2\cdot \sum_{1 \leq m < n\leq d}\sqrt{\lambda_m}\sqrt{\lambda_n}y_my_n\sum_{i=1}^{d} q_{im}q_{in}=$$
$$= \sum_{i=1}^{d}\lambda_iy_i^2+2\cdot \sum_{1 \leq m < n\leq d}\sqrt{\lambda_m}\sqrt{\lambda_n}y_my_n \boldsymbol{q_m}^T\boldsymbol{q_n},$$
and since $\boldsymbol{q_m}^T\boldsymbol{q_n}=0$, we conclude

\begin{equation}\label{make an ellipse from ball}
    \sum_{i=1}^{d}x_i^2=\sum_{i=1}^{d}\lambda_iy_i^2. 
\end{equation}

Now \eqref{Ellipse]} follows from \eqref{FDd over ball}-\eqref{make an ellipse from ball}.

\begin{corollary}\label{Corollary}
    The probability density function of $D_d$ is representable as follows:
 \begin{equation}\label{PDF of D_d over sphere}
    f_{D_d}(\boldsymbol{\Sigma}, R)=\frac{R^{d-1}}{(2\sqrt{\pi})^d |\boldsymbol{\Sigma}|^{1/2}} \int_{\mathbb{S}^{d-1}}\exp\bigg(-\frac{R^2}{4}\boldsymbol{u}^T\boldsymbol{\Sigma}^{-1}\boldsymbol{u}\bigg)d\boldsymbol{u}.
 \end{equation}
\end{corollary}
    
\begin{proof}
As we saw in the last part of the proof of Theorem \ref{Ellipse}, the formula \eqref{Ellipse]} is equivalent to
\begin{equation}\label{CDF of D_d over ball}
     F_{D_d}(\boldsymbol{\Sigma}, R)=\frac{1}{(2\sqrt{\pi})^d |\boldsymbol{\Sigma}|^{1/2}} \int_{B_d(R)}\exp\bigg(-\frac{1}{4}\boldsymbol{x}^T\boldsymbol{\Sigma}^{-1}\boldsymbol{x}\bigg)d\boldsymbol{x}.
 \end{equation}
     The change of variable $\boldsymbol{x}=r\boldsymbol{u}$, $\boldsymbol{u}\in \mathbb{S}^{d-1}$, $d\boldsymbol{x}=r^{d-1}drd\boldsymbol{u}$ in \eqref{CDF of D_d over ball} produces
$$F_{D_d}(\boldsymbol{\Sigma}, R)=\frac{1}{(2\sqrt{\pi})^d |\boldsymbol{\Sigma}|^{1/2}}\int_{\mathbb{S}^{d-1}}d\boldsymbol{u} \int_0^R\exp\bigg(-\frac{r^2}{4}\boldsymbol{u}^T\boldsymbol{\Sigma}^{-1}\boldsymbol{u}\bigg)r^{d-1}dr.$$
By taking the derivatives of both sides in the last equation, we establish \eqref{PDF of D_d over sphere}.
\end{proof}

\section{Applications}\label{applications}

As an application of the obtained integral representations in the previous section, we determine the probability density function of the Euclidean distance between two bivariate Gaussian points in the case when there is an inter-coordinate correlation $\rho$. 
\begin{theorem}\label{Case d=2}
    If $\boldsymbol{\Sigma}=
\begin{bmatrix} 
1 & \rho \\
\rho & 1 
\end{bmatrix},
$
then $$f_{D_2}(\boldsymbol{\Sigma}, R)=\frac{Re^{-\frac{R^2}{4|\boldsymbol{\Sigma}|}}}{2\sqrt{\bold{|\Sigma}|}}I_0 \bigg(\ \frac{\rho R^2}{4|\boldsymbol{\Sigma}|} \bigg),$$
where $$
I_{0}(x)=1+\sum_{k=1}^{\infty} \frac{x^{2 k}}{((2 k) ! !)^{2}}
$$ is the modified  Bessel function of the first kind of order zero. 
\end{theorem}
\begin{proof}
It is easy to see that $\lambda_1=1+\rho, \,\lambda_2=1-\rho$. By \eqref{PDF of D_d over sphere}, we have
$$f_{D_2}(\boldsymbol{\Sigma}, R)=\frac{R}{4\pi\sqrt{1-\rho^2}}\int_0^{2\pi} \exp \bigg(-\frac{R^2\cos^2\varphi}{4+4\rho}-\frac{R^2\sin^2\varphi}{4-4\rho}\bigg)d\varphi=$$
$$=\frac{Re^{-\frac{R^2}{4(1-\rho^2)}}}{2\pi \sqrt{1-\rho^2}}\int_0^{\pi}e^{a\cos2\varphi}d\varphi,$$
where $$a=\frac{\rho R^2}{4(1-\rho^2)}.$$
Since $|\boldsymbol{\Sigma}|=1-\rho^2$, to complete the proof it remains to show that
$$\frac{1}{\pi}\int_0^{\pi}e^{a\cos2\varphi}d\varphi=I_0(a).$$
Indeed, Taylor's expansion for $e^x$ solves this problem:
$$\frac{1}{\pi}\int_0^{\pi}e^{a\cos2\varphi}d\varphi=\frac{1}{\pi}\sum_{k=0}^{\infty}\frac{a^k}{k!}\int_0^{\pi}\cos^k 2\varphi d\varphi=\frac{1}{2\pi}\sum_{k=0}^{\infty}\frac{a^k}{k!}\int_0^{2\pi}\cos^k \psi d\psi=$$
$$=\frac{2}{\pi}\sum_{k=0}^{\infty}\frac{a^{2k}}{(2k)!}\int_0^{\pi/2}\cos^{2k} \psi d\psi=1+\frac{2}{\pi}\sum_{k=1}^{\infty}\frac{a^{2k}}{(2k)!}\frac{(2k-1)!!}{(2k)!!}\frac{\pi}{2}=1+\sum_{k=1}^{\infty} \frac{a^{2 k}}{((2 k) ! !)^{2}}=I_0(a).$$
\end{proof}

As another application, we establish lower and upper bounds for the moments of $D_d$ in terms of the largest and the smallest eigenvalues of the covariance matrix. 

\begin{theorem}\label{Moments bounds}
    Let $\mathbb{E}\left(D_d^{r}\right)$ be the $r$-th moment of $D_d$. Then
    \begin{equation}\label{Moments Inequalities}
        \frac{2^r\Gamma\big(\frac{d+r}{2}\big)}{\Gamma\big(\frac{d}{2}\big)}\frac{\lambda_d^{\frac{d+r}{2}}}{|\boldsymbol{\Sigma}|^{1/2}}\leq \mathbb{E}\left(D_d^{r}\right) \leq \frac{2^r\Gamma\big(\frac{d+r}{2}\big)}{\Gamma\big(\frac{d}{2}\big)}\frac{\lambda_1^{\frac{d+r}{2}}}{|\boldsymbol{\Sigma}|^{1/2}},\, r=0, 1, 2, ...\,\,.
    \end{equation}
\end{theorem}

\noindent \textit{Proof.}
As $\lambda_1\geq \lambda_2 \geq ...\geq \lambda_d >0$ and $$\boldsymbol{u}^T\boldsymbol{\Sigma}^{-1}\boldsymbol{u}=[\boldsymbol{u}^T\boldsymbol{q}_1, \, \boldsymbol{u}^T\boldsymbol{q}_2, \, ... ,\,\boldsymbol{u}^T\boldsymbol{q}_d \,]\,\textbf{diag}(\boldsymbol{\lambda}^{-1})\, \begin{bmatrix} \boldsymbol{q}_1^T\boldsymbol{u} \\ \boldsymbol{q}_2^T\boldsymbol{u} \\ \vdots \\ \boldsymbol{q}_d^T\boldsymbol{u} \end{bmatrix}=\sum_{i=1}^d \frac{(\boldsymbol{q}_i^T \boldsymbol{u})^2}{\lambda_i}, $$ then 
\begin{equation}\label{lambda inequality}
    \frac{1}{\lambda_1}\sum_{i=1}^d (\boldsymbol{q}_i^T \boldsymbol{u})^2\leq \boldsymbol{u}^T\boldsymbol{\Sigma}^{-1}\boldsymbol{u}\leq \frac{1}{\lambda_d}\sum_{i=1}^d (\boldsymbol{q}_i^T \boldsymbol{u})^2.
\end{equation}
As $\boldsymbol{Q}$ is orthogonal,
$$
\sum_{i=1}^d (\boldsymbol{q}_i^T \boldsymbol{u})^2=\sum_{i=1}^{d}(q_{1i}u_1+q_{2i}u_2+ ... + q_{di}u_d)^2= $$
$$=u_1^2\sum_{i=1}^{d}q_{1i}^2+u_2^2\sum_{i=1}^{d}q_{2i}^2+...+u_d^2\sum_{i=1}^{d}q_{di}^2+2\sum_{i=1}^{d}\sum_{1 \leq m < n\leq d}q_{mi}q_{ni}u_m u_n=\sum_{i=1}^{d}u_i^2,$$
we obtain
$$\sum_{i=1}^d (\boldsymbol{q}_i^T \boldsymbol{u})^2=\|\boldsymbol{u}\|^2=1, \,\, \text{if}\,\,\boldsymbol{u}\in \mathbb{S}^{d-1},$$
therefore, the integral representation \eqref{PDF of D_d over sphere} and inequalities \eqref{lambda inequality} yield  
$$\frac{e^{-\frac{R^2}{4\lambda_d}}R^{d-1}}{(2\sqrt{\pi})^d|\boldsymbol{\Sigma}|^{1/2}}\int_{\mathbb{S}^{d-1}}d\boldsymbol{u}\leq f_{D_d}(\boldsymbol{\Sigma}_d, R)\leq \frac{e^{-\frac{R^2}{4\lambda_1}}R^{d-1}}{(2\sqrt{\pi})^d|\boldsymbol{\Sigma}|^{1/2}}\int_{\mathbb{S}^{d-1}}d\boldsymbol{u}.$$
The surface area of $\mathbb{S}^{d-1}$ is well-known and equal to $\frac{2(\sqrt{\pi})^d}{\Gamma (\frac{d}{2})},$ so we obtain
\begin{equation}\label{bounds for pdf}
\frac{R^{d-1}e^{-\frac{R^2}{4\lambda_d}}}{2^{d-1}\Gamma(\frac{d}{2})|\boldsymbol{\Sigma}|^{1/2}}\leq f_{D_d}(\boldsymbol{\Sigma}_d, R)\leq \frac{R^{d-1}e^{-\frac{R^2}{4\lambda_1}}}{2^{d-1}\Gamma(\frac{d}{2})|\boldsymbol{\Sigma}|^{1/2}}.
\end{equation}
Multiplying all sides of \eqref{bounds for pdf} by $R^r$ and applying integral over $(0, \, +\infty)$ to all sides leads to   
$$\frac{\lambda_d^{\frac{d+r}{2}}}{|\boldsymbol{\Sigma}|^{1/2}}I(d)\leq \mathbb{E}\left(D_d^{r}\right) \leq \frac{\lambda_1^{\frac{d+r}{2}}}{|\boldsymbol{\Sigma}|^{1/2}}I(d),$$
where $$I(d)=\frac{1}{2^{d-1}\Gamma(\frac{d}{2})}\int_0^{+\infty}R^{d+r-1}e^{-\frac{R^2}{4}}dR.$$ 
To finalize the proof it only remains to ensure that
$$I(d)=2^{r} \frac{\Gamma\left(\frac{d+r}{2}\right)}{\Gamma\left(\frac{d}{2}\right)}.$$
Indeed, by \eqref{PDFDd},
$$I(d)=\int_0^{+\infty}R^r f_{D_d}(\boldsymbol{I}_d, R)dR,$$
which is, by \eqref{moments}, is equal to  
$$2^{r} \frac{\Gamma\left(\frac{d+r}{2}\right)}{\Gamma\left(\frac{d}{2}\right)}.$$

\section{The normal covariogram of $\mathbb{R}^d$}\label{NormCov}
As we already know, the covariogram of a convex body $\mathbb{D}\subset \mathbb{R}^d$ is known to be the function   
 $$C_{\mathbb{D}}(\boldsymbol{t}) = L_{d}(\mathbb{D} \cap \{\mathbb{D}+\boldsymbol{t}\}), \hspace{5pt} \boldsymbol{t} \in \mathbb{R}^d,$$ where $\mathbb{D}+\boldsymbol{t}=\{\mathcal{P}+\boldsymbol{t}\,:\, \mathcal{P}\in \mathbb{D}\}$ and $L_{d}(\cdot)$ is the $d$-dimensional Lebesgue measure in $\mathbb{R}^d$.
 
 If $\mathcal{P}_1$, $\mathcal{P}_2$ are chosen uniformly and independently from $\mathbb{D}$, then the probability density function of $\mathcal{P}_1-\mathcal{P}_2$ is representable as follows:
 \begin{equation}\label{pdf of P1-P2}
     f_{\mathcal{P}_1-\mathcal{P}_2}(\boldsymbol{t})=\int_{\mathbb{R}^d}f(\mathcal{P})f(\boldsymbol{t}+\mathcal{P})d\mathcal{P}=\frac{1}{L_d^2(\mathbb{D})}\int_{\mathbb{R}^d} I_{\mathbb{D}}(\mathcal{P})I_{\mathbb{D}}(\mathcal{P}+\boldsymbol{t})d\mathcal{P},   
 \end{equation}
 where $I_{\mathbb{D}}$ is the indicator function of $\mathbb{D}$.
 
 On the other hand,
 \begin{equation}\label{Covariogram on the other hand}
     C_{\mathbb{D}}(\boldsymbol{t}) = L_{d}(\mathbb{D} \cap \{\mathbb{D}+\boldsymbol{t}\})=\int_{\mathbb{R}^d}I_{\mathbb{D} \cap \{\mathbb{D}+\boldsymbol{t}\}}(\mathcal{P})d\mathcal{P}=\int_{\mathbb{R}^d} I_{\mathbb{D}}(\mathcal{P})I_{\mathbb{D}}(\mathcal{P}+\boldsymbol{t})d\mathcal{P}.
 \end{equation}
 Since $L_d^2(\mathbb{D})=C_{\mathbb{D}}(\boldsymbol{0})$, from \eqref{pdf of P1-P2} and \eqref{Covariogram on the other hand} we establish the identity \eqref{Equivalent to Difference and covariogram}, namely
 $$f_{\mathcal{P}_1-\mathcal{P}_2}(\boldsymbol{t})= \frac{C_{\mathbb
     {D}}(\boldsymbol{t})}{C_{\mathbb
     {D}}^2(\boldsymbol{0})}.$$
 
 
 
 
 
 
 
 This motivates us to extend the concept of the covariogram for $\mathbb{D}=\mathbb{R}^d$. 
\begin{definition}\label{Definition of normal covariogram}
    Let $\mathcal{P}_1, \,\mathcal{P}_2 \sim N_d (\boldsymbol{0},\, \boldsymbol{\Sigma})$ be independent and $f_{\mathcal{P}_1-\mathcal{P}_2}$ be the probability density function of $\mathcal{P}_1-\mathcal{P}_2$. The function $C_{\boldsymbol{\Sigma}}: \mathbb{R}^d \rightarrow (0, \,+\infty)$ that satisfies to 
    $$f_{\mathcal{P}_1-\mathcal{P}_2}(\boldsymbol{t})= \frac{C_{\boldsymbol{\Sigma}}(\boldsymbol{t})}{C_{\boldsymbol{\Sigma}}^2(\boldsymbol{0})},$$
    will be called the normal covariogram of $\mathbb{R}^d$ associated with $\boldsymbol{\Sigma}$.
\end{definition}

Taking into account \eqref{Ohanyan, Khalatyan intro}, the following theorem argues that the normal covariogram naturally extends the concept of covariogram.
     
\begin{theorem}\label{Confirm sigma covariogram}
Let $\boldsymbol{\Sigma}$ be the covariance matrix of a non-singular $d$-variate normal distribution and $C_{\boldsymbol{\Sigma}}$ be the normal covariogram of $\mathbb{R}^d$ associated with $\boldsymbol{\Sigma}$. Then
\begin{equation}\label{CSigma}
   C_{\boldsymbol{\Sigma}}(\boldsymbol{t})=(2\sqrt{\pi})^d |\boldsymbol{\Sigma}|^{1/2}\exp\bigg(-\frac{1}{4}\boldsymbol{t}^T\boldsymbol{\Sigma}^{-1}\boldsymbol{t}\bigg), \, \boldsymbol{t}\in \mathbb{R}^d
\end{equation}
and
  \begin{equation}\label{Analog of OhKh}
      f_{D_d}(\boldsymbol{\Sigma}, R)=\frac{R^{d-1}}{C_{\boldsymbol{\Sigma}}^2(\boldsymbol{0})} \int_{\mathbb{S}^{d-1}} C_{\boldsymbol{\Sigma}}(R\boldsymbol{u}) d \boldsymbol{u}, \,\,R>0.
  \end{equation}   
\end{theorem}

\noindent \textit{Proof.}
Let us take $\boldsymbol{t}=\boldsymbol{0}$ in the definition of a normal covariogram. Since by \eqref{fUu}
$$\frac{1}{(2\sqrt{\pi})^d |\boldsymbol{\Sigma}|^{1/2}}=f_{\mathcal{P}_1-\mathcal{P}_2}(\boldsymbol{0})=\frac{C_{\boldsymbol{\Sigma}}(\boldsymbol{0})}{C_{\boldsymbol{\Sigma}}^2(\boldsymbol{0})},$$
we obtain
$$C_{\boldsymbol{\Sigma}}(\boldsymbol{0})=(2\sqrt{\pi})^d |\boldsymbol{\Sigma}|^{1/2},$$
and, consequently,
\begin{equation*}
   C_{\boldsymbol{\Sigma}}(\boldsymbol{t})=(2\sqrt{\pi})^d |\boldsymbol{\Sigma}|^{1/2}\exp\bigg(-\frac{1}{4}\boldsymbol{t}^T\boldsymbol{\Sigma}^{-1}\boldsymbol{t}\bigg), \, \boldsymbol{t}\in \mathbb{R}^d.
\end{equation*}
As we proved \eqref{CSigma}, then we have
$$\frac{R^{d-1}}{C_{\boldsymbol{\Sigma}}^2(\boldsymbol{0})} \int_{\mathbb{S}^{d-1}} C_{\boldsymbol{\Sigma}}(R\boldsymbol{u}) d \boldsymbol{u}=\frac{R^{d-1}}{(2\sqrt{\pi})^d |\boldsymbol{\Sigma}|^{1/2}} \int_{\mathbb{S}^{d-1}}\exp\bigg(-\frac{R^2}{4}\boldsymbol{u}^T\boldsymbol{\Sigma}^{-1}\boldsymbol{u}\bigg)d\boldsymbol{u}.$$
Now due to \eqref{PDF of D_d over sphere}, the right-hand-side of the above equality coincides with the left-hand-side of \eqref{Analog of OhKh}. This completes the proof.

\begin{remark}\label{Remark on naturalness}
    It is remarkable that $C_{\boldsymbol{I}_d}(\boldsymbol{t})=(2\sqrt{\pi})^d\exp\big(-\frac{1}{4}\|\boldsymbol{t}\|^2\big)$. This illustrates that if $\mathbb{R}^d$ is considered as a space of points with uncorrelated coordinates then the covariogram of the space is naturally independent on the direction of translation.
\end{remark}





\chapter*{SUMMARY}
\addcontentsline{toc}{chapter}{SUMMARY} 

A brief description of the main results obtained in this dissertation is provided below. 
\begin{enumerate}
    \item As a contribution to the research of recognition of a convex body in ${\mathbb{R}}^n$ from the distribution of characteristics of its lower-dimensional sections,  explicit expressions for the covariogram and the orientation-dependent chord length distribution (ODCLD) function of right prisms with rectangular or right trapezoidal bases are found. Further, the concept of a standard image is introduced for any convex quadrilateral. Within this framework, for each direction $\varphi$, the notions of first and second-order $\varphi$-diameters, along with three supplementary measures, are defined and explicitly calculated for a standard image. Utilizing these five orientation-dependent characteristics, straightforward representations of the ODCLD function and the covariogram are established not only for any convex quadrilateral but also for any right prism based on it. Necessary and sufficient conditions are obtained for the continuity of the ODCLD function per direction. Additionally, points of potential discontinuity and the corresponding jumps are found. 



    \item The problem of finding the probabilities $p_{nk}$ of $n$ random lines producing $k$ intersection points inside a given convex planar domain $D$ is considered. This problem, rooted in stochastic geometry, carries a pronounced geometric essence. While the case of three lines has been explored and resolved by R. Sulanke, extending this understanding to the scenario of $n$ lines remains elusive. It is not clear how the outcome for $n$ lines would manifest, and what specific set of geometric invariants of $D$ should be employed to articulate the necessary probabilities explicitly. A new approach is presented to address this challenge. By utilizing a combinatorial algorithm by R. Ambartzumian, the count of intersection points inside $D$ for $n$ lines is connected to functionals associated with certain point sets situated on the boundary of $D$. The known results are instantly re-established for $n=2, 3$. In the case of $n=4$, a newfound family of geometric invariants is identified, enabling the explicit expression of the required probabilities in terms of these invariants. As a practical application, when $D$ is a disc with a radius of $r$, the simplest forms of these new invariants are derived, and the exact values of $p_{4k}$ are computed.
    
    

    \item The question of extending the concept of covariogram $C_{\mathbb{D}}$  from bounded convex bodies $\mathbb{D}$ to the entire space $\mathbb{R}^d$ is examined. The first problem that arises, is the nature of randomness of choosing a point from $\mathbb{D}=\mathbb{R}^d$. The uniform distribution is no longer applicable to this case, so it is naturally replaced with a multivariate normal distribution. The second obstacle lies in the challenge of applying the language and sense of geometry to define the covariogram of $\mathbb{R}^d$. A novel covariogram, termed the "normal covariogram", is defined analytically, ensuring seamless alignment with the pre-existing version. This precision is achieved by deriving integral representations for the distribution and probability density functions of the Euclidean distance between two $d$-dimensional Gaussian points with correlated coordinates governed by a covariance matrix. In a specific application, when $d=2$, a concise closed-form expression for the density function of that distance is attained. As another application, for any given dimension $d$, exact bounds for the moments of the aforementioned distance are established in terms of the extreme eigenvalues of the covariance matrix.

\end{enumerate}

 


\renewcommand{\bibname}{References}
\begin{thebibliography}{99}
\setlength{\itemsep}{-2pt}

\bibitem{Blaschke} Blaschke, W., Vorlesungen uber Integralgeometrie, 3rd ed. Deutsch. Verlag Wiss., Berlin, 1955.

\bibitem{Santalo} Santal, L.A., Integral Geometry and Geometric Probability, Cambridge University Press, 2004.

\bibitem{Matheron} Matheron, G., Random sets and integral geometry, Wiley, 1975.

\bibitem{Matheron86} Matheron, G., Le covariogramme geometrique des compacts convexes des $R^2$. Technical report N-2/86/G, Centre de Geostatistique, Ecole Nationale Superieure des Mines de Paris, 1986.

\bibitem{Bianchi rejection} Bianchi, G., Matherons conjecture for the covariogram problem. Journal of the London Mathematical Society, vol. 71, no. 1, pp. 203-220, 2005.

\bibitem{Nagel} Nagel, W, Orientation-dependent chord length distributions characterize
convex polygons. Appl. Prob., vol. 30, no. 3, pp. 730-736, 1993.

\bibitem{Bianchi and Averkov} Bianchi, G., and Averkov, G., Confirmation of Matheron's Conjecture on the covariogram of a planar convex body, Journal of the European Mathematical Society 11, no. 6, pp. 1187-1202, 2009.

\bibitem{Bianchi} Bianchi, G., The covariogram determines three-dimensional convex polytopes, Advances in Mathematics, 220 (6), pp. 1771-1808, 2009.

\bibitem{Schneider and Weil} Schneider, R., and Weil, W., Stochastic and Integral Geometry, Springer, Berlin, 2008.

\bibitem {GO_Triangle} Gasparyan, A.G., and Ohanyan, V.K., Recognition of triangles by covariogram, Journal of Contemporary Mathematical Analysis, vol. 48, pp. 110122, 2013.

\bibitem{GO_Parallelogram} Gasparyan, A.G., and Ohanyan, V.K., Covariogram of a parallelogram, Journal of Contemporary Mathem. Analysis, vol. 49, no. 4, pp. 17-34, 2014.

\bibitem{HO_Cylinder} Harutyunyan, H.S., and Ohanyan, V.K., Covariogram of a cylinder, Journal of Contemporary Mathematical Analysis, vol. 49, no. 6, pp. 366-375, 2014.

\bibitem{OAd_parallelepiped} Ohanyan, V.K., and Adamyan, G.L., Covariogram of a right parallelepiped, Proceedings of Yerevan State University, Phys. and Math. Sciences, vol. 53, no. 3, pp. 113-120, 2019.

\bibitem{GO_random segment}	Gasparyan, A.G., and Ohanyan, V.K., Orientation-dependent distribution of the length of a random segment and covariogram, Journal of Contemporary Mathematical Analysis, vol. 50, 2, pp. 90-97, 2015.

\bibitem{AH_triangle} Aharonyan, N.G., and Harutyunyan, H.O., Geometric probability calculation for a triangle, Proceedings of Yerevan State University, Phys. and Math. Sciences, vol. 51(3), pp. 211-216, 2017.

\bibitem{AO_geometric probabilities} Aharonyan, N.G., and Ohanyan, V.K., Calculation of geometric probabilities using covariogram of convex bodies, Journal of Contemporary Mathem. Analysis, vol. 53. no. 2, pp. 113-120, 2018.	 

\bibitem{AO_pattern recognition} Aharonyan, N.G., and Ohanyan, V.K., Pattern recognition by cross-sections, Modeling of Artificial Intelligence,  vol. 4, no. 2, pp. 72-77, 2017.

\bibitem{One more Sulanke} Sulanke, R., Die Verteilung der Sehnenlngen an ebenen und rumlichen Figuren. Math. Nachr. 23, pp. 5174, 1961.

\bibitem{2023} Van der Jagt, T., Jongbloed, G., and Vittorietti, M., Existence and Approximation of Densities of Chord Length- and Cross Section Area Distributions, Image Analysis and Stereology, 42(3), pp. 171184, 2023.    

\bibitem{Mallows and Clark} Mallows, C.L., and Clark, J.M., Linear intercept distributions do not characterize plane sets. Appl. Prob., vol. 7, pp. 240-244, 1970.

\bibitem{Gates_1} Gates, J., Recognition of Triangles and Quadrilaterals by Chord Length Distribution, Journal of Applied Probability, vol.19, pp. 873-879, 1982.

\bibitem{Gates_2} Gates, J., Some properties of chord-length distributions, Journal of Applied Probability, vol.24, pp. 863-874, 1987.

\bibitem{AO_polygons} Aharonyan, N.G., and Ohanyan, V.K., Chord length distributions for polygons, Journal of Contemporary Math. Anal., vol. 40, no. 4, pp. 43-56, 2005.

\bibitem{HO_regular polygons} Harutyunyan, H.S., and Ohanyan, V.K., Chord length distribution function for regular polygons, Advances in Applied Probability (SGSA), vol. 41, no. 2, pp. 358-366, 2009. 

\bibitem{Hayk} Sukiasian, H.S., and Gille, W., Relation between the chord length distribution of an infinitely long cylinder and that of its base, J. Math. Phys., vol. 48, 053305, 2007.	 	
	
\bibitem{HO_Regular Polygons and Ellipse} Harutyunyan, H.S., and Ohanyan, V.K., Orientation-dependent section distributions for convex bodies, Journal of Contemporary Mathematical Analysis, vol. 49, no. 3, pp. 139-156, 2014.

\bibitem{K} Khalatyan, V., Covariogram and Orientation-Dependent Chord Length Distribution Function for Oblique Prism, Journal of Contemporary Mathematical Analysis, Vol. 57, No. 3, pp. 157171, 2022.

\bibitem{Mount} Mount, D.M., The densest double-lattice packing of a convex polygon, DIMACS, Series in Discrete Mathematics and Theoretical Computer Science, vol. 6, pp. 245-262, 1991.  

\bibitem{Gardner} Gardner, R.J., Geometric Tomography, Cambridge Univ. Press, UK, 2nd ed., 2006. 

\bibitem{GGZ} Gardner, R.J., Gronchi, P., and Zong, C., Sums, Projections, and Sections of Lattice Sets, and the Discrete Covariogram, Discrete Comput. Geom. 34, pp. 391409, 2005.

\bibitem{Sulanke} Sulanke, R., Schnittpunkte zufalliger Geraden, Arch. Math. 16, pp. 320324, 1965.

\bibitem{Ambartzumian_1} Ambartzumian, R.V., Factorization calculus and geometric probability, Cambridge University Press, 1990.

\bibitem{Ambartzumian_2} Ambartzumian, R.V., Remarks on measure generation in the space of lines in $\mathbb{R}^3$, Journal of Contemporary Mathematical Analysis, 27, no. 5, pp. 1-21, 1992.

\bibitem{Crofton} Crofton, M.W., Probability, in Encyclopaedia Britannica, 9th ed., Vol. 19, 1885, pp. 768-788, 1885.

\bibitem{RobbinsBolis} Robbins, D.P., and Bolis, T.S., Solution to problem E2629: Average Distance between Two Points in a Box. American Math. Monthly, vol. 85, No. 4, pp. 277278, 1978. 

\bibitem{BaileyBorweinCrandall} Bailey, D.H., Borwein, J.M., and Crandall, R.E., Box integrals, Journal of Computational and Applied Mathematics, vol. 206, Issue 1, pp. 196-208, 2007. 

\bibitem{BurgstallerPillichshammer} Burgstaller, B., and Pillichshammer, F., The average distance between two points. Bull. Aust. Math. Soc. 80, pp. 353-359, 2009. 

\bibitem{AnderssenBrentDaleyMoran} Anderssen, R.S., Brent, R.P., Daley, D.J., and Moran, P.A.P., Concerning $\int_{0}^{1} \cdots \int_{0}^{1}\left(x_{1}^{2}+\cdots+x_{k}^{2}\right)^{1 / 2} d x_{1} \cdots d x_{k}$ and Taylor series method, SIAM Journal on Applied Mathematics, 30 (1), pp. 2230, 1976.

\bibitem{Philip} Philip, J., The Distance Between Two Random Points in a 4- and 5-Cube, Department of Mathematics, Royal Institute of Technology: Stockholm, Sweden, 2008.

\bibitem{MathaiMoschopoulosPederzoli_Italiano} Mathai A.M., Moschopoulos P., and Pederzoli, G., Random points associated with rectangles. Rendiconti del Circolo Matematico Di Palermo, 48, pp. 162190, 1999.

\bibitem{MathaiMoschopoulosPederzoli} Mathai A. M., Moschopoulos P., and Pederzoli G., Distance between random points in a cube. Statistica, 59(1), pp. 6181, 1999.

\bibitem{Aharonyan} Aharonyan, N.G., The distribution of the distance between two random points in a convex set, Russian Journal of Mathematical Research, Series A, 1, pp. 4-8, 2015.

\bibitem {AharonyanOhanyan} Aharonyan, N.G., and Ohanyan, V.K., Moments of the distance between two random points, Modeling of Artificial Intelligence, Vol. 10, Is. 2, pp. 64-70, 2016.

\bibitem{AK_distance} Aharonyan, N.G., and Khalatyan, V., Distribution of the distance between two random points in a body from ${\bf R}^n$, Journal of Contemporary Mathem. Analysis, vol. 55(6), pp. 329-334, 2020.

\bibitem{OhanyanKhalatyan} Ohanyan, V.K., and Khalatyan, V.H., Relation between the covariogram and distribution function of the distance between two uniform and independent points, Proceedings of the YSU, Physical and Mathematical Sciences, Volume 56, Issue 1, pp. 3342, 2022.

\bibitem{Aramyan1} Aramyan, R., and Yeranyan, D., Chord length distribution and the distance between two random points in a convex body in Rn, General Letters in Mathematics, vol. 9, no. 2, pp. 74-79, 2020.

\bibitem{Aramyan2} Aramyan, R., and Mnatsakanyan, V., Conditional moments for a d-dimensional convex body, Journal of Contemporary Mathem. Analysis, vol. 56, no 3, pp. 128-133, 2021.

\bibitem{LelloucheSouris} Lellouche, S., and Souris, M., "Distribution of distances between elements in a compact set, Stats, MDPI, vol. 3(1), pp. 1-15, 2019.

\bibitem{MathaiProvost} Mathai, A.M., and Provost, S.B., Quadratic forms in random variables. Theory and applications, Marcel Dekker, New York, 1992.

\bibitem{Stacy} Stacy, E.W., A Generalization of the Gamma Distribution, Annals of Mathematical Statistics 33(3), pp. 1187-1192, 1962.

\bibitem{JohnsonKotzBalakrishnan} Johnson, N.L., Kotz, S., and Balakrishnan, N., Continuous Univariate Distributions, Volume 1, 2nd Edition, Wiley, 1994.

\bibitem{arXiv} Thirey, B., and Hickman, R., Distribution of Euclidean distances between randomly distributed Gaussian points in n-space, arXiv:1508.02238 [math.PR], 2015.

\bibitem{OM1} Ohanyan, V.K., and Martirosyan, D.M., Orientation-Dependent Chord Length Distribution Function for Right Prisms with Rectangular or Right Trapezoidal Bases, Journal of Contemporary Mathematical Analysis, vol. 55, no 6, pp. 344355, 2020.

\bibitem{OM2} Martirosyan, D.M., and Ohanyan, V.K., On intersection probabilities of four lines inside a planar convex domain, Journal of Applied Probability, Volume 60, Issue 2, pp. 504  527, 2023.

\bibitem{M3} Martirosyan, D.M., Orientation-Dependent Chord Length Distribution in a Convex Quadrilateral, Journal of Contemporary Mathematical Analysis, vol. 58, no 6, pp. 416-430, 2023.

\bibitem{OM4} Martirosyan, D.M., and Ohanyan, V.K., On the Euclidean Distance Between Two Gaussian Points and the Normal Covariogram of $\mathbb{R}^d$, \foreignlanguage{russian}{  , ,  59, . 1, . 54-63, 2024} (Journal of Contemporary Mathematical Analysis, vol. 59, no 1, pp. 38-46, 2024). 


\end{thebibliography}
\addcontentsline{toc}{chapter}{REFERENCES}



\end{document}
