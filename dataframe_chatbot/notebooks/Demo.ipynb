{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59c0e1ca-1f3a-4170-8ec2-74cf1f6001ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8394564f-a373-4d45-8167-adffa07127aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32585fc9-e215-41a0-a78b-b805f0fa8522",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "from langchain_core.messages import HumanMessage\n",
    "from src.ai.autodf_ml_assistant import build_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b7b0005-bf5c-4878-9ff1-a4160d8f23e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def visualize_dataframe_assistant_graph():\n",
    "    graph = await build_graph()\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67ce270b-4980-4a9b-81b1-20795a777087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "config:\n",
      "  flowchart:\n",
      "    curve: linear\n",
      "---\n",
      "graph TD;\n",
      "\t__start__([<p>__start__</p>]):::first\n",
      "\tconversation(conversation)\n",
      "\tpandas_agent(pandas_agent)\n",
      "\tml_agent(ml_agent)\n",
      "\t__end__([<p>__end__</p>]):::last\n",
      "\t__start__ --> conversation;\n",
      "\tml_agent --> __end__;\n",
      "\tpandas_agent --> __end__;\n",
      "\tconversation -.-> pandas_agent;\n",
      "\tconversation -.-> ml_agent;\n",
      "\tclassDef default fill:#f2f0ff,line-height:1.2\n",
      "\tclassDef first fill-opacity:0\n",
      "\tclassDef last fill:#bfb6fc\n",
      "\n"
     ]
    }
   ],
   "source": [
    "assistant_graph = await visualize_dataframe_assistant_graph()\n",
    "print(assistant_graph.get_graph().draw_mermaid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad67ddad-a0b1-4a67-aae9-3b82ea43533d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assistant_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "566f5b22-1e28-4790-a82c-c5bf0bd9b825",
   "metadata": {},
   "outputs": [],
   "source": [
    "thread_id = str(uuid.uuid4())\n",
    "config = {\"configurable\": {\"thread_id\" : thread_id}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3da5b54b-704d-4971-9a56-1620b49b3cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def log_assistant_graph_steps(query: str, config: dict):\n",
    "    step = 1\n",
    "    current_tool = None\n",
    "    async for token, metadata in assistant_graph.astream(\n",
    "            {\"messages\": [HumanMessage(content=query)]}, config=config, stream_mode=\"messages\"\n",
    "    ):\n",
    "        current_node = metadata.get('langgraph_node', 'unknown')\n",
    "        \n",
    "        # Check if this is a tool call by looking at the message content\n",
    "        if hasattr(token, 'tool_calls') and token.tool_calls:\n",
    "            for tool_call in token.tool_calls:\n",
    "                tool_name = tool_call.get('name', 'unknown_tool')\n",
    "                print(f\"\\nüîß Calling tool: {tool_name}\")\n",
    "                current_tool = tool_name\n",
    "        \n",
    "        # Print step metadata when it changes\n",
    "        if metadata['langgraph_step'] == step:\n",
    "            print(f\"\\nüîÑ Step {step}: Node '{current_node}'\")\n",
    "            if current_node == 'tools' and current_tool:\n",
    "                print(f\"   ‚îî‚îÄ‚îÄ Executing tool: {current_tool}\")\n",
    "            print(\"Metadata\", metadata, \"\\n\")\n",
    "            step += 1\n",
    "            \n",
    "        print(token.content, end='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b61c7b84-b85b-48ec-970f-5b9d0cde4903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÑ Step 1: Node 'conversation'\n",
      "Metadata {'thread_id': 'cf078d61-f2af-4783-8ffe-b7eb065df3e3', 'langgraph_step': 1, 'langgraph_node': 'conversation', 'langgraph_triggers': ('branch:to:conversation', 'start:conversation'), 'langgraph_path': ('__pregel_pull', 'conversation'), 'langgraph_checkpoint_ns': 'conversation:8ece4fa0-2c15-5ee0-3ef1-7491fcd17d91', 'checkpoint_ns': 'conversation:8ece4fa0-2c15-5ee0-3ef1-7491fcd17d91', 'ls_provider': 'ollama', 'ls_model_name': 'gpt-oss:20b', 'ls_model_type': 'chat', 'ls_temperature': 0.7} \n",
      "\n",
      "pandas_agent\n",
      "üîß Calling tool: python_repl_ast\n",
      "\n",
      "üîÑ Step 2: Node 'tools'\n",
      "   ‚îî‚îÄ‚îÄ Executing tool: python_repl_ast\n",
      "Metadata {'thread_id': 'cf078d61-f2af-4783-8ffe-b7eb065df3e3', 'langgraph_step': 2, 'langgraph_node': 'tools', 'langgraph_triggers': ('branch:to:tools',), 'langgraph_path': ('__pregel_pull', 'tools'), 'langgraph_checkpoint_ns': 'pandas_agent:aaa4668e-b47e-5b31-40d9-6f8c73d69dfa|tools:c43f3392-911f-8f48-e466-e059c02c71be', 'checkpoint_ns': 'pandas_agent:aaa4668e-b47e-5b31-40d9-6f8c73d69dfa'} \n",
      "\n",
      "[\"age\", \"gender\", \"bmi\", \"daily_steps\", \"sleep_hours\", \"water_intake_l\", \"calories_consumed\", \"smoker\", \"alcohol\", \"resting_hr\", \"systolic_bp\", \"diastolic_bp\", \"cholesterol\", \"family_history\", \"disease_risk\"]\n",
      "üîÑ Step 3: Node 'agent'\n",
      "Metadata {'thread_id': 'cf078d61-f2af-4783-8ffe-b7eb065df3e3', 'langgraph_step': 3, 'langgraph_node': 'agent', 'langgraph_triggers': ('branch:to:agent', 'start:agent', 'tools'), 'langgraph_path': ('__pregel_pull', 'agent'), 'langgraph_checkpoint_ns': 'pandas_agent:aaa4668e-b47e-5b31-40d9-6f8c73d69dfa|agent:cd8726f2-9477-c313-8b9b-c7e827103ff9', 'checkpoint_ns': 'pandas_agent:aaa4668e-b47e-5b31-40d9-6f8c73d69dfa', 'ls_provider': 'ollama', 'ls_model_name': 'gpt-oss:20b', 'ls_model_type': 'chat', 'ls_temperature': 0.7} \n",
      "\n",
      "Here are the column names in your dataset:\n",
      "\n",
      "- age  \n",
      "- gender  \n",
      "- bmi  \n",
      "- daily_steps  \n",
      "- sleep_hours  \n",
      "- water_intake_l  \n",
      "- calories_consumed  \n",
      "- smoker  \n",
      "- alcohol  \n",
      "- resting_hr  \n",
      "- systolic_bp  \n",
      "- diastolic_bp  \n",
      "- cholesterol  \n",
      "- family_history  \n",
      "- disease_risk"
     ]
    }
   ],
   "source": [
    "query = \"List the columns of my dataset.\"\n",
    "await log_assistant_graph_steps(query, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f038d3ad-95c4-4a04-96aa-035a0b4115fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas_agent\n",
      "üîÑ Step 1: Node 'agent'\n",
      "Metadata {'thread_id': 'cf078d61-f2af-4783-8ffe-b7eb065df3e3', 'langgraph_step': 1, 'langgraph_node': 'agent', 'langgraph_triggers': ('branch:to:agent', 'start:agent', 'tools'), 'langgraph_path': ('__pregel_pull', 'agent'), 'langgraph_checkpoint_ns': 'pandas_agent:499fc0d6-4651-af32-ec31-ab799e3d7985|agent:7219d886-d815-3022-d785-02528d8442bd', 'checkpoint_ns': 'pandas_agent:499fc0d6-4651-af32-ec31-ab799e3d7985', 'ls_provider': 'ollama', 'ls_model_name': 'gpt-oss:20b', 'ls_model_type': 'chat', 'ls_temperature': 0.7} \n",
      "\n",
      "\n",
      "üîÑ Step 2: Node 'tools'\n",
      "   ‚îî‚îÄ‚îÄ Executing tool: python_repl_ast\n",
      "Metadata {'thread_id': 'cf078d61-f2af-4783-8ffe-b7eb065df3e3', 'langgraph_step': 2, 'langgraph_node': 'tools', 'langgraph_triggers': ('branch:to:tools',), 'langgraph_path': ('__pregel_pull', 'tools'), 'langgraph_checkpoint_ns': 'pandas_agent:499fc0d6-4651-af32-ec31-ab799e3d7985|tools:44c9e6f9-e9a1-7c85-c12f-dc7ad4d3c3a6', 'checkpoint_ns': 'pandas_agent:499fc0d6-4651-af32-ec31-ab799e3d7985'} \n",
      "\n",
      "{\"age\": {\"count\": 100000.0, \"unique\": NaN, \"top\": NaN, \"freq\": NaN, \"mean\": 48.52599, \"std\": 17.886767843423776, \"min\": 18.0, \"25%\": 33.0, \"50%\": 48.0, \"75%\": 64.0, \"max\": 79.0}, \"gender\": {\"count\": 100000, \"unique\": 2, \"top\": \"Male\", \"freq\": 50132, \"mean\": NaN, \"std\": NaN, \"min\": NaN, \"25%\": NaN, \"50%\": NaN, \"75%\": NaN, \"max\": NaN}, \"bmi\": {\"count\": 100000.0, \"unique\": NaN, \"top\": NaN, \"freq\": NaN, \"mean\": 29.02479, \"std\": 6.352665961590315, \"min\": 18.0, \"25%\": 23.5, \"50%\": 29.0, \"75%\": 34.5, \"max\": 40.0}, \"daily_steps\": {\"count\": 100000.0, \"unique\": NaN, \"top\": NaN, \"freq\": NaN, \"mean\": 10479.87029, \"std\": 5483.632360115321, \"min\": 1000.0, \"25%\": 5729.0, \"50%\": 10468.0, \"75%\": 15229.0, \"max\": 19999.0}, \"sleep_hours\": {\"count\": 100000.0, \"unique\": NaN, \"top\": NaN, \"freq\": NaN, \"mean\": 6.491783999999999, \"std\": 2.0219221001398124, \"min\": 3.0, \"25%\": 4.7, \"50%\": 6.5, \"75%\": 8.2, \"max\": 10.0}, \"water_intake_l\": {\"count\": 100000.0, \"unique\": NaN, \"top\": NaN, \"freq\": NaN, \"mean\": 2.751496, \"std\": 1.2973377327573297, \"min\": 0.5, \"25%\": 1.6, \"50%\": 2.8, \"75%\": 3.9, \"max\": 5.0}, \"calories_consumed\": {\"count\": 100000.0, \"unique\": NaN, \"top\": NaN, \"freq\": NaN, \"mean\": 2603.3412, \"std\": 807.2885631239932, \"min\": 1200.0, \"25%\": 1906.0, \"50%\": 2603.0, \"75%\": 3299.0, \"max\": 3999.0}, \"smoker\": {\"count\": 100000.0, \"unique\": NaN, \"top\": NaN, \"freq\": NaN, \"mean\": 0.20094, \"std\": 0.4007052807827974, \"min\": 0.0, \"25%\": 0.0, \"50%\": 0.0, \"75%\": 0.0, \"max\": 1.0}, \"alcohol\": {\"count\": 100000.0, \"unique\": NaN, \"top\": NaN, \"freq\": NaN, \"mean\": 0.30002, \"std\": 0.4582685890403105, \"min\": 0.0, \"25%\": 0.0, \"50%\": 0.0, \"75%\": 1.0, \"max\": 1.0}, \"resting_hr\": {\"count\": 100000.0, \"unique\": NaN, \"top\": NaN, \"freq\": NaN, \"mean\": 74.45742, \"std\": 14.423715449885782, \"min\": 50.0, \"25%\": 62.0, \"50%\": 74.0, \"75%\": 87.0, \"max\": 99.0}, \"systolic_bp\": {\"count\": 100000.0, \"unique\": NaN, \"top\": NaN, \"freq\": NaN, \"mean\": 134.58063, \"std\": 25.95153046782475, \"min\": 90.0, \"25%\": 112.0, \"50%\": 135.0, \"75%\": 157.0, \"max\": 179.0}, \"diastolic_bp\": {\"count\": 100000.0, \"unique\": NaN, \"top\": NaN, \"freq\": NaN, \"mean\": 89.50885, \"std\": 17.347040983286135, \"min\": 60.0, \"25%\": 74.0, \"50%\": 89.0, \"75%\": 105.0, \"max\": 119.0}, \"cholesterol\": {\"count\": 100000.0, \"unique\": NaN, \"top\": NaN, \"freq\": NaN, \"mean\": 224.30063, \"std\": 43.32774935929335, \"min\": 150.0, \"25%\": 187.0, \"50%\": 224.0, \"75%\": 262.0, \"max\": 299.0}, \"family_history\": {\"count\": 100000.0, \"unique\": NaN, \"top\": NaN, \"freq\": NaN, \"mean\": 0.29915, \"std\": 0.45788794929954335, \"min\": 0.0, \"25%\": 0.0, \"50%\": 0.0, \"75%\": 1.0, \"max\": 1.0}, \"disease_risk\": {\"count\": 100000.0, \"unique\": NaN, \"top\": NaN, \"freq\": NaN, \"mean\": 0.24821, \"std\": 0.4319764599334313, \"min\": 0.0, \"25%\": 0.0, \"50%\": 0.0, \"75%\": 0.0, \"max\": 1.0}}\n",
      "üîÑ Step 3: Node 'agent'\n",
      "Metadata {'thread_id': 'cf078d61-f2af-4783-8ffe-b7eb065df3e3', 'langgraph_step': 3, 'langgraph_node': 'agent', 'langgraph_triggers': ('branch:to:agent', 'start:agent', 'tools'), 'langgraph_path': ('__pregel_pull', 'agent'), 'langgraph_checkpoint_ns': 'pandas_agent:499fc0d6-4651-af32-ec31-ab799e3d7985|agent:50928f2f-b0bc-e9e4-76f9-225b1ab34719', 'checkpoint_ns': 'pandas_agent:499fc0d6-4651-af32-ec31-ab799e3d7985', 'ls_provider': 'ollama', 'ls_model_name': 'gpt-oss:20b', 'ls_model_type': 'chat', 'ls_temperature': 0.7} \n",
      "\n",
      "Below is a concise summary of the descriptive statistics for each column in your dataset.  \n",
      "The numbers are rounded to two decimal places for readability.\n",
      "\n",
      "| Column          | Count | Mean | Std Dev | Min | 25‚ÄØ% | 50‚ÄØ% (Median) | 75‚ÄØ% | Max | Unique | Top (most frequent) | Frequency |\n",
      "|-----------------|-------|------|---------|-----|------|----------------|------|-----|--------|---------------------|-----------|\n",
      "| **age**         | 100‚ÄØ000 | 48.53 | 17.89 | 18.0 | 33.0 | 48.0 | 64.0 | 79.0 | ‚Äì | ‚Äì | ‚Äì |\n",
      "| **gender**      | 100‚ÄØ000 | ‚Äì | ‚Äì | ‚Äì | ‚Äì | ‚Äì | ‚Äì | ‚Äì | 2 | Male | 50‚ÄØ132 |\n",
      "| **bmi**         | 100‚ÄØ000 | 29.02 | 6.35 | 18.0 | 23.5 | 29.0 | 34.5 | 40.0 | ‚Äì | ‚Äì | ‚Äì |\n",
      "| **daily_steps** | 100‚ÄØ000 | 10‚ÄØ480 | 5‚ÄØ484 | 1‚ÄØ000 | 5‚ÄØ729 | 10‚ÄØ468 | 15‚ÄØ229 | 19‚ÄØ999 | ‚Äì | ‚Äì | ‚Äì |\n",
      "| **sleep_hours** | 100‚ÄØ000 | 6.49 | 2.02 | 3.0 | 4.7 | 6.5 | 8.2 | 10.0 | ‚Äì | ‚Äì | ‚Äì |\n",
      "| **water_intake_l** | 100‚ÄØ000 | 2.75 | 1.30 | 0.5 | 1.6 | 2.8 | 3.9 | 5.0 | ‚Äì | ‚Äì | ‚Äì |\n",
      "| **calories_consumed** | 100‚ÄØ000 | 2‚ÄØ603 | 807 | 1‚ÄØ200 | 1‚ÄØ906 | 2‚ÄØ603 | 3‚ÄØ299 | 3‚ÄØ999 | ‚Äì | ‚Äì | ‚Äì |\n",
      "| **smoker**      | 100‚ÄØ000 | 0.20 | 0.40 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | ‚Äì | ‚Äì | ‚Äì |\n",
      "| **alcohol**     | 100‚ÄØ000 | 0.30 | 0.46 | 0.0 | 0.0 | 0.0 | 1.0 | 1.0 | ‚Äì | ‚Äì | ‚Äì |\n",
      "| **resting_hr**  | 100‚ÄØ000 | 74.46 | 14.42 | 50.0 | 62.0 | 74.0 | 87.0 | 99.0 | ‚Äì | ‚Äì | ‚Äì |\n",
      "| **systolic_bp** | 100‚ÄØ000 | 134.58 | 25.95 | 90.0 | 112.0 | 135.0 | 157.0 | 179.0 | ‚Äì | ‚Äì | ‚Äì |\n",
      "| **diastolic_bp**| 100‚ÄØ000 | 89.51 | 17.35 | 60.0 | 74.0 | 89.0 | 105.0 | 119.0 | ‚Äì | ‚Äì | ‚Äì |\n",
      "| **cholesterol** | 100‚ÄØ000 | 224.30 | 43.33 | 150.0 | 187.0 | 224.0 | 262.0 | 299.0 | ‚Äì | ‚Äì | ‚Äì |\n",
      "| **family_history** | 100‚ÄØ000 | 0.30 | 0.46 | 0.0 | 0.0 | 0.0 | 1.0 | 1.0 | ‚Äì | ‚Äì | ‚Äì |\n",
      "| **disease_risk** | 100‚ÄØ000 | 0.25 | 0.43 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | ‚Äì | ‚Äì | ‚Äì |\n",
      "\n",
      "### Notes\n",
      "- **Binary columns** (`smoker`, `alcohol`, `family_history`, `disease_risk`) are encoded as 0/1. The mean value represents the proportion of 1‚Äôs in the column.\n",
      "- **Categorical column** `gender` has two unique values; the most frequent value is ‚ÄúMale‚Äù (50‚ÄØ132 occurrences).\n",
      "- All other columns are continuous numeric variables.\n",
      "\n",
      "Let me know if you‚Äôd like any additional summaries (e.g., correlations, group‚Äëby statistics, or visualizations)."
     ]
    }
   ],
   "source": [
    "query = \"please give me descriptive statistics of the data\"\n",
    "await log_assistant_graph_steps(query, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38e39272-a945-4fbc-b224-82e3ae75d8dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ml_agent\n",
      "üîÑ Step 1: Node 'agent'\n",
      "Metadata {'thread_id': 'cf078d61-f2af-4783-8ffe-b7eb065df3e3', 'langgraph_step': 1, 'langgraph_node': 'agent', 'langgraph_triggers': ('branch:to:agent', 'start:agent', 'tools'), 'langgraph_path': ('__pregel_pull', 'agent'), 'langgraph_checkpoint_ns': 'ml_agent:766f2c3b-6422-9610-60ef-421efc731223|agent:734c3bdd-302c-45e4-376f-9120c90cc222', 'checkpoint_ns': 'ml_agent:766f2c3b-6422-9610-60ef-421efc731223', 'ls_provider': 'ollama', 'ls_model_name': 'gpt-oss:20b', 'ls_model_type': 'chat', 'ls_temperature': 0.7} \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-10 07:08:45,412 - dataframe-chatbot - INFO - #Train examples = 80000\n",
      "2025-10-10 07:08:45,412 - dataframe-chatbot - INFO - #Test examples = 20000\n",
      "2025-10-10 07:08:50,555 - dataframe-chatbot - INFO - Best Parameters: {'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 2}\n",
      "2025-10-10 07:08:50,555 - dataframe-chatbot - INFO - Best CV Macro F1: 0.3439806638365158\n",
      "2025-10-10 07:08:50,556 - dataframe-chatbot - INFO - ----------\n",
      "\n",
      "2025-10-10 07:08:50,581 - dataframe-chatbot - INFO - ---- Train Results ----\n",
      "2025-10-10 07:08:50,582 - dataframe-chatbot - INFO - Recall (binary) = 0.6385153850027698\n",
      "2025-10-10 07:08:50,582 - dataframe-chatbot - INFO - Precision (binary) = 0.27773761801493946\n",
      "2025-10-10 07:08:50,582 - dataframe-chatbot - INFO - F1-score (binary) = 0.38709775905232946\n",
      "2025-10-10 07:08:50,582 - dataframe-chatbot - INFO - ----------\n",
      "\n",
      "2025-10-10 07:08:50,582 - dataframe-chatbot - INFO - ---- Test Results ----\n",
      "2025-10-10 07:08:50,582 - dataframe-chatbot - INFO - Recall (binary) = 0.5703062046736502\n",
      "2025-10-10 07:08:50,583 - dataframe-chatbot - INFO - Precision (binary) = 0.24561860142287004\n",
      "2025-10-10 07:08:50,583 - dataframe-chatbot - INFO - F1-score (binary) = 0.3433596118859915\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÑ Step 2: Node 'tools'\n",
      "   ‚îî‚îÄ‚îÄ Executing tool: python_repl_ast\n",
      "Metadata {'thread_id': 'cf078d61-f2af-4783-8ffe-b7eb065df3e3', 'langgraph_step': 2, 'langgraph_node': 'tools', 'langgraph_triggers': ('branch:to:tools',), 'langgraph_path': ('__pregel_pull', 'tools'), 'langgraph_checkpoint_ns': 'ml_agent:766f2c3b-6422-9610-60ef-421efc731223|tools:370a7aba-e7ae-3fb7-f398-f7068f6fa372', 'checkpoint_ns': 'ml_agent:766f2c3b-6422-9610-60ef-421efc731223'} \n",
      "\n",
      "{\"model_uri\": \"/home/davit/medium/dataframe_chatbot/models/decision_tree/model.joblib\", \"metrics\": {\"train\": {\"Recall (binary)\": 0.6385153850027698, \"Precision (binary)\": 0.27773761801493946, \"F1-score (binary)\": 0.38709775905232946}, \"test\": {\"Recall (binary)\": 0.5703062046736502, \"Precision (binary)\": 0.24561860142287004, \"F1-score (binary)\": 0.3433596118859915}}}\n",
      "üîÑ Step 3: Node 'agent'\n",
      "Metadata {'thread_id': 'cf078d61-f2af-4783-8ffe-b7eb065df3e3', 'langgraph_step': 3, 'langgraph_node': 'agent', 'langgraph_triggers': ('branch:to:agent', 'start:agent', 'tools'), 'langgraph_path': ('__pregel_pull', 'agent'), 'langgraph_checkpoint_ns': 'ml_agent:766f2c3b-6422-9610-60ef-421efc731223|agent:cce302df-e989-a355-9b54-5f0512d2b75d', 'checkpoint_ns': 'ml_agent:766f2c3b-6422-9610-60ef-421efc731223', 'ls_provider': 'ollama', 'ls_model_name': 'gpt-oss:20b', 'ls_model_type': 'chat', 'ls_temperature': 0.7} \n",
      "\n",
      "Great! The decision‚Äëtree model has been trained and stored at:\n",
      "\n",
      "```\n",
      "/home/davit/medium/dataframe_chatbot/models/decision_tree/model.joblib\n",
      "```\n",
      "\n",
      "### Performance Summary\n",
      "\n",
      "| Set | Recall (binary) | Precision (binary) | F1‚Äëscore (binary) |\n",
      "|-----|-----------------|--------------------|-------------------|\n",
      "| **Train** | 0.639 | 0.278 | 0.387 |\n",
      "| **Test**  | 0.570 | 0.246 | 0.343 |\n",
      "\n",
      "- **Recall** (sensitivity) is the proportion of actual disease‚Äërisk cases correctly identified.  \n",
      "- **Precision** is the proportion of predicted disease‚Äërisk cases that are truly positive.  \n",
      "- **F1‚Äëscore** balances recall and precision.\n",
      "\n",
      "The model performs reasonably well on recall, but precision is relatively low, which is common in medical risk prediction where false positives are tolerable but false negatives are costly.\n",
      "\n",
      "### Next Steps\n",
      "\n",
      "1. **Interpretation** ‚Äì If you‚Äôd like a human‚Äëreadable representation of the tree (rules, feature importance), just let me know and I‚Äôll generate it with `export_decision_tree_to_text()`.  \n",
      "2. **Prediction** ‚Äì Provide a dictionary of feature values (e.g., `{'age': 45, 'bmi': 27.5, ...}`) and I‚Äôll return the predicted disease risk.  \n",
      "3. **Evaluation** ‚Äì Want additional metrics (accuracy, ROC‚ÄëAUC, confusion matrix) or a cross‚Äëvalidation report?  \n",
      "4. **Improvement** ‚Äì We could tune hyperparameters, try a different algorithm, or engineer new features.\n",
      "\n",
      "What would you like to do next?"
     ]
    }
   ],
   "source": [
    "query = \"Let's now build a decision tree model using as our target variable 'disease_risk'\"\n",
    "await log_assistant_graph_steps(query, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b2a2089-1ea0-4850-a970-3afd4aa749ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas_agent\n",
      "üîÑ Step 1: Node 'agent'\n",
      "Metadata {'thread_id': 'cf078d61-f2af-4783-8ffe-b7eb065df3e3', 'langgraph_step': 1, 'langgraph_node': 'agent', 'langgraph_triggers': ('branch:to:agent', 'start:agent', 'tools'), 'langgraph_path': ('__pregel_pull', 'agent'), 'langgraph_checkpoint_ns': 'pandas_agent:b9b7e620-7e2d-472b-e3cb-8f9437d6e547|agent:f2e4c006-f414-0328-2292-aa092231dbb8', 'checkpoint_ns': 'pandas_agent:b9b7e620-7e2d-472b-e3cb-8f9437d6e547', 'ls_provider': 'ollama', 'ls_model_name': 'gpt-oss:20b', 'ls_model_type': 'chat', 'ls_temperature': 0.7} \n",
      "\n",
      "\n",
      "üîß Calling tool: python_repl_ast\n",
      "\n",
      "üîÑ Step 2: Node 'tools'\n",
      "   ‚îî‚îÄ‚îÄ Executing tool: python_repl_ast\n",
      "Metadata {'thread_id': 'cf078d61-f2af-4783-8ffe-b7eb065df3e3', 'langgraph_step': 2, 'langgraph_node': 'tools', 'langgraph_triggers': ('branch:to:tools',), 'langgraph_path': ('__pregel_pull', 'tools'), 'langgraph_checkpoint_ns': 'pandas_agent:b9b7e620-7e2d-472b-e3cb-8f9437d6e547|tools:1cfe93fa-7cb3-8df7-f119-fa29c7bbb591', 'checkpoint_ns': 'pandas_agent:b9b7e620-7e2d-472b-e3cb-8f9437d6e547'} \n",
      "\n",
      "disease_risk\n",
      "0    75179\n",
      "1    24821\n",
      "Name: count, dtype: int64\n",
      "üîÑ Step 3: Node 'agent'\n",
      "Metadata {'thread_id': 'cf078d61-f2af-4783-8ffe-b7eb065df3e3', 'langgraph_step': 3, 'langgraph_node': 'agent', 'langgraph_triggers': ('branch:to:agent', 'start:agent', 'tools'), 'langgraph_path': ('__pregel_pull', 'agent'), 'langgraph_checkpoint_ns': 'pandas_agent:b9b7e620-7e2d-472b-e3cb-8f9437d6e547|agent:d0b1e7a9-ae61-ff2e-6b44-1465383cf714', 'checkpoint_ns': 'pandas_agent:b9b7e620-7e2d-472b-e3cb-8f9437d6e547', 'ls_provider': 'ollama', 'ls_model_name': 'gpt-oss:20b', 'ls_model_type': 'chat', 'ls_temperature': 0.7} \n",
      "\n",
      "Here‚Äôs the distribution of the target variable **`disease_risk`** in the dataset:\n",
      "\n",
      "| `disease_risk` | Count | Percentage |\n",
      "|----------------|-------|------------|\n",
      "| 0 (No risk)    | 75,179 | 75.2‚ÄØ% |\n",
      "| 1 (Risk)       | 24,821 | 24.8‚ÄØ% |\n",
      "\n",
      "So, about three‚Äëquarters of the records are labeled as *no risk*, while roughly one‚Äëquarter are labeled as *risk*."
     ]
    }
   ],
   "source": [
    "query = \"Please give me the value distribution of the column 'disease_risk'\"\n",
    "await log_assistant_graph_steps(query, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2b5ac2-997c-43f9-8d02-65f9c78ff836",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec4d120-90d1-4f1d-9d96-eefb01033de8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653e8db0-3e09-4e5c-9891-b20739616064",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8d3061-a422-4a2c-8f75-aeecb32f746e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
