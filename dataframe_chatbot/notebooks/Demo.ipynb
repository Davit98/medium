{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59c0e1ca-1f3a-4170-8ec2-74cf1f6001ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8394564f-a373-4d45-8167-adffa07127aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32585fc9-e215-41a0-a78b-b805f0fa8522",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "from langchain_core.messages import HumanMessage\n",
    "from src.ai.autodf_ml_assistant import build_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b7b0005-bf5c-4878-9ff1-a4160d8f23e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def visualize_dataframe_assistant_graph():\n",
    "    graph = await build_graph()\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67ce270b-4980-4a9b-81b1-20795a777087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "config:\n",
      "  flowchart:\n",
      "    curve: linear\n",
      "---\n",
      "graph TD;\n",
      "\t__start__([<p>__start__</p>]):::first\n",
      "\tconversation(conversation)\n",
      "\tpandas_agent(pandas_agent)\n",
      "\tml_agent(ml_agent)\n",
      "\t__end__([<p>__end__</p>]):::last\n",
      "\t__start__ --> conversation;\n",
      "\tml_agent --> __end__;\n",
      "\tpandas_agent --> __end__;\n",
      "\tconversation -.-> pandas_agent;\n",
      "\tconversation -.-> ml_agent;\n",
      "\tclassDef default fill:#f2f0ff,line-height:1.2\n",
      "\tclassDef first fill-opacity:0\n",
      "\tclassDef last fill:#bfb6fc\n",
      "\n"
     ]
    }
   ],
   "source": [
    "assistant_graph = await visualize_dataframe_assistant_graph()\n",
    "print(assistant_graph.get_graph().draw_mermaid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad67ddad-a0b1-4a67-aae9-3b82ea43533d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assistant_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "566f5b22-1e28-4790-a82c-c5bf0bd9b825",
   "metadata": {},
   "outputs": [],
   "source": [
    "thread_id = str(uuid.uuid4())\n",
    "config = {\"configurable\": {\"thread_id\" : thread_id}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3da5b54b-704d-4971-9a56-1620b49b3cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def log_assistant_graph_steps(query: str, config: dict):\n",
    "    step = 1\n",
    "    current_tool = None\n",
    "    async for token, metadata in assistant_graph.astream(\n",
    "            {\"messages\": [HumanMessage(content=query)]}, config=config, stream_mode=\"messages\"\n",
    "    ):\n",
    "        current_node = metadata.get('langgraph_node', 'unknown')\n",
    "        \n",
    "        # Check if this is a tool call by looking at the message content\n",
    "        if hasattr(token, 'tool_calls') and token.tool_calls:\n",
    "            for tool_call in token.tool_calls:\n",
    "                tool_name = tool_call.get('name', 'unknown_tool')\n",
    "                print(f\"\\n🔧 Calling tool: {tool_name}\")\n",
    "                current_tool = tool_name\n",
    "        \n",
    "        # Print step metadata when it changes\n",
    "        if metadata['langgraph_step'] == step:\n",
    "            print(f\"\\n🔄 Step {step}: Node '{current_node}'\")\n",
    "            if current_node == 'tools' and current_tool:\n",
    "                print(f\"   └── Executing tool: {current_tool}\")\n",
    "            print(\"Metadata\", metadata, \"\\n\")\n",
    "            step += 1\n",
    "            \n",
    "        print(token.content, end='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b61c7b84-b85b-48ec-970f-5b9d0cde4903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔄 Step 1: Node 'conversation'\n",
      "Metadata {'thread_id': 'cf078d61-f2af-4783-8ffe-b7eb065df3e3', 'langgraph_step': 1, 'langgraph_node': 'conversation', 'langgraph_triggers': ('branch:to:conversation', 'start:conversation'), 'langgraph_path': ('__pregel_pull', 'conversation'), 'langgraph_checkpoint_ns': 'conversation:8ece4fa0-2c15-5ee0-3ef1-7491fcd17d91', 'checkpoint_ns': 'conversation:8ece4fa0-2c15-5ee0-3ef1-7491fcd17d91', 'ls_provider': 'ollama', 'ls_model_name': 'gpt-oss:20b', 'ls_model_type': 'chat', 'ls_temperature': 0.7} \n",
      "\n",
      "pandas_agent\n",
      "🔧 Calling tool: python_repl_ast\n",
      "\n",
      "🔄 Step 2: Node 'tools'\n",
      "   └── Executing tool: python_repl_ast\n",
      "Metadata {'thread_id': 'cf078d61-f2af-4783-8ffe-b7eb065df3e3', 'langgraph_step': 2, 'langgraph_node': 'tools', 'langgraph_triggers': ('branch:to:tools',), 'langgraph_path': ('__pregel_pull', 'tools'), 'langgraph_checkpoint_ns': 'pandas_agent:aaa4668e-b47e-5b31-40d9-6f8c73d69dfa|tools:c43f3392-911f-8f48-e466-e059c02c71be', 'checkpoint_ns': 'pandas_agent:aaa4668e-b47e-5b31-40d9-6f8c73d69dfa'} \n",
      "\n",
      "[\"age\", \"gender\", \"bmi\", \"daily_steps\", \"sleep_hours\", \"water_intake_l\", \"calories_consumed\", \"smoker\", \"alcohol\", \"resting_hr\", \"systolic_bp\", \"diastolic_bp\", \"cholesterol\", \"family_history\", \"disease_risk\"]\n",
      "🔄 Step 3: Node 'agent'\n",
      "Metadata {'thread_id': 'cf078d61-f2af-4783-8ffe-b7eb065df3e3', 'langgraph_step': 3, 'langgraph_node': 'agent', 'langgraph_triggers': ('branch:to:agent', 'start:agent', 'tools'), 'langgraph_path': ('__pregel_pull', 'agent'), 'langgraph_checkpoint_ns': 'pandas_agent:aaa4668e-b47e-5b31-40d9-6f8c73d69dfa|agent:cd8726f2-9477-c313-8b9b-c7e827103ff9', 'checkpoint_ns': 'pandas_agent:aaa4668e-b47e-5b31-40d9-6f8c73d69dfa', 'ls_provider': 'ollama', 'ls_model_name': 'gpt-oss:20b', 'ls_model_type': 'chat', 'ls_temperature': 0.7} \n",
      "\n",
      "Here are the column names in your dataset:\n",
      "\n",
      "- age  \n",
      "- gender  \n",
      "- bmi  \n",
      "- daily_steps  \n",
      "- sleep_hours  \n",
      "- water_intake_l  \n",
      "- calories_consumed  \n",
      "- smoker  \n",
      "- alcohol  \n",
      "- resting_hr  \n",
      "- systolic_bp  \n",
      "- diastolic_bp  \n",
      "- cholesterol  \n",
      "- family_history  \n",
      "- disease_risk"
     ]
    }
   ],
   "source": [
    "query = \"List the columns of my dataset.\"\n",
    "await log_assistant_graph_steps(query, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f038d3ad-95c4-4a04-96aa-035a0b4115fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas_agent\n",
      "🔄 Step 1: Node 'agent'\n",
      "Metadata {'thread_id': 'cf078d61-f2af-4783-8ffe-b7eb065df3e3', 'langgraph_step': 1, 'langgraph_node': 'agent', 'langgraph_triggers': ('branch:to:agent', 'start:agent', 'tools'), 'langgraph_path': ('__pregel_pull', 'agent'), 'langgraph_checkpoint_ns': 'pandas_agent:499fc0d6-4651-af32-ec31-ab799e3d7985|agent:7219d886-d815-3022-d785-02528d8442bd', 'checkpoint_ns': 'pandas_agent:499fc0d6-4651-af32-ec31-ab799e3d7985', 'ls_provider': 'ollama', 'ls_model_name': 'gpt-oss:20b', 'ls_model_type': 'chat', 'ls_temperature': 0.7} \n",
      "\n",
      "\n",
      "🔄 Step 2: Node 'tools'\n",
      "   └── Executing tool: python_repl_ast\n",
      "Metadata {'thread_id': 'cf078d61-f2af-4783-8ffe-b7eb065df3e3', 'langgraph_step': 2, 'langgraph_node': 'tools', 'langgraph_triggers': ('branch:to:tools',), 'langgraph_path': ('__pregel_pull', 'tools'), 'langgraph_checkpoint_ns': 'pandas_agent:499fc0d6-4651-af32-ec31-ab799e3d7985|tools:44c9e6f9-e9a1-7c85-c12f-dc7ad4d3c3a6', 'checkpoint_ns': 'pandas_agent:499fc0d6-4651-af32-ec31-ab799e3d7985'} \n",
      "\n",
      "{\"age\": {\"count\": 100000.0, \"unique\": NaN, \"top\": NaN, \"freq\": NaN, \"mean\": 48.52599, \"std\": 17.886767843423776, \"min\": 18.0, \"25%\": 33.0, \"50%\": 48.0, \"75%\": 64.0, \"max\": 79.0}, \"gender\": {\"count\": 100000, \"unique\": 2, \"top\": \"Male\", \"freq\": 50132, \"mean\": NaN, \"std\": NaN, \"min\": NaN, \"25%\": NaN, \"50%\": NaN, \"75%\": NaN, \"max\": NaN}, \"bmi\": {\"count\": 100000.0, \"unique\": NaN, \"top\": NaN, \"freq\": NaN, \"mean\": 29.02479, \"std\": 6.352665961590315, \"min\": 18.0, \"25%\": 23.5, \"50%\": 29.0, \"75%\": 34.5, \"max\": 40.0}, \"daily_steps\": {\"count\": 100000.0, \"unique\": NaN, \"top\": NaN, \"freq\": NaN, \"mean\": 10479.87029, \"std\": 5483.632360115321, \"min\": 1000.0, \"25%\": 5729.0, \"50%\": 10468.0, \"75%\": 15229.0, \"max\": 19999.0}, \"sleep_hours\": {\"count\": 100000.0, \"unique\": NaN, \"top\": NaN, \"freq\": NaN, \"mean\": 6.491783999999999, \"std\": 2.0219221001398124, \"min\": 3.0, \"25%\": 4.7, \"50%\": 6.5, \"75%\": 8.2, \"max\": 10.0}, \"water_intake_l\": {\"count\": 100000.0, \"unique\": NaN, \"top\": NaN, \"freq\": NaN, \"mean\": 2.751496, \"std\": 1.2973377327573297, \"min\": 0.5, \"25%\": 1.6, \"50%\": 2.8, \"75%\": 3.9, \"max\": 5.0}, \"calories_consumed\": {\"count\": 100000.0, \"unique\": NaN, \"top\": NaN, \"freq\": NaN, \"mean\": 2603.3412, \"std\": 807.2885631239932, \"min\": 1200.0, \"25%\": 1906.0, \"50%\": 2603.0, \"75%\": 3299.0, \"max\": 3999.0}, \"smoker\": {\"count\": 100000.0, \"unique\": NaN, \"top\": NaN, \"freq\": NaN, \"mean\": 0.20094, \"std\": 0.4007052807827974, \"min\": 0.0, \"25%\": 0.0, \"50%\": 0.0, \"75%\": 0.0, \"max\": 1.0}, \"alcohol\": {\"count\": 100000.0, \"unique\": NaN, \"top\": NaN, \"freq\": NaN, \"mean\": 0.30002, \"std\": 0.4582685890403105, \"min\": 0.0, \"25%\": 0.0, \"50%\": 0.0, \"75%\": 1.0, \"max\": 1.0}, \"resting_hr\": {\"count\": 100000.0, \"unique\": NaN, \"top\": NaN, \"freq\": NaN, \"mean\": 74.45742, \"std\": 14.423715449885782, \"min\": 50.0, \"25%\": 62.0, \"50%\": 74.0, \"75%\": 87.0, \"max\": 99.0}, \"systolic_bp\": {\"count\": 100000.0, \"unique\": NaN, \"top\": NaN, \"freq\": NaN, \"mean\": 134.58063, \"std\": 25.95153046782475, \"min\": 90.0, \"25%\": 112.0, \"50%\": 135.0, \"75%\": 157.0, \"max\": 179.0}, \"diastolic_bp\": {\"count\": 100000.0, \"unique\": NaN, \"top\": NaN, \"freq\": NaN, \"mean\": 89.50885, \"std\": 17.347040983286135, \"min\": 60.0, \"25%\": 74.0, \"50%\": 89.0, \"75%\": 105.0, \"max\": 119.0}, \"cholesterol\": {\"count\": 100000.0, \"unique\": NaN, \"top\": NaN, \"freq\": NaN, \"mean\": 224.30063, \"std\": 43.32774935929335, \"min\": 150.0, \"25%\": 187.0, \"50%\": 224.0, \"75%\": 262.0, \"max\": 299.0}, \"family_history\": {\"count\": 100000.0, \"unique\": NaN, \"top\": NaN, \"freq\": NaN, \"mean\": 0.29915, \"std\": 0.45788794929954335, \"min\": 0.0, \"25%\": 0.0, \"50%\": 0.0, \"75%\": 1.0, \"max\": 1.0}, \"disease_risk\": {\"count\": 100000.0, \"unique\": NaN, \"top\": NaN, \"freq\": NaN, \"mean\": 0.24821, \"std\": 0.4319764599334313, \"min\": 0.0, \"25%\": 0.0, \"50%\": 0.0, \"75%\": 0.0, \"max\": 1.0}}\n",
      "🔄 Step 3: Node 'agent'\n",
      "Metadata {'thread_id': 'cf078d61-f2af-4783-8ffe-b7eb065df3e3', 'langgraph_step': 3, 'langgraph_node': 'agent', 'langgraph_triggers': ('branch:to:agent', 'start:agent', 'tools'), 'langgraph_path': ('__pregel_pull', 'agent'), 'langgraph_checkpoint_ns': 'pandas_agent:499fc0d6-4651-af32-ec31-ab799e3d7985|agent:50928f2f-b0bc-e9e4-76f9-225b1ab34719', 'checkpoint_ns': 'pandas_agent:499fc0d6-4651-af32-ec31-ab799e3d7985', 'ls_provider': 'ollama', 'ls_model_name': 'gpt-oss:20b', 'ls_model_type': 'chat', 'ls_temperature': 0.7} \n",
      "\n",
      "Below is a concise summary of the descriptive statistics for each column in your dataset.  \n",
      "The numbers are rounded to two decimal places for readability.\n",
      "\n",
      "| Column          | Count | Mean | Std Dev | Min | 25 % | 50 % (Median) | 75 % | Max | Unique | Top (most frequent) | Frequency |\n",
      "|-----------------|-------|------|---------|-----|------|----------------|------|-----|--------|---------------------|-----------|\n",
      "| **age**         | 100 000 | 48.53 | 17.89 | 18.0 | 33.0 | 48.0 | 64.0 | 79.0 | – | – | – |\n",
      "| **gender**      | 100 000 | – | – | – | – | – | – | – | 2 | Male | 50 132 |\n",
      "| **bmi**         | 100 000 | 29.02 | 6.35 | 18.0 | 23.5 | 29.0 | 34.5 | 40.0 | – | – | – |\n",
      "| **daily_steps** | 100 000 | 10 480 | 5 484 | 1 000 | 5 729 | 10 468 | 15 229 | 19 999 | – | – | – |\n",
      "| **sleep_hours** | 100 000 | 6.49 | 2.02 | 3.0 | 4.7 | 6.5 | 8.2 | 10.0 | – | – | – |\n",
      "| **water_intake_l** | 100 000 | 2.75 | 1.30 | 0.5 | 1.6 | 2.8 | 3.9 | 5.0 | – | – | – |\n",
      "| **calories_consumed** | 100 000 | 2 603 | 807 | 1 200 | 1 906 | 2 603 | 3 299 | 3 999 | – | – | – |\n",
      "| **smoker**      | 100 000 | 0.20 | 0.40 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | – | – | – |\n",
      "| **alcohol**     | 100 000 | 0.30 | 0.46 | 0.0 | 0.0 | 0.0 | 1.0 | 1.0 | – | – | – |\n",
      "| **resting_hr**  | 100 000 | 74.46 | 14.42 | 50.0 | 62.0 | 74.0 | 87.0 | 99.0 | – | – | – |\n",
      "| **systolic_bp** | 100 000 | 134.58 | 25.95 | 90.0 | 112.0 | 135.0 | 157.0 | 179.0 | – | – | – |\n",
      "| **diastolic_bp**| 100 000 | 89.51 | 17.35 | 60.0 | 74.0 | 89.0 | 105.0 | 119.0 | – | – | – |\n",
      "| **cholesterol** | 100 000 | 224.30 | 43.33 | 150.0 | 187.0 | 224.0 | 262.0 | 299.0 | – | – | – |\n",
      "| **family_history** | 100 000 | 0.30 | 0.46 | 0.0 | 0.0 | 0.0 | 1.0 | 1.0 | – | – | – |\n",
      "| **disease_risk** | 100 000 | 0.25 | 0.43 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | – | – | – |\n",
      "\n",
      "### Notes\n",
      "- **Binary columns** (`smoker`, `alcohol`, `family_history`, `disease_risk`) are encoded as 0/1. The mean value represents the proportion of 1’s in the column.\n",
      "- **Categorical column** `gender` has two unique values; the most frequent value is “Male” (50 132 occurrences).\n",
      "- All other columns are continuous numeric variables.\n",
      "\n",
      "Let me know if you’d like any additional summaries (e.g., correlations, group‑by statistics, or visualizations)."
     ]
    }
   ],
   "source": [
    "query = \"please give me descriptive statistics of the data\"\n",
    "await log_assistant_graph_steps(query, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38e39272-a945-4fbc-b224-82e3ae75d8dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ml_agent\n",
      "🔄 Step 1: Node 'agent'\n",
      "Metadata {'thread_id': 'cf078d61-f2af-4783-8ffe-b7eb065df3e3', 'langgraph_step': 1, 'langgraph_node': 'agent', 'langgraph_triggers': ('branch:to:agent', 'start:agent', 'tools'), 'langgraph_path': ('__pregel_pull', 'agent'), 'langgraph_checkpoint_ns': 'ml_agent:766f2c3b-6422-9610-60ef-421efc731223|agent:734c3bdd-302c-45e4-376f-9120c90cc222', 'checkpoint_ns': 'ml_agent:766f2c3b-6422-9610-60ef-421efc731223', 'ls_provider': 'ollama', 'ls_model_name': 'gpt-oss:20b', 'ls_model_type': 'chat', 'ls_temperature': 0.7} \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-10 07:08:45,412 - dataframe-chatbot - INFO - #Train examples = 80000\n",
      "2025-10-10 07:08:45,412 - dataframe-chatbot - INFO - #Test examples = 20000\n",
      "2025-10-10 07:08:50,555 - dataframe-chatbot - INFO - Best Parameters: {'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 2}\n",
      "2025-10-10 07:08:50,555 - dataframe-chatbot - INFO - Best CV Macro F1: 0.3439806638365158\n",
      "2025-10-10 07:08:50,556 - dataframe-chatbot - INFO - ----------\n",
      "\n",
      "2025-10-10 07:08:50,581 - dataframe-chatbot - INFO - ---- Train Results ----\n",
      "2025-10-10 07:08:50,582 - dataframe-chatbot - INFO - Recall (binary) = 0.6385153850027698\n",
      "2025-10-10 07:08:50,582 - dataframe-chatbot - INFO - Precision (binary) = 0.27773761801493946\n",
      "2025-10-10 07:08:50,582 - dataframe-chatbot - INFO - F1-score (binary) = 0.38709775905232946\n",
      "2025-10-10 07:08:50,582 - dataframe-chatbot - INFO - ----------\n",
      "\n",
      "2025-10-10 07:08:50,582 - dataframe-chatbot - INFO - ---- Test Results ----\n",
      "2025-10-10 07:08:50,582 - dataframe-chatbot - INFO - Recall (binary) = 0.5703062046736502\n",
      "2025-10-10 07:08:50,583 - dataframe-chatbot - INFO - Precision (binary) = 0.24561860142287004\n",
      "2025-10-10 07:08:50,583 - dataframe-chatbot - INFO - F1-score (binary) = 0.3433596118859915\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔄 Step 2: Node 'tools'\n",
      "   └── Executing tool: python_repl_ast\n",
      "Metadata {'thread_id': 'cf078d61-f2af-4783-8ffe-b7eb065df3e3', 'langgraph_step': 2, 'langgraph_node': 'tools', 'langgraph_triggers': ('branch:to:tools',), 'langgraph_path': ('__pregel_pull', 'tools'), 'langgraph_checkpoint_ns': 'ml_agent:766f2c3b-6422-9610-60ef-421efc731223|tools:370a7aba-e7ae-3fb7-f398-f7068f6fa372', 'checkpoint_ns': 'ml_agent:766f2c3b-6422-9610-60ef-421efc731223'} \n",
      "\n",
      "{\"model_uri\": \"/home/davit/medium/dataframe_chatbot/models/decision_tree/model.joblib\", \"metrics\": {\"train\": {\"Recall (binary)\": 0.6385153850027698, \"Precision (binary)\": 0.27773761801493946, \"F1-score (binary)\": 0.38709775905232946}, \"test\": {\"Recall (binary)\": 0.5703062046736502, \"Precision (binary)\": 0.24561860142287004, \"F1-score (binary)\": 0.3433596118859915}}}\n",
      "🔄 Step 3: Node 'agent'\n",
      "Metadata {'thread_id': 'cf078d61-f2af-4783-8ffe-b7eb065df3e3', 'langgraph_step': 3, 'langgraph_node': 'agent', 'langgraph_triggers': ('branch:to:agent', 'start:agent', 'tools'), 'langgraph_path': ('__pregel_pull', 'agent'), 'langgraph_checkpoint_ns': 'ml_agent:766f2c3b-6422-9610-60ef-421efc731223|agent:cce302df-e989-a355-9b54-5f0512d2b75d', 'checkpoint_ns': 'ml_agent:766f2c3b-6422-9610-60ef-421efc731223', 'ls_provider': 'ollama', 'ls_model_name': 'gpt-oss:20b', 'ls_model_type': 'chat', 'ls_temperature': 0.7} \n",
      "\n",
      "Great! The decision‑tree model has been trained and stored at:\n",
      "\n",
      "```\n",
      "/home/davit/medium/dataframe_chatbot/models/decision_tree/model.joblib\n",
      "```\n",
      "\n",
      "### Performance Summary\n",
      "\n",
      "| Set | Recall (binary) | Precision (binary) | F1‑score (binary) |\n",
      "|-----|-----------------|--------------------|-------------------|\n",
      "| **Train** | 0.639 | 0.278 | 0.387 |\n",
      "| **Test**  | 0.570 | 0.246 | 0.343 |\n",
      "\n",
      "- **Recall** (sensitivity) is the proportion of actual disease‑risk cases correctly identified.  \n",
      "- **Precision** is the proportion of predicted disease‑risk cases that are truly positive.  \n",
      "- **F1‑score** balances recall and precision.\n",
      "\n",
      "The model performs reasonably well on recall, but precision is relatively low, which is common in medical risk prediction where false positives are tolerable but false negatives are costly.\n",
      "\n",
      "### Next Steps\n",
      "\n",
      "1. **Interpretation** – If you’d like a human‑readable representation of the tree (rules, feature importance), just let me know and I’ll generate it with `export_decision_tree_to_text()`.  \n",
      "2. **Prediction** – Provide a dictionary of feature values (e.g., `{'age': 45, 'bmi': 27.5, ...}`) and I’ll return the predicted disease risk.  \n",
      "3. **Evaluation** – Want additional metrics (accuracy, ROC‑AUC, confusion matrix) or a cross‑validation report?  \n",
      "4. **Improvement** – We could tune hyperparameters, try a different algorithm, or engineer new features.\n",
      "\n",
      "What would you like to do next?"
     ]
    }
   ],
   "source": [
    "query = \"Let's now build a decision tree model using as our target variable 'disease_risk'\"\n",
    "await log_assistant_graph_steps(query, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b2a2089-1ea0-4850-a970-3afd4aa749ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas_agent\n",
      "🔄 Step 1: Node 'agent'\n",
      "Metadata {'thread_id': 'cf078d61-f2af-4783-8ffe-b7eb065df3e3', 'langgraph_step': 1, 'langgraph_node': 'agent', 'langgraph_triggers': ('branch:to:agent', 'start:agent', 'tools'), 'langgraph_path': ('__pregel_pull', 'agent'), 'langgraph_checkpoint_ns': 'pandas_agent:b9b7e620-7e2d-472b-e3cb-8f9437d6e547|agent:f2e4c006-f414-0328-2292-aa092231dbb8', 'checkpoint_ns': 'pandas_agent:b9b7e620-7e2d-472b-e3cb-8f9437d6e547', 'ls_provider': 'ollama', 'ls_model_name': 'gpt-oss:20b', 'ls_model_type': 'chat', 'ls_temperature': 0.7} \n",
      "\n",
      "\n",
      "🔧 Calling tool: python_repl_ast\n",
      "\n",
      "🔄 Step 2: Node 'tools'\n",
      "   └── Executing tool: python_repl_ast\n",
      "Metadata {'thread_id': 'cf078d61-f2af-4783-8ffe-b7eb065df3e3', 'langgraph_step': 2, 'langgraph_node': 'tools', 'langgraph_triggers': ('branch:to:tools',), 'langgraph_path': ('__pregel_pull', 'tools'), 'langgraph_checkpoint_ns': 'pandas_agent:b9b7e620-7e2d-472b-e3cb-8f9437d6e547|tools:1cfe93fa-7cb3-8df7-f119-fa29c7bbb591', 'checkpoint_ns': 'pandas_agent:b9b7e620-7e2d-472b-e3cb-8f9437d6e547'} \n",
      "\n",
      "disease_risk\n",
      "0    75179\n",
      "1    24821\n",
      "Name: count, dtype: int64\n",
      "🔄 Step 3: Node 'agent'\n",
      "Metadata {'thread_id': 'cf078d61-f2af-4783-8ffe-b7eb065df3e3', 'langgraph_step': 3, 'langgraph_node': 'agent', 'langgraph_triggers': ('branch:to:agent', 'start:agent', 'tools'), 'langgraph_path': ('__pregel_pull', 'agent'), 'langgraph_checkpoint_ns': 'pandas_agent:b9b7e620-7e2d-472b-e3cb-8f9437d6e547|agent:d0b1e7a9-ae61-ff2e-6b44-1465383cf714', 'checkpoint_ns': 'pandas_agent:b9b7e620-7e2d-472b-e3cb-8f9437d6e547', 'ls_provider': 'ollama', 'ls_model_name': 'gpt-oss:20b', 'ls_model_type': 'chat', 'ls_temperature': 0.7} \n",
      "\n",
      "Here’s the distribution of the target variable **`disease_risk`** in the dataset:\n",
      "\n",
      "| `disease_risk` | Count | Percentage |\n",
      "|----------------|-------|------------|\n",
      "| 0 (No risk)    | 75,179 | 75.2 % |\n",
      "| 1 (Risk)       | 24,821 | 24.8 % |\n",
      "\n",
      "So, about three‑quarters of the records are labeled as *no risk*, while roughly one‑quarter are labeled as *risk*."
     ]
    }
   ],
   "source": [
    "query = \"Please give me the value distribution of the column 'disease_risk'\"\n",
    "await log_assistant_graph_steps(query, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2b5ac2-997c-43f9-8d02-65f9c78ff836",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec4d120-90d1-4f1d-9d96-eefb01033de8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653e8db0-3e09-4e5c-9891-b20739616064",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8d3061-a422-4a2c-8f75-aeecb32f746e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
