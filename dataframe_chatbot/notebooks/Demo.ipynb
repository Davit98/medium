{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59c0e1ca-1f3a-4170-8ec2-74cf1f6001ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8394564f-a373-4d45-8167-adffa07127aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32585fc9-e215-41a0-a78b-b805f0fa8522",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "from langchain_core.messages import HumanMessage\n",
    "from src.ai.autodf_ml_assistant import build_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b7b0005-bf5c-4878-9ff1-a4160d8f23e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def visualize_dataframe_assistant_graph():\n",
    "    graph = await build_graph()\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67ce270b-4980-4a9b-81b1-20795a777087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "config:\n",
      "  flowchart:\n",
      "    curve: linear\n",
      "---\n",
      "graph TD;\n",
      "\t__start__([<p>__start__</p>]):::first\n",
      "\tconversation(conversation)\n",
      "\tpandas_agent(pandas_agent)\n",
      "\tml_agent(ml_agent)\n",
      "\t__end__([<p>__end__</p>]):::last\n",
      "\t__start__ --> conversation;\n",
      "\tml_agent --> __end__;\n",
      "\tpandas_agent --> __end__;\n",
      "\tconversation -.-> pandas_agent;\n",
      "\tconversation -.-> ml_agent;\n",
      "\tclassDef default fill:#f2f0ff,line-height:1.2\n",
      "\tclassDef first fill-opacity:0\n",
      "\tclassDef last fill:#bfb6fc\n",
      "\n"
     ]
    }
   ],
   "source": [
    "assistant_graph = await visualize_dataframe_assistant_graph()\n",
    "print(assistant_graph.get_graph().draw_mermaid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad67ddad-a0b1-4a67-aae9-3b82ea43533d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assistant_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "566f5b22-1e28-4790-a82c-c5bf0bd9b825",
   "metadata": {},
   "outputs": [],
   "source": [
    "thread_id = str(uuid.uuid4())\n",
    "config = {\"configurable\": {\"thread_id\" : thread_id}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3da5b54b-704d-4971-9a56-1620b49b3cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def log_assistant_graph_steps(query: str, config: dict):\n",
    "    step = 1\n",
    "    current_tool = None\n",
    "    async for token, metadata in assistant_graph.astream(\n",
    "            {\"messages\": [HumanMessage(content=query)]}, config=config, stream_mode=\"messages\"\n",
    "    ):\n",
    "        current_node = metadata.get('langgraph_node', 'unknown')\n",
    "        \n",
    "        # Check if this is a tool call by looking at the message content\n",
    "        if hasattr(token, 'tool_calls') and token.tool_calls:\n",
    "            for tool_call in token.tool_calls:\n",
    "                tool_name = tool_call.get('name', 'unknown_tool')\n",
    "                print(f\"\\nğŸ”§ Calling tool: {tool_name}\")\n",
    "                current_tool = tool_name\n",
    "        \n",
    "        # Print step metadata when it changes\n",
    "        if metadata['langgraph_step'] == step:\n",
    "            print(f\"\\nğŸ”„ Step {step}: Node '{current_node}'\")\n",
    "            if current_node == 'tools' and current_tool:\n",
    "                print(f\"   â””â”€â”€ Executing tool: {current_tool}\")\n",
    "            print(\"Metadata\", metadata, \"\\n\")\n",
    "            step += 1\n",
    "            \n",
    "        print(token.content, end='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b61c7b84-b85b-48ec-970f-5b9d0cde4903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”„ Step 1: Node 'conversation'\n",
      "Metadata {'thread_id': 'a712a6b5-1831-4e4e-a86f-6532d5bc649d', 'langgraph_step': 1, 'langgraph_node': 'conversation', 'langgraph_triggers': ('branch:to:conversation', 'start:conversation'), 'langgraph_path': ('__pregel_pull', 'conversation'), 'langgraph_checkpoint_ns': 'conversation:03e186b6-01ab-fe02-8955-26f23b30d520', 'checkpoint_ns': 'conversation:03e186b6-01ab-fe02-8955-26f23b30d520', 'ls_provider': 'ollama', 'ls_model_name': 'gpt-oss:20b', 'ls_model_type': 'chat', 'ls_temperature': 0.7} \n",
      "\n",
      "default\n",
      "ğŸ”§ Calling tool: python_repl_ast\n",
      "\n",
      "ğŸ”„ Step 2: Node 'tools'\n",
      "   â””â”€â”€ Executing tool: python_repl_ast\n",
      "Metadata {'thread_id': 'a712a6b5-1831-4e4e-a86f-6532d5bc649d', 'langgraph_step': 2, 'langgraph_node': 'tools', 'langgraph_triggers': ('branch:to:tools',), 'langgraph_path': ('__pregel_pull', 'tools'), 'langgraph_checkpoint_ns': 'pandas_agent:466460f0-7701-4739-63ea-a1d3bedc2960|tools:2b5697ff-4463-64fa-bfe3-779b52641683', 'checkpoint_ns': 'pandas_agent:466460f0-7701-4739-63ea-a1d3bedc2960'} \n",
      "\n",
      "[\"age\", \"gender\", \"bmi\", \"daily_steps\", \"sleep_hours\", \"water_intake_l\", \"calories_consumed\", \"smoker\", \"alcohol\", \"resting_hr\", \"systolic_bp\", \"diastolic_bp\", \"cholesterol\", \"family_history\", \"disease_risk\"]\n",
      "ğŸ”„ Step 3: Node 'agent'\n",
      "Metadata {'thread_id': 'a712a6b5-1831-4e4e-a86f-6532d5bc649d', 'langgraph_step': 3, 'langgraph_node': 'agent', 'langgraph_triggers': ('branch:to:agent', 'start:agent', 'tools'), 'langgraph_path': ('__pregel_pull', 'agent'), 'langgraph_checkpoint_ns': 'pandas_agent:466460f0-7701-4739-63ea-a1d3bedc2960|agent:8a20e325-4fc5-aca4-4fe7-8b711fbec1b3', 'checkpoint_ns': 'pandas_agent:466460f0-7701-4739-63ea-a1d3bedc2960', 'ls_provider': 'ollama', 'ls_model_name': 'gpt-oss:20b', 'ls_model_type': 'chat', 'ls_temperature': 0.7} \n",
      "\n",
      "Here are the column names in your dataset:\n",
      "\n",
      "1. `age`  \n",
      "2. `gender`  \n",
      "3. `bmi`  \n",
      "4. `daily_steps`  \n",
      "5. `sleep_hours`  \n",
      "6. `water_intake_l`  \n",
      "7. `calories_consumed`  \n",
      "8. `smoker`  \n",
      "9. `alcohol`  \n",
      "10. `resting_hr`  \n",
      "11. `systolic_bp`  \n",
      "12. `diastolic_bp`  \n",
      "13. `cholesterol`  \n",
      "14. `family_history`  \n",
      "15. `disease_risk`"
     ]
    }
   ],
   "source": [
    "query = \"List the columns of my dataset.\"\n",
    "await log_assistant_graph_steps(query, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f038d3ad-95c4-4a04-96aa-035a0b4115fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas_agent\n",
      "ğŸ”„ Step 1: Node 'agent'\n",
      "Metadata {'thread_id': 'a712a6b5-1831-4e4e-a86f-6532d5bc649d', 'langgraph_step': 1, 'langgraph_node': 'agent', 'langgraph_triggers': ('branch:to:agent', 'start:agent', 'tools'), 'langgraph_path': ('__pregel_pull', 'agent'), 'langgraph_checkpoint_ns': 'pandas_agent:1e676f25-48f1-01c7-96af-c5a099235064|agent:aee4ad90-c7cb-1492-835e-9e49be32d1ed', 'checkpoint_ns': 'pandas_agent:1e676f25-48f1-01c7-96af-c5a099235064', 'ls_provider': 'ollama', 'ls_model_name': 'gpt-oss:20b', 'ls_model_type': 'chat', 'ls_temperature': 0.7} \n",
      "\n",
      "\n",
      "ğŸ”„ Step 2: Node 'tools'\n",
      "   â””â”€â”€ Executing tool: python_repl_ast\n",
      "Metadata {'thread_id': 'a712a6b5-1831-4e4e-a86f-6532d5bc649d', 'langgraph_step': 2, 'langgraph_node': 'tools', 'langgraph_triggers': ('branch:to:tools',), 'langgraph_path': ('__pregel_pull', 'tools'), 'langgraph_checkpoint_ns': 'pandas_agent:1e676f25-48f1-01c7-96af-c5a099235064|tools:debff8e5-d9c9-f0e0-4635-9dd2d6437210', 'checkpoint_ns': 'pandas_agent:1e676f25-48f1-01c7-96af-c5a099235064'} \n",
      "\n",
      "{\"age\": {\"count\": 100000.0, \"unique\": NaN, \"top\": NaN, \"freq\": NaN, \"mean\": 48.52599, \"std\": 17.886767843423776, \"min\": 18.0, \"25%\": 33.0, \"50%\": 48.0, \"75%\": 64.0, \"max\": 79.0}, \"gender\": {\"count\": 100000, \"unique\": 2, \"top\": \"Male\", \"freq\": 50132, \"mean\": NaN, \"std\": NaN, \"min\": NaN, \"25%\": NaN, \"50%\": NaN, \"75%\": NaN, \"max\": NaN}, \"bmi\": {\"count\": 100000.0, \"unique\": NaN, \"top\": NaN, \"freq\": NaN, \"mean\": 29.02479, \"std\": 6.352665961590315, \"min\": 18.0, \"25%\": 23.5, \"50%\": 29.0, \"75%\": 34.5, \"max\": 40.0}, \"daily_steps\": {\"count\": 100000.0, \"unique\": NaN, \"top\": NaN, \"freq\": NaN, \"mean\": 10479.87029, \"std\": 5483.632360115321, \"min\": 1000.0, \"25%\": 5729.0, \"50%\": 10468.0, \"75%\": 15229.0, \"max\": 19999.0}, \"sleep_hours\": {\"count\": 100000.0, \"unique\": NaN, \"top\": NaN, \"freq\": NaN, \"mean\": 6.491783999999999, \"std\": 2.0219221001398124, \"min\": 3.0, \"25%\": 4.7, \"50%\": 6.5, \"75%\": 8.2, \"max\": 10.0}, \"water_intake_l\": {\"count\": 100000.0, \"unique\": NaN, \"top\": NaN, \"freq\": NaN, \"mean\": 2.751496, \"std\": 1.2973377327573297, \"min\": 0.5, \"25%\": 1.6, \"50%\": 2.8, \"75%\": 3.9, \"max\": 5.0}, \"calories_consumed\": {\"count\": 100000.0, \"unique\": NaN, \"top\": NaN, \"freq\": NaN, \"mean\": 2603.3412, \"std\": 807.2885631239932, \"min\": 1200.0, \"25%\": 1906.0, \"50%\": 2603.0, \"75%\": 3299.0, \"max\": 3999.0}, \"smoker\": {\"count\": 100000.0, \"unique\": NaN, \"top\": NaN, \"freq\": NaN, \"mean\": 0.20094, \"std\": 0.4007052807827974, \"min\": 0.0, \"25%\": 0.0, \"50%\": 0.0, \"75%\": 0.0, \"max\": 1.0}, \"alcohol\": {\"count\": 100000.0, \"unique\": NaN, \"top\": NaN, \"freq\": NaN, \"mean\": 0.30002, \"std\": 0.4582685890403105, \"min\": 0.0, \"25%\": 0.0, \"50%\": 0.0, \"75%\": 1.0, \"max\": 1.0}, \"resting_hr\": {\"count\": 100000.0, \"unique\": NaN, \"top\": NaN, \"freq\": NaN, \"mean\": 74.45742, \"std\": 14.423715449885782, \"min\": 50.0, \"25%\": 62.0, \"50%\": 74.0, \"75%\": 87.0, \"max\": 99.0}, \"systolic_bp\": {\"count\": 100000.0, \"unique\": NaN, \"top\": NaN, \"freq\": NaN, \"mean\": 134.58063, \"std\": 25.95153046782475, \"min\": 90.0, \"25%\": 112.0, \"50%\": 135.0, \"75%\": 157.0, \"max\": 179.0}, \"diastolic_bp\": {\"count\": 100000.0, \"unique\": NaN, \"top\": NaN, \"freq\": NaN, \"mean\": 89.50885, \"std\": 17.347040983286135, \"min\": 60.0, \"25%\": 74.0, \"50%\": 89.0, \"75%\": 105.0, \"max\": 119.0}, \"cholesterol\": {\"count\": 100000.0, \"unique\": NaN, \"top\": NaN, \"freq\": NaN, \"mean\": 224.30063, \"std\": 43.32774935929335, \"min\": 150.0, \"25%\": 187.0, \"50%\": 224.0, \"75%\": 262.0, \"max\": 299.0}, \"family_history\": {\"count\": 100000.0, \"unique\": NaN, \"top\": NaN, \"freq\": NaN, \"mean\": 0.29915, \"std\": 0.45788794929954335, \"min\": 0.0, \"25%\": 0.0, \"50%\": 0.0, \"75%\": 1.0, \"max\": 1.0}, \"disease_risk\": {\"count\": 100000.0, \"unique\": NaN, \"top\": NaN, \"freq\": NaN, \"mean\": 0.24821, \"std\": 0.4319764599334313, \"min\": 0.0, \"25%\": 0.0, \"50%\": 0.0, \"75%\": 0.0, \"max\": 1.0}}\n",
      "ğŸ”„ Step 3: Node 'agent'\n",
      "Metadata {'thread_id': 'a712a6b5-1831-4e4e-a86f-6532d5bc649d', 'langgraph_step': 3, 'langgraph_node': 'agent', 'langgraph_triggers': ('branch:to:agent', 'start:agent', 'tools'), 'langgraph_path': ('__pregel_pull', 'agent'), 'langgraph_checkpoint_ns': 'pandas_agent:1e676f25-48f1-01c7-96af-c5a099235064|agent:c94eb0b0-4961-768b-e216-98823eac5276', 'checkpoint_ns': 'pandas_agent:1e676f25-48f1-01c7-96af-c5a099235064', 'ls_provider': 'ollama', 'ls_model_name': 'gpt-oss:20b', 'ls_model_type': 'chat', 'ls_temperature': 0.7} \n",
      "\n",
      "Below is a concise summary of the key descriptive statistics for each column in your dataset (100â€¯000 rows).  \n",
      "For numeric columns we report **count, mean, std, min, 25â€¯%, 50â€¯% (median), 75â€¯%, max**.  \n",
      "For categorical columns we report **count, unique, top (most frequent value), freq (count of the top)**.\n",
      "\n",
      "| Column          | Count | Mean | Std | Min | 25â€¯% | 50â€¯% | 75â€¯% | Max | Unique | Top | Freq |\n",
      "|-----------------|-------|------|-----|-----|------|------|------|-----|--------|-----|------|\n",
      "| **age**         | 100â€¯000 | 48.53 | 17.89 | 18 | 33 | 48 | 64 | 79 | â€“ | â€“ | â€“ |\n",
      "| **gender**      | 100â€¯000 | â€“ | â€“ | â€“ | â€“ | â€“ | â€“ | â€“ | 2 | Male | 50â€¯132 |\n",
      "| **bmi**         | 100â€¯000 | 29.02 | 6.35 | 18 | 23.5 | 29 | 34.5 | 40 | â€“ | â€“ | â€“ |\n",
      "| **daily_steps** | 100â€¯000 | 10â€¯480 | 5â€¯484 | 1â€¯000 | 5â€¯729 | 10â€¯468 | 15â€¯229 | 19â€¯999 | â€“ | â€“ | â€“ |\n",
      "| **sleep_hours** | 100â€¯000 | 6.49 | 2.02 | 3 | 4.7 | 6.5 | 8.2 | 10 | â€“ | â€“ | â€“ |\n",
      "| **water_intake_l** | 100â€¯000 | 2.75 | 1.30 | 0.5 | 1.6 | 2.8 | 3.9 | 5 | â€“ | â€“ | â€“ |\n",
      "| **calories_consumed** | 100â€¯000 | 2â€¯603 | 807 | 1â€¯200 | 1â€¯906 | 2â€¯603 | 3â€¯299 | 3â€¯999 | â€“ | â€“ | â€“ |\n",
      "| **smoker**      | 100â€¯000 | 0.201 | 0.401 | 0 | 0 | 0 | 0 | 1 | â€“ | â€“ | â€“ |\n",
      "| **alcohol**     | 100â€¯000 | 0.300 | 0.458 | 0 | 0 | 0 | 1 | 1 | â€“ | â€“ | â€“ |\n",
      "| **resting_hr**  | 100â€¯000 | 74.46 | 14.42 | 50 | 62 | 74 | 87 | 99 | â€“ | â€“ | â€“ |\n",
      "| **systolic_bp** | 100â€¯000 | 134.58 | 25.95 | 90 | 112 | 135 | 157 | 179 | â€“ | â€“ | â€“ |\n",
      "| **diastolic_bp**| 100â€¯000 | 89.51 | 17.35 | 60 | 74 | 89 | 105 | 119 | â€“ | â€“ | â€“ |\n",
      "| **cholesterol** | 100â€¯000 | 224.30 | 43.33 | 150 | 187 | 224 | 262 | 299 | â€“ | â€“ | â€“ |\n",
      "| **family_history** | 100â€¯000 | 0.299 | 0.458 | 0 | 0 | 0 | 1 | 1 | â€“ | â€“ | â€“ |\n",
      "| **disease_risk** | 100â€¯000 | 0.248 | 0.432 | 0 | 0 | 0 | 0 | 1 | â€“ | â€“ | â€“ |\n",
      "\n",
      "### Quick Takeaways\n",
      "\n",
      "- **Age & BMI**: The population is relatively mature (mean age ~48.5â€¯y) and on the higher side of BMI (mean ~29â€¯kg/mÂ²).\n",
      "- **Physical activity**: Average daily steps (~10â€¯480) suggests moderate activity; the 25th percentile is 5â€¯729 steps.\n",
      "- **Sleep**: Mean sleep is ~6.5â€¯h; 75th percentile at 8.2â€¯h indicates many people sleep above 8â€¯h.\n",
      "- **Hydration**: Average water intake is ~2.75â€¯L/day, with 75th percentile at 3.9â€¯L.\n",
      "- **Nutrition**: Caloric intake averages ~2â€¯603â€¯kcal/day, with a spread from 1â€¯200 to 3â€¯999â€¯kcal.\n",
      "- **Lifestyle**: ~20â€¯% are smokers, ~30â€¯% consume alcohol.\n",
      "- **Cardiovascular metrics**: Systolic BP mean ~134â€¯mmHg, diastolic ~90â€¯mmHg, reflecting a slightly elevated average.\n",
      "- **Risk factors**: ~30â€¯% have a family history of disease; overall disease risk mean ~0.25 (on a 0â€“1 scale).\n",
      "\n",
      "Feel free to let me know if youâ€™d like visualizations, deeper statistical tests, or any other analysis!"
     ]
    }
   ],
   "source": [
    "query = \"please give me descriptive statistics of the data\"\n",
    "await log_assistant_graph_steps(query, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38e39272-a945-4fbc-b224-82e3ae75d8dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ml_agent\n",
      "ğŸ”„ Step 1: Node 'agent'\n",
      "Metadata {'thread_id': 'a712a6b5-1831-4e4e-a86f-6532d5bc649d', 'langgraph_step': 1, 'langgraph_node': 'agent', 'langgraph_triggers': ('branch:to:agent', 'start:agent', 'tools'), 'langgraph_path': ('__pregel_pull', 'agent'), 'langgraph_checkpoint_ns': 'ml_agent:77fb2ef2-f3e2-5584-2833-5a39b6f4bd7b|agent:a11af55c-66c1-1e48-02fd-826dc6dc67f1', 'checkpoint_ns': 'ml_agent:77fb2ef2-f3e2-5584-2833-5a39b6f4bd7b', 'ls_provider': 'ollama', 'ls_model_name': 'gpt-oss:20b', 'ls_model_type': 'chat', 'ls_temperature': 0.7} \n",
      "\n",
      "\n",
      "ğŸ”§ Calling tool: python_repl_ast\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-10 06:52:18,188 - dataframe-chatbot - INFO - #Train examples = 80000\n",
      "2025-10-10 06:52:18,188 - dataframe-chatbot - INFO - #Test examples = 20000\n",
      "2025-10-10 06:52:23,360 - dataframe-chatbot - INFO - Best Parameters: {'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 2}\n",
      "2025-10-10 06:52:23,361 - dataframe-chatbot - INFO - Best CV Macro F1: 0.3439806638365158\n",
      "2025-10-10 06:52:23,361 - dataframe-chatbot - INFO - ----------\n",
      "\n",
      "2025-10-10 06:52:23,387 - dataframe-chatbot - INFO - ---- Train Results ----\n",
      "2025-10-10 06:52:23,387 - dataframe-chatbot - INFO - Recall (binary) = 0.6385153850027698\n",
      "2025-10-10 06:52:23,388 - dataframe-chatbot - INFO - Precision (binary) = 0.27773761801493946\n",
      "2025-10-10 06:52:23,388 - dataframe-chatbot - INFO - F1-score (binary) = 0.38709775905232946\n",
      "2025-10-10 06:52:23,388 - dataframe-chatbot - INFO - ----------\n",
      "\n",
      "2025-10-10 06:52:23,388 - dataframe-chatbot - INFO - ---- Test Results ----\n",
      "2025-10-10 06:52:23,389 - dataframe-chatbot - INFO - Recall (binary) = 0.5703062046736502\n",
      "2025-10-10 06:52:23,389 - dataframe-chatbot - INFO - Precision (binary) = 0.24561860142287004\n",
      "2025-10-10 06:52:23,389 - dataframe-chatbot - INFO - F1-score (binary) = 0.3433596118859915\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”„ Step 2: Node 'tools'\n",
      "   â””â”€â”€ Executing tool: python_repl_ast\n",
      "Metadata {'thread_id': 'a712a6b5-1831-4e4e-a86f-6532d5bc649d', 'langgraph_step': 2, 'langgraph_node': 'tools', 'langgraph_triggers': ('branch:to:tools',), 'langgraph_path': ('__pregel_pull', 'tools'), 'langgraph_checkpoint_ns': 'ml_agent:77fb2ef2-f3e2-5584-2833-5a39b6f4bd7b|tools:67758101-091f-a790-82d9-f057ef42054e', 'checkpoint_ns': 'ml_agent:77fb2ef2-f3e2-5584-2833-5a39b6f4bd7b'} \n",
      "\n",
      "{\"model_uri\": \"/home/davit/medium/dataframe_chatbot/models/decision_tree/model.joblib\", \"metrics\": {\"train\": {\"Recall (binary)\": 0.6385153850027698, \"Precision (binary)\": 0.27773761801493946, \"F1-score (binary)\": 0.38709775905232946}, \"test\": {\"Recall (binary)\": 0.5703062046736502, \"Precision (binary)\": 0.24561860142287004, \"F1-score (binary)\": 0.3433596118859915}}}\n",
      "ğŸ”„ Step 3: Node 'agent'\n",
      "Metadata {'thread_id': 'a712a6b5-1831-4e4e-a86f-6532d5bc649d', 'langgraph_step': 3, 'langgraph_node': 'agent', 'langgraph_triggers': ('branch:to:agent', 'start:agent', 'tools'), 'langgraph_path': ('__pregel_pull', 'agent'), 'langgraph_checkpoint_ns': 'ml_agent:77fb2ef2-f3e2-5584-2833-5a39b6f4bd7b|agent:017fca7a-55e7-c6fe-462a-022c330c172c', 'checkpoint_ns': 'ml_agent:77fb2ef2-f3e2-5584-2833-5a39b6f4bd7b', 'ls_provider': 'ollama', 'ls_model_name': 'gpt-oss:20b', 'ls_model_type': 'chat', 'ls_temperature': 0.7} \n",
      "\n",
      "Your decisionâ€‘tree model has been trained successfully!  \n",
      "Hereâ€™s what the tool returned:\n",
      "\n",
      "| Phase | Recall (binary) | Precision (binary) | F1â€‘score (binary) |\n",
      "|-------|-----------------|--------------------|-------------------|\n",
      "| **Train** | 0.6385 | 0.2777 | 0.3871 |\n",
      "| **Test** | 0.5703 | 0.2456 | 0.3434 |\n",
      "\n",
      "**What this means**\n",
      "\n",
      "- **Recall** (sensitivity) is reasonably high on the training set (~64â€¯%) and still decent on the test set (~57â€¯%). The model is catching a fair number of actual diseaseâ€‘risk cases.\n",
      "- **Precision** is low (~28â€¯% train, ~25â€¯% test). When the model predicts â€œhigh riskâ€, itâ€™s correct only about a quarter of the time.\n",
      "- **F1â€‘score** reflects the tradeâ€‘off between precision and recall, and is moderate (~0.39 train, ~0.34 test).\n",
      "\n",
      "The model is stored at:\n",
      "\n",
      "```\n",
      "/home/davit/medium/dataframe_chatbot/models/decision_tree/model.joblib\n",
      "```\n",
      "\n",
      "### Next steps you might consider\n",
      "\n",
      "1. **Visualize the tree** â€“ `export_decision_tree_to_text()` will give you a humanâ€‘readable rule set.  \n",
      "2. **Make predictions** on new data â€“ `model_inference(feature_values)` where `feature_values` is a dict of column names to lists.  \n",
      "3. **Tune the model** â€“ adjust depth, min_samples_split, etc., and retrain to improve precision.  \n",
      "4. **Evaluate other metrics** â€“ e.g., ROCâ€‘AUC, confusion matrix, or a weighted average if class imbalance matters.\n",
      "\n",
      "Let me know what youâ€™d like to do next!"
     ]
    }
   ],
   "source": [
    "query = \"Let's now build a decision tree model using as our target variable 'disease_risk'\"\n",
    "await log_assistant_graph_steps(query, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b2a2089-1ea0-4850-a970-3afd4aa749ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas_agent\n",
      "ğŸ”„ Step 1: Node 'agent'\n",
      "Metadata {'thread_id': 'a712a6b5-1831-4e4e-a86f-6532d5bc649d', 'langgraph_step': 1, 'langgraph_node': 'agent', 'langgraph_triggers': ('branch:to:agent', 'start:agent', 'tools'), 'langgraph_path': ('__pregel_pull', 'agent'), 'langgraph_checkpoint_ns': 'pandas_agent:02c37a5d-216b-b430-caa7-780a1ebf1cf9|agent:e10b3da6-69ee-0272-0ff4-bac2471cfaef', 'checkpoint_ns': 'pandas_agent:02c37a5d-216b-b430-caa7-780a1ebf1cf9', 'ls_provider': 'ollama', 'ls_model_name': 'gpt-oss:20b', 'ls_model_type': 'chat', 'ls_temperature': 0.7} \n",
      "\n",
      "\n",
      "ğŸ”§ Calling tool: python_repl_ast\n",
      "\n",
      "ğŸ”„ Step 2: Node 'tools'\n",
      "   â””â”€â”€ Executing tool: python_repl_ast\n",
      "Metadata {'thread_id': 'a712a6b5-1831-4e4e-a86f-6532d5bc649d', 'langgraph_step': 2, 'langgraph_node': 'tools', 'langgraph_triggers': ('branch:to:tools',), 'langgraph_path': ('__pregel_pull', 'tools'), 'langgraph_checkpoint_ns': 'pandas_agent:02c37a5d-216b-b430-caa7-780a1ebf1cf9|tools:26fbe288-892a-e677-1a61-c7339c906dcf', 'checkpoint_ns': 'pandas_agent:02c37a5d-216b-b430-caa7-780a1ebf1cf9'} \n",
      "\n",
      "disease_risk\n",
      "0    75179\n",
      "1    24821\n",
      "Name: count, dtype: int64\n",
      "ğŸ”„ Step 3: Node 'agent'\n",
      "Metadata {'thread_id': 'a712a6b5-1831-4e4e-a86f-6532d5bc649d', 'langgraph_step': 3, 'langgraph_node': 'agent', 'langgraph_triggers': ('branch:to:agent', 'start:agent', 'tools'), 'langgraph_path': ('__pregel_pull', 'agent'), 'langgraph_checkpoint_ns': 'pandas_agent:02c37a5d-216b-b430-caa7-780a1ebf1cf9|agent:a289d25e-1f9e-1695-8dd9-77eaaba33fdd', 'checkpoint_ns': 'pandas_agent:02c37a5d-216b-b430-caa7-780a1ebf1cf9', 'ls_provider': 'ollama', 'ls_model_name': 'gpt-oss:20b', 'ls_model_type': 'chat', 'ls_temperature': 0.7} \n",
      "\n",
      "**Distribution of the target variable `disease_risk`**\n",
      "\n",
      "| Value | Count | Percentage |\n",
      "|-------|-------|------------|\n",
      "| 0 (no disease risk) | 75,179 | 75.1â€¯% |\n",
      "| 1 (disease risk) | 24,821 | 24.9â€¯% |\n",
      "\n",
      "So roughly 3 out of 4 patients are labeled **0**, while about 1 out of 4 are labeled **1**. This indicates a moderate class imbalance that may influence model performance (e.g., lower precision)."
     ]
    }
   ],
   "source": [
    "query = \"Please give me value distribution of 'disease_risk'\"\n",
    "await log_assistant_graph_steps(query, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2b5ac2-997c-43f9-8d02-65f9c78ff836",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec4d120-90d1-4f1d-9d96-eefb01033de8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653e8db0-3e09-4e5c-9891-b20739616064",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8d3061-a422-4a2c-8f75-aeecb32f746e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
